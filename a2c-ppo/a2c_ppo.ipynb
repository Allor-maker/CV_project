{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import gymnasium\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_CLASSES = 10\n",
    "IMG_SIZE = 32  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet():\n",
    "    def __init__(self):# 1. Параметры генератора\n",
    "        self.CELL_COUNT_RANGE = (1, 10)  # Количество клеток на изображение (минимум, максимум)\n",
    "        self.CELL_SIZE_RANGE = (5, 15)  # Диаметр клеток (минимум, максимум)\n",
    "        self.CELL_COLOR_RANGE = ((100, 0, 0), (255, 100, 100))  # Цвет клеток (минимум, максимум по BGR)\n",
    "        self.BACKGROUND_COLOR = (247, 131, 243)  # Розовый фон\n",
    "        self.OVERLAP_PROBABILITY = 0.1  # Вероятность перекрытия клетки с другой\n",
    "    \n",
    "    def random_color(self, color_range):\n",
    "        \"\"\"Генерирует случайный цвет в заданном диапазоне.\"\"\"\n",
    "        return tuple(random.randint(color_range[0][i], color_range[1][i]) for i in range(3))\n",
    "\n",
    "    def generate_blood_cell_image(self):\n",
    "        \"\"\"Генерирует одно изображение с клетками крови.\"\"\"\n",
    "        image = Image.new(\"RGB\", (IMG_SIZE, IMG_SIZE), self.BACKGROUND_COLOR)\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        cell_count = random.randint(self.CELL_COUNT_RANGE[0], self.CELL_COUNT_RANGE[1])\n",
    "        cells = []  # Список координат и размеров клеток, чтобы отслеживать перекрытия\n",
    "\n",
    "        for _ in range(cell_count):\n",
    "            cell_size = random.randint(self.CELL_SIZE_RANGE[0], self.CELL_SIZE_RANGE[1])\n",
    "\n",
    "            # Попробуем найти позицию для клетки, чтобы избежать перекрытия (если OVERLAP_PROBABILITY низкая)\n",
    "            max_attempts = 100\n",
    "            for attempt in range(max_attempts):\n",
    "                x = random.randint(cell_size, IMG_SIZE - cell_size)\n",
    "                y = random.randint(cell_size, IMG_SIZE - cell_size)\n",
    "\n",
    "                # Проверяем, перекрывается ли новая клетка с существующими\n",
    "                overlap = False\n",
    "                if random.random() > self.OVERLAP_PROBABILITY: # Проверяем, нужно ли вообще проверять перекрытие\n",
    "                    for existing_x, existing_y, existing_size in cells:\n",
    "                        distance = np.sqrt((x - existing_x)**2 + (y - existing_y)**2)\n",
    "                        if distance < (cell_size + existing_size) * 0.7:  # Уменьшил коэфф. для допущения небольшого перекрытия\n",
    "                            overlap = True\n",
    "                            break\n",
    "\n",
    "                if not overlap:\n",
    "                    break # Нашли подходящую позицию\n",
    "\n",
    "            if overlap and attempt == max_attempts-1 :\n",
    "                #Если не нашли хорошую позицию, то игнорируем данную клетку\n",
    "                continue\n",
    "\n",
    "\n",
    "            cell_color = self.random_color(self.CELL_COLOR_RANGE)\n",
    "            draw.ellipse((x - cell_size, y - cell_size, x + cell_size, y + cell_size), fill=cell_color)\n",
    "            cells.append((x, y, cell_size))\n",
    "\n",
    "        return np.array(image), cell_count\n",
    "\n",
    "    def generate_dataset(self,num_images, output_dir=\"blood_cell_dataset\"):\n",
    "        \"\"\"Генерирует набор данных изображений и меток.\"\"\"\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        for i in range(num_images):\n",
    "            image, cell_count = self.generate_blood_cell_image()\n",
    "            images.append(image)\n",
    "            labels.append(cell_count)\n",
    "\n",
    "            # Сохранение изображений (опционально)\n",
    "            image_path = os.path.join(output_dir, f\"image_{i}.png\")\n",
    "            cv2.imwrite(image_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))  # Convert to BGR for OpenCV\n",
    "\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(subset):\n",
    "    return DataLoader(subset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, batch):\n",
    "        return batch.view(batch.size(0), -1)\n",
    "    \n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.cv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.cv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.flatten = Flatten()\n",
    "        self.fc1 = nn.Linear(64 * IMG_SIZE * IMG_SIZE, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.cv1(x))\n",
    "        x = F.relu(self.cv2(x))\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BloodCellDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        #self.images = [cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) for img in images]  # Преобразуем в градации серого\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = np.expand_dims(image, axis=0)  # Добавляем канал (1, H, W)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return torch.tensor(image, dtype=torch.float32), torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreloading():\n",
    "    def __init__(self, num_samples=100):\n",
    "        self.dataset_generator = DataSet()\n",
    "        images, labels = self.dataset_generator.generate_dataset(num_samples)\n",
    "        self.dataset = BloodCellDataset(images, labels)\n",
    "\n",
    "    def get_train_data(self):\n",
    "        return self.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSelectionEnv(gymnasium.Env):\n",
    "    def __init__(self):\n",
    "        super(DataSelectionEnv, self).__init__()\n",
    "        self.train_data = DataPreloading().get_train_data()\n",
    "        self.num_class = NUM_CLASSES\n",
    "        self.model = SimpleCNN()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.total_num_img = 32\n",
    "        self.indexes = self.class_select()\n",
    "        self.optim = optim.Adam(self.model.parameters(), lr=LEARNING_RATE)\n",
    "        \n",
    "        # Пространство действий: вероятности выбора изображений для каждого класса\n",
    "        self.action_space = gymnasium.spaces.Box(low=0, high=1, shape=(NUM_CLASSES,), dtype=np.float32)\n",
    "        self.observation_space = gymnasium.spaces.Box(low=0, high=1, shape=(NUM_CLASSES,), dtype=np.float32)\n",
    "    \n",
    "    def class_select(self):#возвращаем словарь из индексов принадлежащим классам\n",
    "        ls = {i: [] for i in range(self.num_class)} #создали пустой словарь на 10 классов\n",
    "\n",
    "        for x, (_, label) in enumerate(self.train_data):\n",
    "            ls[label].append(x) #индекс каждого изображения из train_data положили в нужный класс в зависимости от метки\n",
    "\n",
    "        return ls\n",
    "    \n",
    "    def sample(self, action):#action - тензор распределения процентов изображений от каждого класса в выборке\n",
    "        action = F.softmax(torch.tensor(action), dim=-1).numpy()\n",
    "        index = []\n",
    "\n",
    "        for i in range(self.num_class):\n",
    "            num_img = int(action[i] * self.total_num_img) #определили количество изображений для i-го класса в выборке из 32 изображений\n",
    "            indexes = np.random.choice(self.indexes[i], num_img, replace=True) #рандомно выбираем вычисленное количество изображений из изображений нужного класса, возвращаем их индексы\n",
    "            index.extend(indexes)#добавляем найденные индексы в выборку\n",
    "\n",
    "        return Subset(self.train_data, index)#состовляем subset \n",
    "    \n",
    "    def step(self, action):\n",
    "        # в этой функции мы создаем выборку на основе action и проверяем, насколько улучшилось или ухудшилось предсказание сети\n",
    "        train_subset = self.sample(action) #subset - выбранное случайное подмножество из 32 элементов на основе распределения action\n",
    "        test_subset = self.sample(action) #subset - выбранное случайное подмножество из 32 элементов на основе распределения action\n",
    "\n",
    "        train_dataloader = get_dataloader(train_subset) #создали dataloader, выдающий этот batch из 32 элементов \n",
    "        test_dataloader = get_dataloader(test_subset) #создаем dataloader для тестирования\n",
    "\n",
    "        prev_acc, _ = self.evaluate(test_dataloader) #вычиляем текущую точность модели на тестовой выборке\n",
    "        self.train_model(train_dataloader) #тренируем модель на тренировчной выборке\n",
    "        new_acc, err_per_cl = self.evaluate(test_dataloader) #проверяем модель после тренировки на тестовой выборке\n",
    "\n",
    "        reward = new_acc - prev_acc #вычисляем награду\n",
    "\n",
    "        return reward, err_per_cl\n",
    "    \n",
    "    def train_model(self, dataloader):\n",
    "        # на вход приходит dataloader выдающий batch изображений и ответов к ним\n",
    "        batch = iter(dataloader) #получили батч из тренирогочного dataloader \n",
    "        images, labels = batch #разделили полученный батч на изображения и метки\n",
    "\n",
    "        self.optim.zero_grad() #обновили optimizer\n",
    "        output = self.model(images) #получили тензор(batch_size, NUM_CLASSES) с распределением вероятностей для каждого изображения\n",
    "        loss = self.criterion(output, labels) #вычислили ошибку с помощью CrossEntropyLoss\n",
    "\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "    \n",
    "    def evaluate(self,dataloader):#тестирование модели\n",
    "        self.model.eval()#перевели модель в оценочный режим\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "        with torch.no_grad():\n",
    "            batch = iter(dataloader) #получили из dataloader batch на batch_size изображений\n",
    "            images,labels = batch # получили изображения и ответы\n",
    "            all_labels.extend(labels)\n",
    "            output = self.model(images) #получили тензор(batch_size,NUM_CLASSES) с распределениями вероятснотей для каждого изображения\n",
    "            predicted = torch.argmax(output,dim=1) #получили тезор(batch_size) с предложенными значениями классов\n",
    "            all_preds.extend(predicted)\n",
    "            correct += (predicted==labels).sum().item() #нашли количество правильных ответов\n",
    "            total = BATCH_SIZE #так как мы рассматриваем только один батч, следовательно общий разве - BATCH_SIZE\n",
    "\n",
    "        conf_matrix = confusion_matrix(all_labels,all_preds)#находим confusion matrix,чтобы рассчитать ошибку по классам\n",
    "        error_per_class = conf_matrix.sum(axis=1) - np.diagonal(conf_matrix)#рассчитываем ошибку по классам, возваращаем ...\n",
    "        accuracy = correct / total if total > 0 else 0 # находим точность на данной выборке\n",
    "        return accuracy, error_per_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, input_size, num_actions):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, num_actions)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x), dim=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actor_critic(env, actor, critic, episodes=100, max_steps=100, gamma=0.99, lr_actor=1e-3, lr_critic=1e-3):\n",
    "    optimizer_actor = optim.AdamW(actor.parameters(), lr=lr_actor)\n",
    "    optimizer_critic = optim.AdamW(critic.parameters(), lr=lr_critic)\n",
    "    EPS = 0.2 #значение epsilon для клиппинга обычно от 0.1 до 0.3\n",
    "    state = np.ones(NUM_CLASSES) / 2 # проценты точности на каждом классе\n",
    "    for episode in range(episodes):\n",
    "        step = 0\n",
    "        while step < max_steps:\n",
    "            step += 1\n",
    "            state_tensor = torch.FloatTensor(state)#флотовый тензор с процентами точности\n",
    "            action_probabilities = actor(state_tensor)#вызов forward для actor от state_tensor, возвращает тензор распределения процентов количества изображений классов в выборке\n",
    "            action = action_probabilities.numpy() # ndarray от action_probabilities\n",
    "            old_log_prob = torch.log(action_probabilities)\n",
    "\n",
    "            reward, next_state = env.step(action) #рассчитываем награду и next_state, где next_state - ndarray процента ошибок по классам на тестовой выборке из batch_size элементов\n",
    "            next_state_tensor = torch.FloatTensor(next_state)#создаем тензор от next_state\n",
    "            new_action_probabilities = actor(next_state_tensor)\n",
    "            new_log_prob = torch.log(new_action_probabilities)\n",
    "\n",
    "            value = critic(state_tensor) #критик предсказывает значение на основе предыдущего тензора \n",
    "            next_value = critic(next_state_tensor) #и предсказывает значение на основе нового тензора\n",
    "            \n",
    "            advantage = reward + (gamma * next_value.item()) - value.item()\n",
    "            loss_critic = advantage ** 2\n",
    "\n",
    "            #вычисляем потерю актера с учетом клиппинга\n",
    "            ratio = torch.exp(new_log_prob - old_log_prob)\n",
    "            surrogate_loss = torch.min(ratio * advantage, torch.clamp(ratio, 1 - EPS, 1 + EPS) * advantage)\n",
    "            loss_actor = -surrogate_loss.mean()\n",
    "\n",
    "            optimizer_critic.zero_grad()\n",
    "            loss_critic.backward()\n",
    "            optimizer_critic.step()\n",
    "            state = next_state\n",
    "\n",
    "            #вводим фиктивную раномерно распределенную выборку для более объективной оценки точности\n",
    "            if step == 99:\n",
    "                test_state = np.ones(NUM_CLASSES)/NUM_CLASSES\n",
    "                test_action_probabilities = torch.FloatTensor(test_state)\n",
    "                test_action = test_action_probabilities.numpy()\n",
    "                _,state = env.step(test_action)\n",
    "            #обновляем политику раз в 10 шагов\n",
    "            if step % 10 == 0:\n",
    "                optimizer_actor.zero_grad()\n",
    "                loss_actor.backward()\n",
    "                optimizer_actor.step()\n",
    "    return\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
