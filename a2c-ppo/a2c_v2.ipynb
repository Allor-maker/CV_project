{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import namedtuple, deque\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import gymnasium\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import copy #Импортируем библиотеку для ранней остановки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-4 #скорость обучения CNN\n",
    "NUM_CLASSES = 10\n",
    "IMG_SIZE = 128\n",
    "NUM_IMAGES = 50000\n",
    "MAX_SUBSET_SIZE = 1000 #количество изображений в выборке\n",
    "CNN_EPOCHS = 2\n",
    "\n",
    "EPS_START = 0.9#стартовое значение epsilon для e-greedy стратегии\n",
    "EPS_END = 0.05#конечное значение\n",
    "EPS_DECAY = 200 #скорость изменения epsilon\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet():\n",
    "    def __init__(self):# 1. Параметры генератора\n",
    "        self.CELL_COUNT_RANGE = (1, 10)  # Количество клеток на изображение (минимум, максимум)\n",
    "        self.CELL_SIZE_RANGE = (5, 15)  # Диаметр клеток (минимум, максимум)\n",
    "        self.CELL_COLOR_RANGE = ((100, 0, 0), (255, 100, 100))  # Цвет клеток (минимум, максимум по BGR)\n",
    "        self.BACKGROUND_COLOR = (247, 131, 243)  # Розовый фон\n",
    "        self.OVERLAP_PROBABILITY = 0.1  # Вероятность перекрытия клетки с другой\n",
    "\n",
    "    def random_color(self, color_range):\n",
    "        \"\"\"Генерирует случайный цвет в заданном диапазоне.\"\"\"\n",
    "        return tuple(random.randint(color_range[0][i], color_range[1][i]) for i in range(3))\n",
    "\n",
    "    def generate_blood_cell_image(self):\n",
    "        \"\"\"Генерирует одно изображение с клетками крови.\"\"\"\n",
    "        image = Image.new(\"RGB\", (IMG_SIZE, IMG_SIZE), self.BACKGROUND_COLOR)\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        cell_count = random.randint(self.CELL_COUNT_RANGE[0], self.CELL_COUNT_RANGE[1])\n",
    "        cells = []  # Список координат и размеров клеток, чтобы отслеживать перекрытия\n",
    "\n",
    "        for _ in range(cell_count):\n",
    "            cell_size = random.randint(self.CELL_SIZE_RANGE[0], self.CELL_SIZE_RANGE[1])\n",
    "\n",
    "            # Попробуем найти позицию для клетки, чтобы избежать перекрытия (если OVERLAP_PROBABILITY низкая)\n",
    "            max_attempts = 100\n",
    "            for attempt in range(max_attempts):\n",
    "                x = random.randint(cell_size, IMG_SIZE - cell_size)\n",
    "                y = random.randint(cell_size, IMG_SIZE - cell_size)\n",
    "\n",
    "                # Проверяем, перекрывается ли новая клетка с существующими\n",
    "                overlap = False\n",
    "                if random.random() > self.OVERLAP_PROBABILITY: # Проверяем, нужно ли вообще проверять перекрытие\n",
    "                    for existing_x, existing_y, existing_size in cells:\n",
    "                        distance = np.sqrt((x - existing_x)**2 + (y - existing_y)**2)\n",
    "                        if distance < (cell_size + existing_size) * 0.7:  # Уменьшил коэфф. для допущения небольшого перекрытия\n",
    "                            overlap = True\n",
    "                            break\n",
    "\n",
    "                if not overlap:\n",
    "                    break # Нашли подходящую позицию\n",
    "\n",
    "            if overlap and attempt == max_attempts-1 :\n",
    "                #Если не нашли хорошую позицию, то игнорируем данную клетку\n",
    "                continue\n",
    "\n",
    "\n",
    "            cell_color = self.random_color(self.CELL_COLOR_RANGE)\n",
    "            draw.ellipse((x - cell_size, y - cell_size, x + cell_size, y + cell_size), fill=cell_color)\n",
    "            cells.append((x, y, cell_size))\n",
    "\n",
    "        return np.array(image), cell_count\n",
    "\n",
    "    def generate_dataset(self,num_images, output_dir=\"blood_cell_dataset\"):\n",
    "        \"\"\"Генерирует набор данных изображений и меток.\"\"\"\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        for i in range(num_images):\n",
    "            image, cell_count = self.generate_blood_cell_image()\n",
    "            images.append(image)\n",
    "            labels.append(cell_count) #label-1 to make 0 index\n",
    "\n",
    "            # Сохранение изображений (опционально)\n",
    "            #image_path = os.path.join(output_dir, f\"image_{i}.png\")\n",
    "           # cv2.imwrite(image_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))  # Convert to BGR for OpenCV\n",
    "\n",
    "        return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(subset, shuffle=True):\n",
    "    return DataLoader(subset, batch_size=BATCH_SIZE, shuffle=shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, batch):\n",
    "        return batch.reshape(batch.size(0), -1)\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.cv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.cv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.cv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "       # self.dropout = nn.Dropout(0.25) # Dropout\n",
    "        self.flatten = Flatten()\n",
    "        self.fc1 = nn.Linear(128 * (IMG_SIZE//8) * (IMG_SIZE//8), 128)\n",
    "        self.bn4 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.cv1(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn2(self.cv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn3(self.cv3(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "       # x = self.dropout(x)  # Применяем Dropout перед полносвязными слоями\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BloodCellDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        #self.images = [cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) for img in images]  # Преобразуем в градации серого\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        #image = np.expand_dims(image, axis=0)  # Добавляем канал (1, H, W)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        image = torch.tensor(image, dtype=torch.float32).permute(2,0,1) # Convert to float and permute\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreloading():\n",
    "    def __init__(self, num_samples=NUM_IMAGES):\n",
    "        self.dataset_generator = DataSet()\n",
    "        images, labels = self.dataset_generator.generate_dataset(num_samples)\n",
    "\n",
    "        self.dataset = BloodCellDataset(images, labels)\n",
    "    def get_train_data(self):\n",
    "        return self.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = DataPreloading(num_samples=100).get_train_data()\n",
    "# 5. Визуализация\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_data(images, labels, num_samples=5):\n",
    "    \"\"\"Визуализирует несколько случайных изображений из набора данных.\"\"\"\n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(15, 3))\n",
    "    for i in range(num_samples):\n",
    "        index = random.randint(0, len(images) - 1)\n",
    "        axes[i].imshow(images[index])\n",
    "        axes[i].set_title(f\"Cells: {labels[index]}\")\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "visualize_data(train_data.images, train_data.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, input_size, num_actions):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, num_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x), dim=-1)\n",
    "        return x\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSelectionEnv(gymnasium.Env):\n",
    "    def __init__(self):\n",
    "        super(DataSelectionEnv, self).__init__()\n",
    "        self.train_data = DataPreloading(num_samples=NUM_IMAGES).get_train_data()\n",
    "        self.model = SimpleCNN().to(DEVICE) \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.indexes = self.class_select()\n",
    "        self.optim = optim.Adam(self.model.parameters(), lr=LEARNING_RATE) #пробовал добавлять weight_decay\n",
    "\n",
    "        # Пространство действий: вероятности выбора изображений для каждого класса\n",
    "        self.action_space = gymnasium.spaces.Box(low=0, high=1, shape=(NUM_CLASSES,), dtype=np.float32)\n",
    "        self.observation_space = gymnasium.spaces.Box(low=0, high=1, shape=(NUM_CLASSES,), dtype=np.float32)\n",
    "\n",
    "        #validation set\n",
    "        self.validation_indices = random.sample(range(len(self.train_data)), int(0.2 * len(self.train_data)))\n",
    "        self.validation_subset = Subset(self.train_data, self.validation_indices)\n",
    "        self.validation_dataloader = get_dataloader(self.validation_subset, shuffle=False)\n",
    "\n",
    "    def class_select(self):#возвращаем словарь из индексов принадлежащим классам\n",
    "        ls = {i: [] for i in range(NUM_CLASSES)} #создали пустой словарь на 10 классов\n",
    "\n",
    "        for x, (image, label) in enumerate(self.train_data): #unpack both\n",
    "            label_value = label.item()-1 #значения меток начинаются с 1, а индексация с 0\n",
    "            ls[label_value].append(x) #индекс каждого изображения из train_data положили в нужный класс в зависимости от метки\n",
    "\n",
    "        return ls\n",
    "\n",
    "    def sample(self, action):#action - тензор распределения процентов изображений от каждого класса в выборке\n",
    "        action = np.clip(action, 0, 1) #clip the action\n",
    "        action = action / np.sum(action) #renormalize to ensure sum = 1\n",
    "        index = []\n",
    "\n",
    "        for i in range(NUM_CLASSES):\n",
    "            num_img = int(action[i] * MAX_SUBSET_SIZE) #определили количество изображений для i-го класса в выборке из batch_size изображений\n",
    "            indexes = np.random.choice(self.indexes[i], num_img, replace=True) #рандомно выбираем вычисленное количество изображений из изображений нужного класса, возвращаем их индексы\n",
    "            index.extend(indexes)#добавляем найденные индексы в выборку\n",
    "\n",
    "        return Subset(self.train_data, index)#состовляем subset\n",
    "\n",
    "    def step(self, action,weights):\n",
    "        # в этой функции мы создаем выборку на основе action и проверяем, насколько улучшилось или ухудшилось предсказание сети\n",
    "        #action = np.clip(action + np.random.uniform(-0.05, 0.05, size=action.shape), 0, 1)\n",
    "        train_subset = self.sample(action) #subset - выбранное случайное подмножество из 32 элементов на основе распределения action\n",
    "        train_dataloader = get_dataloader(train_subset) #создали dataloader, выдающий этот batch из 32 элементов\n",
    "        #prev_acc, _ = self.evaluate(test_dataloader) #вычиляем текущую точность модели на тестовой выборке\n",
    "        self.train_model(train_dataloader, epochs=CNN_EPOCHS) #тренируем модель на тренировчной выборке\n",
    "        _, err_per_cl = self.evaluate(self.validation_dataloader)  # Теперь возвращается точность по классам\n",
    "        \n",
    "        reward = np.sum([(1- err_per_cl[i])*weights[i] for i in range(NUM_CLASSES)])\n",
    "        #reward = new_acc - self.last_acc #Предыдущая награда\n",
    "\n",
    "        return reward, err_per_cl\n",
    "\n",
    "    def train_model(self, dataloader, epochs=1):\n",
    "        # на вход приходит dataloader выдающий batch изображений и ответов к ним\n",
    "        self.model.train()#Необходимо переводить в train\n",
    "        for epoch in range(epochs):\n",
    "            for images, labels in dataloader:\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "                \n",
    "                self.optim.zero_grad() #обновили optimizer\n",
    "                output = self.model(images) #получили тензор(batch_size, NUM_CLASSES) с распределением вероятностей для каждого изображения\n",
    "                \n",
    "                loss = self.criterion(output, labels-1) #вычислили ошибку с помощью CrossEntropyLoss\\\n",
    "                print(\"loss = \", loss)\n",
    "                loss.backward()\n",
    "                self.optim.step()\n",
    "\n",
    "\n",
    "\n",
    "    def evaluate(self, dataloader):\n",
    "        self.model.eval()  # Переводим модель в оценочный режим\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        ls = torch.zeros(NUM_CLASSES, dtype=torch.int64, device=DEVICE)\n",
    "        ers = torch.zeros(NUM_CLASSES, dtype=torch.int64, device=DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in dataloader:\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "                output = self.model(images)  # Получили тензор(batch_size,NUM_CLASSES)\n",
    "                predicted = torch.argmax(output, dim=1)+1  # Получили тезор(batch_size)\n",
    "                correct += (predicted == labels).sum().item()  # Нашли количество правильных ответов\n",
    "                total += labels.size(0) \n",
    "\n",
    "                # Обновляем ls и ers\n",
    "                for i in range(NUM_CLASSES):\n",
    "                    ls[i] += (labels == i+1).sum()\n",
    "                    ers[i] += ((labels == i+1) & (predicted != labels)).sum()\n",
    "\n",
    "        # Вычисляем error_per_class, обрабатывая деление на ноль\n",
    "        error_per_class = [(ers[i].float() / ls[i].float()).item() if ls[i] > 0 else 0 for i in range(NUM_CLASSES)]\n",
    "\n",
    "        accuracy = (correct / total) if total > 0 else 0  # Находим точность на данной выборке\n",
    "        print(\"accuracy = \", accuracy)\n",
    "        return accuracy, error_per_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',('state','action','next_state','reward'))\n",
    "\n",
    "class replay_memory(object):\n",
    "    def __init__(self,capacity):\n",
    "        self.memory = deque([],maxlen=capacity)\n",
    "    def push(self,*args):\n",
    "        self.memory.append(Transition(*args))\n",
    "    def sample(self,batch_size):\n",
    "        return random.sample(self.memory,batch_size)\n",
    "    def __len__(self):\n",
    "        return len(self.memory)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.profiler as profiler\n",
    "prof = profiler.profile(\n",
    "    schedule=profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler('./log'),\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,\n",
    "    with_stack=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_values(error_per_class):#функция для вычисления весов классов по ошибке на них\n",
    "    \"\"\"Вычисляет ценность классов на основе ошибок.\"\"\"\n",
    "    class_values = [min(1.0 / (1 - error + 1e-6), 10) for error in error_per_class]  # Избегаем деления на 0\n",
    "    return class_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actor_critic(env, actor, critic, episodes=10, max_steps=100, gamma=0.99, lr_actor=1e-2, lr_critic=1e-2):\n",
    "    optimizer_actor = optim.AdamW(actor.parameters(), lr=lr_actor)\n",
    "    optimizer_critic = optim.AdamW(critic.parameters(), lr=lr_critic)\n",
    "\n",
    "    actor.to(DEVICE)\n",
    "    critic.to(DEVICE)\n",
    "    memory = replay_memory(10000)\n",
    "    # Create test set outside the loop for consistency\n",
    "    test_dataset = DataPreloading().get_train_data()  # Get the full training data\n",
    "    test_indices = random.sample(range(len(test_dataset)), int(0.2 * len(test_dataset)))  # 20% for test\n",
    "    test_subset = Subset(test_dataset, test_indices)\n",
    "    test_dataloader = get_dataloader(test_subset, shuffle=False)\n",
    "\n",
    "    steps_done = 0\n",
    "    best_val_accuracy = float('-inf')  # Начальное значение (отрицательная бесконечность)\n",
    "    patience = 30  # Окно терпения (количество шагов без улучшений)\n",
    "    counter = 0  # Счетчик эпох без улучшений\n",
    "    best_model_state = None #Сохраняем модель с наилучшей точностью\n",
    "    with prof:\n",
    "        for episode in range(episodes):\n",
    "            state = np.ones(NUM_CLASSES) / NUM_CLASSES #массив ошибок по классам\n",
    "            action = np.zeros(NUM_CLASSES) #распределение процентов количества изображений из каждого класса в выборке\n",
    "            state_tensor = torch.FloatTensor(state).to(DEVICE)\n",
    "            step = 0\n",
    "            while step < max_steps:\n",
    "                step += 1\n",
    "                steps_done += 1  # Увеличиваем steps_done здесь, до использования\n",
    "\n",
    "                print(f\"Episode: {episode+1}, Step: {step}, State: {state}\")\n",
    "                weights = calculate_class_values(state)\n",
    "                print(\"weights\",weights)\n",
    "                epsilon = EPS_END + (EPS_START - EPS_END)*math.exp(-1*steps_done/EPS_DECAY)\n",
    "                print(f\"Episode: {episode+1}, Step: {step}, Epsilon: {epsilon:.4f}\")\n",
    "                #выбираем действие\n",
    "                if np.random.rand() < epsilon:\n",
    "                    action = np.random.dirichlet(np.ones(NUM_CLASSES))\n",
    "                    action_source = \"случайное\"\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        action_probabilities = actor(state_tensor)\n",
    "                        action = action_probabilities.cpu().numpy()\n",
    "                    action_source = \"агент\"\n",
    "                print(f\"Episode: {episode+1}, Step: {step}, Action: {action}, Действие: {action_source}\") #Добавлено action_source\n",
    "\n",
    "                reward, next_state = env.step(action, weights)\n",
    "                print(f\"Reward: {reward:.4f}\") \n",
    "                next_state_tensor = torch.FloatTensor(next_state).to(DEVICE)\n",
    "\n",
    "                reward_tensor = torch.tensor([reward], dtype=torch.float32).to(DEVICE) # Преобразуем награду в тензор\n",
    "\n",
    "                #Сохраняем переход в буфер\n",
    "                memory.push(state_tensor, torch.tensor(action, dtype=torch.float32).to(DEVICE), next_state_tensor, reward_tensor)\n",
    "\n",
    "                if len(memory) > 0:  # Начинаем обучение, как только в буфере что-то появится\n",
    "                    batch_size = min(len(memory), BATCH_SIZE)  # Размер мини-батча зависит от заполненности буфера\n",
    "                    transitions = memory.sample(batch_size)\n",
    "                    batch = Transition(*zip(*transitions))\n",
    "\n",
    "                    state_batch = torch.stack(batch.state) #преобразование списка состояний в один тензон (batch_size,NUM_CLASSES)\n",
    "                    action_batch = torch.stack(batch.action)\n",
    "                    reward_batch = torch.cat(batch.reward)\n",
    "                    next_state_batch = torch.stack(batch.next_state)\n",
    "\n",
    "                    #Обучаем critic\n",
    "                    value = critic(state_batch)#тензор размера (batch_size) оценок критика для батча состояний\n",
    "                    next_value = critic(next_state_batch)#аналогично тензор (batch_size) оценок следующих состояний\n",
    "                    advantage = reward_batch + (gamma * next_value.squeeze()) - value.squeeze() #advatnage - тензор размера batch_size\n",
    "                    loss_critic = advantage.pow(2).mean()#берем среднее\n",
    "\n",
    "                    #Вычисляем параметры actor\n",
    "                    with torch.no_grad():\n",
    "                        td_target = reward_batch + gamma * critic(next_state_batch)\n",
    "                        delta = td_target - critic(state_batch)\n",
    "                        \n",
    "                    action_probabilities = actor(state_batch) #пропускаем через actor batch состояний, получаем тензор (batch_size, NUM_CLASSES)\n",
    "                    log_prob = F.log_softmax(action_probabilities, dim=1) #вычиляем логарифмы вероятностей действий, размерность все еще (batch_size, NUM_CLASSES)\n",
    "\n",
    "                    # Собираем log_prob для выбранных действий\n",
    "                    log_prob_actions = log_prob.gather(1, action_batch.argmax(dim=1,keepdim=True).long())#Собираем логарифмы вероятностей только для тех действий, которые были фактически предприняты (и сохранены в action_batch). \n",
    "                    #log_prob_actions - это тензор размера (batch_size).\n",
    "\n",
    "                    loss_actor = -log_prob_actions * delta.unsqueeze(1) #Исправлено\n",
    "                    loss_actor = loss_actor.mean()\n",
    "\n",
    "                    entropy_bonus = -torch.sum(action_probabilities * torch.log(action_probabilities + 1e-6))\n",
    "                    loss_actor += 0.01 * entropy_bonus\n",
    "\n",
    "                    optimizer_actor.zero_grad()\n",
    "                    loss_actor.backward()\n",
    "                    optimizer_actor.step()\n",
    "\n",
    "                    optimizer_critic.zero_grad()\n",
    "                    loss_critic.backward()\n",
    "                    optimizer_critic.step()\n",
    "                env.model.train()\n",
    "                state = next_state\n",
    "                state_tensor = next_state_tensor\n",
    "\n",
    "                if step % 10 == 0:\n",
    "                    env.model.eval()\n",
    "                    accuracy, _ = env.evaluate(test_dataloader)\n",
    "                    print(f\"--------------------------------------\")\n",
    "                    print(f\"Episode: {episode+1}, Step: {step}, Test Accuracy: {accuracy:.4f}\")\n",
    "                    print(f\"--------------------------------------\")\n",
    "\n",
    "                    if accuracy > best_val_accuracy:\n",
    "                        best_val_accuracy = accuracy\n",
    "                        counter = 0  # Сбрасываем счетчик\n",
    "                        best_model_state = {\n",
    "                            'actor_state_dict': copy.deepcopy(actor.state_dict()), #Сохраняем лучшие веса\n",
    "                            'critic_state_dict': copy.deepcopy(critic.state_dict()),\n",
    "                            'actor_optimizer_state_dict': copy.deepcopy(optimizer_actor.state_dict()),\n",
    "                            'critic_optimizer_state_dict': copy.deepcopy(optimizer_critic.state_dict()),\n",
    "                            'cnn_state_dict': copy.deepcopy(env.model.state_dict()),#Сохраняем лучшие веса\n",
    "                            'steps_done': steps_done,\n",
    "                            'epsilon': epsilon\n",
    "                        }\n",
    "                        print(f\"Новая лучшая точность: {best_val_accuracy:.4f}\")\n",
    "                    else:\n",
    "                        counter += 1  # Увеличиваем счетчик\n",
    "\n",
    "                if counter >= patience:\n",
    "                    print(f\"Ранняя остановка! Нет улучшений в течение {patience} шагов.\")\n",
    "      \n",
    "                    actor.load_state_dict(best_model_state['actor_state_dict'])\n",
    "                    critic.load_state_dict(best_model_state['critic_state_dict'])\n",
    "                    optimizer_actor.load_state_dict(best_model_state['actor_optimizer_state_dict'])\n",
    "                    optimizer_critic.load_state_dict(best_model_state['critic_optimizer_state_dict'])\n",
    "                    env.model.load_state_dict(best_model_state['cnn_state_dict'])\n",
    "                    steps_done = best_model_state['steps_done']\n",
    "                    epsilon = best_model_state['epsilon']\n",
    "\n",
    "                    break  # Выходим из цикла while\n",
    "            if best_model_state is not None:\n",
    "                print(\"Восстанавливаем лучшее состояние модели...\")\n",
    "                actor.load_state_dict(best_model_state['actor_state_dict'])\n",
    "                critic.load_state_dict(best_model_state['critic_state_dict'])\n",
    "                optimizer_actor.load_state_dict(best_model_state['actor_optimizer_state_dict'])\n",
    "                optimizer_critic.load_state_dict(best_model_state['critic_optimizer_state_dict'])\n",
    "                env.model.load_state_dict(best_model_state['cnn_state_dict'])\n",
    "                steps_done = best_model_state['steps_done']\n",
    "                epsilon = best_model_state['epsilon']\n",
    "    env.model.eval()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 1, State: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "weights [np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815)]\n",
      "Episode: 1, Step: 1, Epsilon: 0.8958\n",
      "Episode: 1, Step: 1, Action: [0.07939264 0.31243985 0.00717113 0.19001755 0.18106087 0.0302771\n",
      " 0.05904087 0.01683785 0.04090358 0.08285857], Действие: случайное\n",
      "loss =  tensor(2.2966, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9427, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7914, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6072, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6370, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7327, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7167, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6161, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4185, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3243, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3703, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3448, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2915, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3632, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3632, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3547, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2683\n",
      "Reward: 2.9700\n",
      "Episode: 1, Step: 2, State: [1.0, 0.02182539738714695, 1.0, 0.6877431869506836, 0.5287008881568909, 0.8925372958183289, 0.9959390759468079, 1.0, 0.9894179701805115, 0.21084336936473846]\n",
      "weights [10, 1.0223113286907286, 10, 3.202481917856977, 2.121790287910837, 9.30546743772637, 10, 10, 10, 1.2671739601567473]\n",
      "Episode: 1, Step: 2, Epsilon: 0.8915\n",
      "Episode: 1, Step: 2, Action: [0.06689988 0.0656213  0.19733934 0.2092304  0.01248787 0.04603842\n",
      " 0.08596729 0.05540309 0.15102188 0.10999053], Действие: случайное\n",
      "loss =  tensor(2.0582, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.1282, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.1250, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0841, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.1243, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0326, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0275, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0178, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8834, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8427, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8340, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8438, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6996, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7387, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7048, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7528, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1908\n",
      "Reward: 6.3499\n",
      "Episode: 1, Step: 3, State: [1.0, 0.0, 1.0, 0.9970816969871521, 0.9466263651847839, 0.9582089781761169, 0.9939086437225342, 1.0, 0.5746031999588013, 0.6044176816940308]\n",
      "weights [10, 0.9999990000010001, 10, 10, 10, 10, 10, 10, 2.350740882776433, 2.527912461734639]\n",
      "Episode: 1, Step: 3, Epsilon: 0.8873\n",
      "Episode: 1, Step: 3, Action: [0.06987025 0.15414545 0.11459289 0.15693265 0.08948245 0.08015705\n",
      " 0.07208747 0.07128913 0.08981344 0.10162915], Действие: агент\n",
      "loss =  tensor(1.8266, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8865, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8470, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8264, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7631, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7634, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7773, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8388, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7566, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6691, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7523, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6334, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6353, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6685, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5790, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5953, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2626\n",
      "Reward: 11.6518\n",
      "Episode: 1, Step: 4, State: [0.9702495336532593, 0.0783730149269104, 0.919881284236908, 0.6935797929763794, 0.9284995198249817, 0.8119403123855591, 0.9512690305709839, 0.8571428656578064, 0.4137566089630127, 0.7319276928901672]\n",
      "weights [10, 1.0850364964999355, 10, 3.263481694734381, 10, 5.317432434630806, 10, 6.999951417569695, 1.7057732496700475, 3.7303229134644442]\n",
      "Episode: 1, Step: 4, Epsilon: 0.8832\n",
      "Episode: 1, Step: 4, Action: [0.01196111 0.11387601 0.17990465 0.08468644 0.07346792 0.06201768\n",
      " 0.1730362  0.0588196  0.03420833 0.20802205], Действие: случайное\n",
      "loss =  tensor(1.8164, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8507, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9244, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8155, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8249, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7277, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8630, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8256, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7265, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6495, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6535, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6036, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6636, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6029, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5301, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5913, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.213\n",
      "Reward: 6.4401\n",
      "Episode: 1, Step: 5, State: [0.9884836673736572, 0.1378968209028244, 0.97230464220047, 0.8920233249664307, 0.9889224767684937, 0.9522387981414795, 0.930964469909668, 0.9929078221321106, 1.0, 0.0200803205370903]\n",
      "weights [10, 1.1599526185422666, 10, 9.26117366102862, 10, 10, 10, 10, 10, 1.02049076109721]\n",
      "Episode: 1, Step: 5, Epsilon: 0.8790\n",
      "Episode: 1, Step: 5, Action: [8.76549554e-02 2.00076752e-02 9.62691385e-03 1.17305647e-01\n",
      " 2.63976421e-01 3.09475057e-01 1.15197726e-01 2.07018144e-04\n",
      " 3.92457764e-02 3.73028094e-02], Действие: случайное\n",
      "loss =  tensor(2.1957, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.1790, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0777, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.1871, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.1733, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.1484, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0592, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0614, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9202, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8994, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8721, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7871, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8102, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8082, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7480, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7193, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1766\n",
      "Reward: 5.4997\n",
      "Episode: 1, Step: 6, State: [1.0, 0.072420634329319, 0.888229489326477, 0.9902724027633667, 0.9577039480209351, 0.8995025157928467, 0.876142144203186, 1.0, 0.9894179701805115, 0.5652610659599304]\n",
      "weights [10, 1.0780737033787433, 8.946823693927987, 10, 10, 9.950398833267394, 8.073706103344474, 10, 10, 2.3002257710878498]\n",
      "Episode: 1, Step: 6, Epsilon: 0.8749\n",
      "Episode: 1, Step: 6, Action: [0.04199132 0.15068609 0.07047538 0.39567286 0.05468425 0.04689612\n",
      " 0.04155343 0.04980817 0.06823935 0.07999311], Действие: агент\n",
      "loss =  tensor(1.8181, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8025, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9183, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7552, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8903, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8039, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7852, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7939, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6522, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6397, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6251, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5587, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6343, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5587, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4948, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5292, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2586\n",
      "Reward: 23.9673\n",
      "Episode: 1, Step: 7, State: [0.09309021383523941, 0.9553571343421936, 0.6834816932678223, 0.31128403544425964, 0.7824773192405701, 0.9243780970573425, 0.9908629655838013, 0.9979736804962158, 0.8084656000137329, 0.9156626462936401]\n",
      "weights [1.102644290105871, 10, 3.1593649383484474, 1.4519752691805028, 4.597200619761252, 10, 10, 10, 5.2209669861117005, 10]\n",
      "Episode: 1, Step: 7, Epsilon: 0.8708\n",
      "Episode: 1, Step: 7, Action: [0.09897365 0.00559233 0.07355409 0.01426304 0.0201927  0.15521807\n",
      " 0.02055477 0.02313544 0.50834135 0.08017457], Действие: случайное\n",
      "loss =  tensor(2.1074, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0115, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9470, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0126, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0858, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9778, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0027, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9739, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7230, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8247, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6771, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6255, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7366, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6328, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5389, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7621, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2277\n",
      "Reward: 12.2074\n",
      "Episode: 1, Step: 8, State: [0.33109405636787415, 0.25, 0.9920870661735535, 0.8667315244674683, 1.0, 1.0, 1.0, 1.0, 0.28148147463798523, 1.0]\n",
      "weights [1.4949762586856372, 1.333331555557926, 10, 7.503593722449182, 10, 10, 10, 10, 1.391750627091401, 10]\n",
      "Episode: 1, Step: 8, Epsilon: 0.8667\n",
      "Episode: 1, Step: 8, Action: [0.17734423 0.01911162 0.18021245 0.0878505  0.15531358 0.02568506\n",
      " 0.22032408 0.04455332 0.00944767 0.08015748], Действие: случайное\n",
      "loss =  tensor(1.9056, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9916, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9212, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8328, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8201, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7867, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8297, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8721, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6720, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7140, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6012, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6423, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5752, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5892, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6555, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6147, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3161\n",
      "Reward: 18.9478\n",
      "Episode: 1, Step: 9, State: [0.021113242954015732, 0.6567460298538208, 0.7566765546798706, 0.7344357967376709, 0.5931520462036133, 0.9761193990707397, 0.6751269102096558, 0.9929078221321106, 0.9682539701461792, 0.5070281028747559]\n",
      "weights [1.0215675830063773, 2.913286294366366, 4.109739153763822, 3.7655535729663567, 2.45791464047973, 10, 3.078115588243263, 10, 10, 2.0285090840317355]\n",
      "Episode: 1, Step: 9, Epsilon: 0.8626\n",
      "Episode: 1, Step: 9, Action: [0.02216401 0.08691456 0.04017419 0.64766544 0.02552292 0.02929893\n",
      " 0.02283031 0.02767677 0.03692409 0.06082877], Действие: агент\n",
      "loss =  tensor(1.9075, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8253, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8738, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8275, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7900, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7290, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7984, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8093, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6280, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6896, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5972, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5683, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5390, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4685, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4632, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5033, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3006\n",
      "Reward: 9.0342\n",
      "Episode: 1, Step: 10, State: [0.0, 1.0, 0.9020771384239197, 0.32295718789100647, 0.9244713187217712, 0.9054726362228394, 0.9614213109016418, 0.9219858050346375, 0.8476190567016602, 0.25702810287475586]\n",
      "weights [0.9999990000010001, 10, 10, 1.477009289672107, 10, 10, 10, 10, 6.562457325026743, 1.3459441170320758]\n",
      "Episode: 1, Step: 10, Epsilon: 0.8585\n",
      "Episode: 1, Step: 10, Action: [0.05001566 0.09527997 0.01700978 0.04336889 0.02858924 0.24379585\n",
      " 0.04063843 0.13757038 0.29637669 0.04735511], Действие: случайное\n",
      "loss =  tensor(1.9689, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9633, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0047, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8958, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8262, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9351, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9123, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8166, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7201, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8397, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7014, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7134, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5987, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6954, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6787, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6686, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2505\n",
      "Reward: 9.5241\n",
      "accuracy =  0.237\n",
      "--------------------------------------\n",
      "Episode: 1, Step: 10, Test Accuracy: 0.2370\n",
      "--------------------------------------\n",
      "Новая лучшая точность: 0.2370\n",
      "Episode: 1, Step: 11, State: [0.0191938579082489, 0.9305555820465088, 0.8031651973724365, 0.5369649529457092, 1.0, 0.9691542387008667, 1.0, 0.9979736804962158, 0.25925925374031067, 0.9949799180030823]\n",
      "weights [1.0195684320439558, 10, 5.080376570984486, 2.1596590726828455, 10, 10, 10, 10, 1.3499981674442036, 10]\n",
      "Episode: 1, Step: 11, Epsilon: 0.8545\n",
      "Episode: 1, Step: 11, Action: [0.0343963  0.18322068 0.18333298 0.09679254 0.03873168 0.052175\n",
      " 0.07203342 0.08417775 0.15545544 0.0996842 ], Действие: случайное\n",
      "loss =  tensor(1.7169, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5960, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7498, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6899, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6451, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6400, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5970, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6615, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5473, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4859, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5120, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4181, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5262, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4870, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4584, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4677, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1789\n",
      "Reward: 11.0179\n",
      "Episode: 1, Step: 12, State: [0.9587332010269165, 0.2579365074634552, 0.7863501310348511, 0.41731518507003784, 0.9979858994483948, 0.93034827709198, 0.9989847540855408, 0.9979736804962158, 0.9238095283508301, 0.9638554453849792]\n",
      "weights [10, 1.3475917660226175, 4.680533268334713, 1.716190740150759, 10, 10, 10, 10, 10, 10]\n",
      "Episode: 1, Step: 12, Epsilon: 0.8505\n",
      "Episode: 1, Step: 12, Action: [0.02403396 0.13266342 0.16705656 0.05600986 0.10679548 0.07837827\n",
      " 0.25225432 0.09117599 0.07494008 0.01669206], Действие: случайное\n",
      "loss =  tensor(1.7823, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8122, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8053, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8707, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8655, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7601, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9058, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8245, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6451, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6696, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6219, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5576, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5587, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4803, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5145, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4580, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1491\n",
      "Reward: 4.8830\n",
      "Episode: 1, Step: 13, State: [1.0, 0.0367063507437706, 0.8724035620689392, 0.8900778293609619, 0.9486404657363892, 0.9014925360679626, 0.8741116523742676, 0.9979736804962158, 0.9978836178779602, 1.0]\n",
      "weights [10, 1.038103970339824, 7.837147957001196, 9.097263062796518, 10, 10, 7.943483851969655, 10, 10, 10]\n",
      "Episode: 1, Step: 13, Epsilon: 0.8465\n",
      "Episode: 1, Step: 13, Action: [0.04336109 0.03981298 0.01304942 0.11878721 0.04269399 0.04766414\n",
      " 0.08502893 0.32779277 0.08639904 0.19541042], Действие: случайное\n",
      "loss =  tensor(2.2209, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.1795, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0814, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0131, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0125, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9300, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.1327, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8249, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7013, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8079, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6407, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6404, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6567, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5498, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5265, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1336\n",
      "Reward: 5.4212\n",
      "Episode: 1, Step: 14, State: [0.7120921015739441, 0.1726190447807312, 0.8516320586204529, 0.9980545043945312, 1.0, 1.0, 0.9989847540855408, 0.9706180095672607, 1.0, 0.9799196720123291]\n",
      "weights [3.4733209201480504, 1.2086316285868053, 6.73995507888588, 10, 10, 10, 10, 10, 10, 10]\n",
      "Episode: 1, Step: 14, Epsilon: 0.8425\n",
      "Episode: 1, Step: 14, Action: [0.02337554 0.00514192 0.19411894 0.20011619 0.06291159 0.09515247\n",
      " 0.00950939 0.20465475 0.08366385 0.12135536], Действие: случайное\n",
      "loss =  tensor(1.6728, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7189, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7227, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6996, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6865, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6789, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6786, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5883, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4762, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4463, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3914, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3832, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4089, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3434, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3384, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3887, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1606\n",
      "Reward: 13.1588\n",
      "Episode: 1, Step: 15, State: [0.9836851954460144, 0.9126983880996704, 0.39366963505744934, 0.7966926097869873, 0.9979858994483948, 1.0, 0.9969543218612671, 0.4407294690608978, 0.9830687642097473, 0.8935742974281311]\n",
      "weights [10, 10, 1.6492631881162028, 4.918636161312714, 10, 10, 10, 1.7880402356988339, 10, 9.396138147986967]\n",
      "Episode: 1, Step: 15, Epsilon: 0.8386\n",
      "Episode: 1, Step: 15, Action: [0.04113267 0.04980214 0.30839334 0.01883699 0.13580147 0.05818356\n",
      " 0.02204151 0.04719824 0.12003148 0.1985786 ], Действие: случайное\n",
      "loss =  tensor(1.6596, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5870, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6632, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7121, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5252, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5747, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6839, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5736, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5171, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4413, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4465, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3950, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4052, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4691, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2951, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3722, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.29\n",
      "Reward: 17.6461\n",
      "Episode: 1, Step: 16, State: [1.0, 0.9384920597076416, 0.24035608768463135, 0.6167315244674683, 0.6817724108695984, 0.9084576964378357, 0.9817258715629578, 0.7041540145874023, 0.9576719403266907, 0.07831325381994247]\n",
      "weights [10, 10, 1.3164045250458378, 2.6091302956243916, 3.1423952283250913, 10, 10, 3.3801257045271837, 10, 1.084966144059643]\n",
      "Episode: 1, Step: 16, Epsilon: 0.8346\n",
      "Episode: 1, Step: 16, Action: [0.11868267 0.05696383 0.0157766  0.16671147 0.31862886 0.06490492\n",
      " 0.02985495 0.10325892 0.07773829 0.04747949], Действие: случайное\n",
      "loss =  tensor(1.8371, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8298, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9061, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8675, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9018, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7608, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7140, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8495, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5923, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5851, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6711, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5913, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5679, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5569, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5377, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5703, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2985\n",
      "Reward: 16.2718\n",
      "Episode: 1, Step: 17, State: [0.9232245683670044, 0.976190447807312, 0.09396637231111526, 0.8190661668777466, 0.7069486379623413, 0.6577114462852478, 0.9868020415306091, 0.7507598996162415, 0.18412698805332184, 0.8855421543121338]\n",
      "weights [10, 10, 1.1037105751143335, 5.5268517550975025, 3.4123594604280827, 2.9215031225678376, 10, 4.012179365523149, 1.2256794374587279, 8.736764677210179]\n",
      "Episode: 1, Step: 17, Epsilon: 0.8307\n",
      "Episode: 1, Step: 17, Action: [0.06336703 0.06305224 0.03984146 0.01795182 0.32092423 0.21385066\n",
      " 0.02555427 0.01221548 0.05022565 0.19301716], Действие: случайное\n",
      "loss =  tensor(1.8765, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7472, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6759, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7025, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6893, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6144, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7860, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7283, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6014, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5096, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5405, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4653, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4933, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3985, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4639, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3813, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3563\n",
      "Reward: 22.2719\n",
      "Episode: 1, Step: 18, State: [0.020153550431132317, 0.9890872836112976, 0.29772502183914185, 0.8715953230857849, 0.6384692788124084, 0.6597014665603638, 1.0, 1.0, 0.9978836178779602, 0.01004016026854515]\n",
      "weights [1.0205670285104067, 10, 1.4239416285017046, 7.787817673108622, 2.7660090149630885, 2.9385876315854085, 10, 10, 10, 1.0101409670621602]\n",
      "Episode: 1, Step: 18, Epsilon: 0.8268\n",
      "Episode: 1, Step: 18, Action: [0.10260379 0.17188813 0.16165231 0.03359359 0.05731429 0.1420721\n",
      " 0.13564197 0.03292798 0.01829691 0.14400893], Действие: случайное\n",
      "loss =  tensor(1.6072, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6260, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5527, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5892, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6565, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6443, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6288, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6454, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4605, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3991, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4665, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4519, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4049, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3978, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4120, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3986, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3799\n",
      "Reward: 11.3372\n",
      "Episode: 1, Step: 19, State: [0.2476007640361786, 0.6111111044883728, 0.4807121753692627, 0.7597275972366333, 0.365558922290802, 0.5870646834373474, 0.9746192693710327, 0.9959473013877869, 0.9978836178779602, 0.22188754379749298]\n",
      "weights [1.329079859629502, 2.571421915409735, 1.9257106114522935, 4.161925491956553, 1.5761880164233977, 2.4216809224341387, 10, 10, 10, 1.285159628109228]\n",
      "Episode: 1, Step: 19, Epsilon: 0.8230\n",
      "Episode: 1, Step: 19, Action: [0.00496176 0.18312367 0.00972871 0.19603773 0.23997978 0.02180801\n",
      " 0.13423609 0.03388983 0.13239156 0.04384285], Действие: случайное\n",
      "loss =  tensor(1.7689, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7159, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7850, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6760, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7214, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6662, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5882, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6340, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5156, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3782, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4330, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3010, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3627, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2706, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3478, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3770, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1002\n",
      "Reward: 1.6430\n",
      "Episode: 1, Step: 20, State: [0.0988483652472496, 0.9801587462425232, 0.9930761456489563, 1.0, 1.0, 1.0, 1.0, 1.0, 0.961904764175415, 1.0]\n",
      "weights [1.1096899253636099, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "Episode: 1, Step: 20, Epsilon: 0.8191\n",
      "Episode: 1, Step: 20, Action: [0.08161745 0.06188084 0.10039509 0.06710935 0.0426357  0.02964095\n",
      " 0.1686936  0.08386503 0.20312685 0.16103514], Действие: случайное\n",
      "loss =  tensor(1.8188, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9845, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8006, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7116, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7584, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8267, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6499, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6476, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5719, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5330, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4609, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5683, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5125, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4691, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5145, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4781, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2239\n",
      "Reward: 22.6159\n",
      "accuracy =  0.2211\n",
      "--------------------------------------\n",
      "Episode: 1, Step: 20, Test Accuracy: 0.2211\n",
      "--------------------------------------\n",
      "Episode: 1, Step: 21, State: [0.9769673943519592, 0.0009920635493472219, 0.9960435032844543, 0.9912451505661011, 0.8519637584686279, 1.0, 0.9939086437225342, 0.9736575484275818, 0.08677248656749725, 0.8463855385780334]\n",
      "weights [10, 1.0009920467307012, 10, 10, 6.755056968472895, 10, 10, 10, 1.0950161819207265, 6.509761392136814]\n",
      "Episode: 1, Step: 21, Epsilon: 0.8153\n",
      "Episode: 1, Step: 21, Action: [0.04377055 0.06988781 0.08527955 0.07290738 0.11070403 0.13224121\n",
      " 0.01119417 0.04211639 0.09357931 0.3383196 ], Действие: случайное\n",
      "loss =  tensor(1.5109, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6601, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6112, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4997, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5062, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4846, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5223, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4411, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4503, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3672, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3879, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3293, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3354, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3045, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2600, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1997, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2663\n",
      "Reward: 17.4028\n",
      "Episode: 1, Step: 22, State: [0.2879078686237335, 0.44841268658638, 0.9525222778320312, 0.9124513864517212, 0.8982880115509033, 0.9004974961280823, 0.9857867956161499, 0.9939209818840027, 0.9841269850730896, 0.005020080134272575]\n",
      "weights [1.4043106946801946, 1.8129463146368896, 10, 10, 9.831586066320924, 10, 10, 10, 10, 1.0050443983739406]\n",
      "Episode: 1, Step: 22, Epsilon: 0.8115\n",
      "Episode: 1, Step: 22, Action: [0.22308166 0.04394953 0.16539808 0.26615095 0.00629478 0.0447464\n",
      " 0.03783515 0.0152396  0.05994541 0.13735844], Действие: случайное\n",
      "loss =  tensor(1.5899, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6684, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5254, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6332, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5495, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5873, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6049, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5182, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2975, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4400, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4073, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2735, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3730, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3263, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2766, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3339, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2896\n",
      "Reward: 20.6484\n",
      "Episode: 1, Step: 23, State: [0.40211132168769836, 0.9216269850730896, 0.8625123500823975, 0.4912451505661011, 0.4753272831439972, 0.44079601764678955, 0.9807106852531433, 0.996960461139679, 0.8010581731796265, 0.7600401639938354]\n",
      "weights [1.6725493619872462, 10, 7.273327657223369, 1.9655793660411307, 1.905946434657124, 1.788253022696372, 10, 10, 5.026569773751657, 4.167346708086607]\n",
      "Episode: 1, Step: 23, Epsilon: 0.8077\n",
      "Episode: 1, Step: 23, Action: [0.08167122 0.10805334 0.02880034 0.44186047 0.13539127 0.03436733\n",
      " 0.00594052 0.01976416 0.1098552  0.03429614], Действие: случайное\n",
      "loss =  tensor(1.5980, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5750, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5827, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6205, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6101, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5522, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5683, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4327, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4797, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3707, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4116, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3989, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3283, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3482, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2515, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2298, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3475\n",
      "Reward: 9.8606\n",
      "Episode: 1, Step: 24, State: [0.0, 1.0, 0.9188922047615051, 0.2655642032623291, 0.34340381622314453, 0.9641790986061096, 0.9989847540855408, 0.9959473013877869, 0.05820105969905853, 0.986947774887085]\n",
      "weights [0.9999990000010001, 10, 10, 1.361587551770209, 1.5230037909206902, 10, 10, 10, 1.0617966270845816, 10]\n",
      "Episode: 1, Step: 24, Epsilon: 0.8039\n",
      "Episode: 1, Step: 24, Action: [0.01569665 0.03562396 0.04031424 0.22031846 0.17281307 0.04385877\n",
      " 0.01980069 0.03721954 0.32700868 0.08734593], Действие: случайное\n",
      "loss =  tensor(1.7847, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7297, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7322, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8302, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7111, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5919, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6172, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4865, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5505, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4018, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4080, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3223, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3801, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2736, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3763, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.205\n",
      "Reward: 2.8348\n",
      "Episode: 1, Step: 25, State: [0.0, 0.9990079402923584, 1.0, 0.9912451505661011, 0.9879153966903687, 1.0, 0.9989847540855408, 1.0, 0.03809523954987526, 0.9236947894096375]\n",
      "weights [0.9999990000010001, 10, 10, 10, 10, 10, 10, 10, 1.039602881192903, 10]\n",
      "Episode: 1, Step: 25, Epsilon: 0.8001\n",
      "Episode: 1, Step: 25, Action: [0.1039673  0.05285049 0.01645124 0.00379397 0.22433896 0.00563572\n",
      " 0.07606398 0.07424578 0.30809663 0.13455594], Действие: случайное\n",
      "loss =  tensor(1.5964, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7035, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7141, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6851, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6174, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5959, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6291, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6247, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4837, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4431, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4590, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3194, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3748, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3068, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3341, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3338, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3152\n",
      "Reward: 20.0488\n",
      "Episode: 1, Step: 26, State: [0.4913627505302429, 0.1865079402923584, 0.9990108609199524, 0.4163424074649811, 0.7834843993186951, 1.0, 0.9979695677757263, 0.975683867931366, 0.22962963581085205, 0.7670682668685913]\n",
      "weights [1.9660338188142072, 1.2292667873028769, 10, 1.7133303831897257, 4.618583502850758, 10, 10, 10, 1.2980752484907678, 4.293084902909937]\n",
      "Episode: 1, Step: 26, Epsilon: 0.7964\n",
      "Episode: 1, Step: 26, Action: [0.09736822 0.09456334 0.17361192 0.05629697 0.0935762  0.1684036\n",
      " 0.06406504 0.05671858 0.03361756 0.16177855], Действие: случайное\n",
      "loss =  tensor(1.6684, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6966, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7422, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6926, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6587, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5706, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7503, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6999, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5250, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5115, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5030, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4156, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3909, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3596, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4184, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4154, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3591\n",
      "Reward: 10.4659\n",
      "Episode: 1, Step: 27, State: [0.35508638620376587, 0.2033730149269104, 0.9396637082099915, 0.43968871235847473, 0.5065458416938782, 0.9830845594406128, 1.0, 0.996960461139679, 1.0, 0.027108434587717056]\n",
      "weights [1.5505928670364382, 1.25529107530443, 10, 1.7847190255441563, 2.0265265914590684, 10, 10, 10, 10, 1.0278627214878857]\n",
      "Episode: 1, Step: 27, Epsilon: 0.7927\n",
      "Episode: 1, Step: 27, Action: [5.2068390e-07 3.7812494e-04 1.2499472e-06 9.9960512e-01 6.7602025e-07\n",
      " 8.3379967e-07 7.9739846e-07 8.7704387e-07 7.7145241e-06 4.1099029e-06], Действие: агент\n",
      "loss =  tensor(2.1290, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.1196, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.1207, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0325, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0165, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9789, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9072, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9100, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7843, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7654, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7380, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7037, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6778, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6524, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6113, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5787, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1606\n",
      "Reward: 2.3614\n",
      "Episode: 1, Step: 28, State: [0.0019193857442587614, 0.9375, 0.997032642364502, 0.9367704391479492, 0.8741188049316406, 0.998009979724884, 1.0, 1.0, 1.0, 0.6907630562782288]\n",
      "weights [1.001922073021743, 10, 10, 10, 7.943935196371159, 10, 10, 10, 10, 3.2337558191103613]\n",
      "Episode: 1, Step: 28, Epsilon: 0.7890\n",
      "Episode: 1, Step: 28, Action: [5.4577008e-08 3.6935823e-04 2.4554606e-07 9.9962687e-01 6.7132397e-08\n",
      " 9.5320523e-08 1.2188821e-07 1.1509051e-07 2.1297647e-06 8.4869424e-07], Действие: агент\n",
      "loss =  tensor(1.6251, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5895, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5654, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5551, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5328, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5021, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4776, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4499, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3958, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3760, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3504, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3293, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3076, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2924, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2665, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2466, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1774\n",
      "Reward: 8.7326\n",
      "Episode: 1, Step: 29, State: [0.13339731097221375, 0.7053571343421936, 0.997032642364502, 0.5573930144309998, 0.981873095035553, 1.0, 1.0, 1.0, 1.0, 0.9016064405441284]\n",
      "weights [1.1539300059083137, 3.39392777707234, 10, 2.2593356482586673, 10, 10, 10, 10, 10, 10]\n",
      "Episode: 1, Step: 29, Epsilon: 0.7853\n",
      "Episode: 1, Step: 29, Action: [4.84132201e-08 7.65119621e-04 2.17172968e-07 9.99231219e-01\n",
      " 6.22906811e-08 8.03084248e-08 1.21338800e-07 1.07472744e-07\n",
      " 2.09741734e-06 7.99589145e-07], Действие: агент\n",
      "loss =  tensor(1.2876, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2616, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2408, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2311, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2201, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1943, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1886, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1732, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1234, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1160, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0831, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0702, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0484, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0444, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0359, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0113, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1486\n",
      "Reward: 3.8681\n",
      "Episode: 1, Step: 30, State: [0.7428023219108582, 0.9067460298538208, 1.0, 0.0038910505827516317, 0.9929506778717041, 1.0, 1.0, 1.0, 1.0, 0.9066265225410461]\n",
      "weights [3.8880448664413922, 10, 10, 1.00390524217234, 10, 10, 10, 10, 10, 10]\n",
      "Episode: 1, Step: 30, Epsilon: 0.7816\n",
      "Episode: 1, Step: 30, Action: [0.10134233 0.1817955  0.08476143 0.05742873 0.2055143  0.06533514\n",
      " 0.0534049  0.14965583 0.01236688 0.08839497], Действие: случайное\n",
      "loss =  tensor(2.0518, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0338, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9361, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8337, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8360, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6966, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6713, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7344, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5454, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6214, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6042, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6121, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5554, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6075, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5020, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5863, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2278\n",
      "Reward: 13.6371\n",
      "accuracy =  0.2083\n",
      "--------------------------------------\n",
      "Episode: 1, Step: 30, Test Accuracy: 0.2083\n",
      "--------------------------------------\n",
      "Episode: 1, Step: 31, State: [0.9884836673736572, 1.0, 1.0, 0.0077821011655032635, 0.9889224767684937, 1.0, 1.0, 0.7993921041488647, 0.8677248954772949, 0.08433734625577927]\n",
      "weights [10, 10, 10, 1.0078421215062958, 10, 10, 10, 4.984823807325396, 7.5599444329595515, 1.0921040667180806]\n",
      "Episode: 1, Step: 31, Epsilon: 0.7780\n",
      "Episode: 1, Step: 31, Action: [0.08318825 0.1396608  0.16024631 0.16110825 0.06723133 0.11752734\n",
      " 0.07126974 0.01697937 0.17106444 0.01172418], Действие: случайное\n",
      "loss =  tensor(1.7006, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7043, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6791, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5933, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6471, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6300, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6194, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5192, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5595, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5046, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4806, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5183, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4151, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4387, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4243, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5216, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.216\n",
      "Reward: 11.0118\n",
      "Episode: 1, Step: 32, State: [0.8195777535438538, 0.97817462682724, 0.9950544238090515, 0.07003890722990036, 0.9597180485725403, 0.9960198998451233, 1.0, 1.0, 0.0, 1.0]\n",
      "weights [5.542523037590173, 10, 10, 1.0753126474448833, 10, 10, 10, 10, 0.9999990000010001, 10]\n",
      "Episode: 1, Step: 32, Epsilon: 0.7743\n",
      "Episode: 1, Step: 32, Action: [1.5206331e-07 4.1805040e-02 8.0517401e-07 9.5818347e-01 2.0669705e-07\n",
      " 2.1366853e-07 3.9822223e-07 2.9318269e-07 6.1447809e-06 3.1794784e-06], Действие: агент\n",
      "loss =  tensor(1.2564, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2197, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2116, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2034, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2080, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2283, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1856, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1592, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1146, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0933, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0362, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0369, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9797, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0001, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9334, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9427, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.258\n",
      "Reward: 5.8502\n",
      "Episode: 1, Step: 33, State: [0.49808061122894287, 0.8998016119003296, 1.0, 0.0, 0.9989929795265198, 1.0, 1.0, 1.0, 0.01904761977493763, 1.0]\n",
      "weights [1.9923478351785662, 9.980100866537022, 10, 0.9999990000010001, 10, 10, 10, 10, 1.0194164372730616, 10]\n",
      "Episode: 1, Step: 33, Epsilon: 0.7707\n",
      "Episode: 1, Step: 33, Action: [0.09909957 0.32198435 0.00926791 0.00509684 0.02277723 0.21214185\n",
      " 0.0241     0.24721399 0.00453615 0.0537821 ], Действие: случайное\n",
      "loss =  tensor(1.8926, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8562, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9469, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9449, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8408, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8765, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7834, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8102, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6900, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7068, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6167, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5478, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6140, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5131, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5670, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5316, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2402\n",
      "Reward: 14.7130\n",
      "Episode: 1, Step: 34, State: [0.9942418336868286, 0.4821428656578064, 0.9950544238090515, 0.0009727626456879079, 1.0, 1.0, 1.0, 0.6575481295585632, 1.0, 0.4939759075641632]\n",
      "weights [10, 1.9310307856228701, 10, 1.0009727078868775, 10, 10, 10, 2.92010984960049, 10, 1.976186586294233]\n",
      "Episode: 1, Step: 34, Epsilon: 0.7671\n",
      "Episode: 1, Step: 34, Action: [0.00279533 0.4094922  0.03191905 0.0545411  0.00236251 0.1778042\n",
      " 0.01042902 0.2212965  0.08465081 0.00470928], Действие: случайное\n",
      "loss =  tensor(1.4422, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3997, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3963, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3644, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4127, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3667, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3622, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3422, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3447, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2285, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2715, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2390, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1801, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2464, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1558, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1384, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2575\n",
      "Reward: 5.1620\n",
      "Episode: 1, Step: 35, State: [0.9980806112289429, 0.1547619104385376, 0.9465875625610352, 0.008754863403737545, 0.9969788789749146, 0.9960198998451233, 1.0, 0.3677811622619629, 0.9957671761512756, 0.986947774887085]\n",
      "weights [10, 1.1830971997743651, 10, 1.0088311702619053, 10, 10, 10, 1.5817282854929238, 10, 10]\n",
      "Episode: 1, Step: 35, Epsilon: 0.7635\n",
      "Episode: 1, Step: 35, Action: [0.19740737 0.05958821 0.02697586 0.26813376 0.02523541 0.19100915\n",
      " 0.03189222 0.13508726 0.02134665 0.04332411], Действие: случайное\n",
      "loss =  tensor(1.7172, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7917, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8287, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8089, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6542, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7524, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6670, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6248, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5821, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5772, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4965, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4578, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3445, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3537, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4111, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3902, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2647\n",
      "Reward: 9.3992\n",
      "Episode: 1, Step: 36, State: [1.0, 0.0, 1.0, 0.22859922051429749, 0.9264854192733765, 0.5174129605293274, 1.0, 0.87132728099823, 0.8888888955116272, 0.9437751173973083]\n",
      "weights [10, 0.9999990000010001, 10, 1.2963413186144126, 10, 2.0721607628254763, 10, 7.771594757327595, 8.999919537161173, 10]\n",
      "Episode: 1, Step: 36, Epsilon: 0.7600\n",
      "Episode: 1, Step: 36, Action: [0.15442837 0.05865297 0.07174055 0.09074938 0.10098402 0.16905079\n",
      " 0.0364814  0.19446935 0.02329415 0.10014902], Действие: случайное\n",
      "loss =  tensor(1.6658, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6715, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5652, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5797, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5509, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5871, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5576, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5460, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4889, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4259, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4058, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3620, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3416, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4018, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4280, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1977\n",
      "Reward: 10.2783\n",
      "Episode: 1, Step: 37, State: [1.0, 0.0, 1.0, 0.951361894607544, 0.9989929795265198, 0.9990049600601196, 1.0, 0.9989868402481079, 0.9968253970146179, 0.0833333358168602]\n",
      "weights [10, 0.9999990000010001, 10, 10, 10, 10, 10, 10, 10, 1.0909079037833402]\n",
      "Episode: 1, Step: 37, Epsilon: 0.7564\n",
      "Episode: 1, Step: 37, Action: [3.9053814e-09 2.7995096e-03 1.5709658e-08 9.9720025e-01 5.7603313e-09\n",
      " 6.1674750e-09 7.2068516e-09 7.9775919e-09 1.6596574e-07 5.6827442e-08], Действие: агент\n",
      "loss =  tensor(1.1919, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2261, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2103, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1617, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1815, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1407, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1008, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1108, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0376, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0053, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9812, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9630, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9426, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9422, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9350, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9043, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1237\n",
      "Reward: 10.1160\n",
      "Episode: 1, Step: 38, State: [0.008637236431241035, 0.7976190447807312, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "weights [1.008711470752322, 4.941151986186513, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "Episode: 1, Step: 38, Epsilon: 0.7529\n",
      "Episode: 1, Step: 38, Action: [0.20810799 0.12409756 0.03698754 0.00139104 0.13355604 0.02486638\n",
      " 0.15414716 0.26679483 0.03947633 0.01057514], Действие: случайное\n",
      "loss =  tensor(1.6412, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7713, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6122, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7024, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7171, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5896, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6659, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5095, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5720, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4734, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4431, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3783, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4759, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3570, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5266, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4574, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2768\n",
      "Reward: 16.1272\n",
      "Episode: 1, Step: 39, State: [0.13147792220115662, 0.3710317313671112, 0.9901087880134583, 0.2665369510650635, 0.9607250690460205, 0.9990049600601196, 0.992893397808075, 0.6018236875534058, 0.9936507940292358, 0.9809237122535706]\n",
      "weights [1.1513798833467586, 1.58990279791185, 10, 1.3633933407535113, 10, 10, 10, 2.5114439440447165, 10, 10]\n",
      "Episode: 1, Step: 39, Epsilon: 0.7494\n",
      "Episode: 1, Step: 39, Action: [6.1612141e-08 3.2256536e-02 2.6695031e-07 9.6773928e-01 8.1781771e-08\n",
      " 8.1435743e-08 1.5646127e-07 1.2271865e-07 2.6441166e-06 7.7665823e-07], Действие: агент\n",
      "loss =  tensor(0.9952, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0043, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9998, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9938, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0054, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9604, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9373, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9458, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8894, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8765, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8423, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8471, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8408, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8286, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8033, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7896, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2217\n",
      "Reward: 3.0892\n",
      "Episode: 1, Step: 40, State: [0.0, 0.9990079402923584, 1.0, 0.0437743179500103, 1.0, 1.0, 0.9969543218612671, 0.825734555721283, 0.9925925731658936, 0.990963876247406]\n",
      "weights [0.9999990000010001, 10, 10, 1.0457771350368175, 10, 10, 10, 5.738339381049326, 10, 10]\n",
      "Episode: 1, Step: 40, Epsilon: 0.7459\n",
      "Episode: 1, Step: 40, Action: [0.01815739 0.05838917 0.25653535 0.37572503 0.12666685 0.04262406\n",
      " 0.01877345 0.00531132 0.07496115 0.02285623], Действие: случайное\n",
      "loss =  tensor(1.7067, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6187, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7366, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6239, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5125, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6297, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4932, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5052, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4292, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3915, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2304, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2993, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3043, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2533, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1709, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3147, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1933\n",
      "Reward: 6.3890\n",
      "accuracy =  0.1802\n",
      "--------------------------------------\n",
      "Episode: 1, Step: 40, Test Accuracy: 0.1802\n",
      "--------------------------------------\n",
      "Episode: 1, Step: 41, State: [0.0, 0.983134925365448, 1.0, 0.5904669165611267, 1.0, 1.0, 1.0, 1.0, 0.523809552192688, 0.9969879388809204]\n",
      "weights [0.9999990000010001, 10, 10, 2.4417992065592244, 10, 10, 10, 10, 2.0999957151784967, 10]\n",
      "Episode: 1, Step: 41, Epsilon: 0.7425\n",
      "Episode: 1, Step: 41, Action: [0.08738162 0.00948738 0.13878146 0.04673548 0.27319519 0.02859896\n",
      " 0.17335927 0.14754451 0.01936972 0.07554643], Действие: случайное\n",
      "loss =  tensor(2.0084, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9577, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9945, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0089, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8730, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8498, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7475, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7977, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7213, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6507, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6599, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5974, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5219, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6109, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4932, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5912, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.317\n",
      "Reward: 23.7835\n",
      "Episode: 1, Step: 42, State: [0.9481765627861023, 0.4136904776096344, 0.8902077078819275, 0.14007781445980072, 0.8177240490913391, 0.939303457736969, 0.9624365568161011, 0.7284700870513916, 0.9026455283164978, 0.10542168468236923]\n",
      "weights [10, 1.705580851462529, 9.1080245496655, 1.1628945664161912, 5.486157163672881, 10, 10, 3.682821926758911, 10, 1.1178438656889114]\n",
      "Episode: 1, Step: 42, Epsilon: 0.7390\n",
      "Episode: 1, Step: 42, Action: [0.08117909 0.09549571 0.02271069 0.09340757 0.2021876  0.06465692\n",
      " 0.02518078 0.14860781 0.08164043 0.1849334 ], Действие: случайное\n",
      "loss =  tensor(1.5035, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5802, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6561, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5030, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5914, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5511, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3777, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5100, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4215, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3201, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2918, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4819, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3332, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3753, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2175, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2233, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2349\n",
      "Reward: 4.5719\n",
      "Episode: 1, Step: 43, State: [0.9481765627861023, 0.9970238208770752, 0.9990108609199524, 0.1031128391623497, 0.9244713187217712, 0.9890547394752502, 1.0, 0.6686930060386658, 0.9798941612243652, 0.05923694744706154]\n",
      "weights [10, 10, 10, 1.1149662172662065, 10, 10, 10, 3.018339485393481, 10, 1.0629657854021035]\n",
      "Episode: 1, Step: 43, Epsilon: 0.7356\n",
      "Episode: 1, Step: 43, Action: [0.17678479 0.02073685 0.06739687 0.07953205 0.01108573 0.1433642\n",
      " 0.03533368 0.04666497 0.10589552 0.31320533], Действие: случайное\n",
      "loss =  tensor(1.4771, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4277, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4832, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4519, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4437, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4296, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5488, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4328, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4018, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3175, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2018, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2717, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1427, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1779, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2506, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2789, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3012\n",
      "Reward: 11.7149\n",
      "Episode: 1, Step: 44, State: [0.20537428557872772, 0.995039701461792, 0.9960435032844543, 0.020428014919161797, 0.8811681866645813, 0.9870646595954895, 0.9989847540855408, 0.9604862928390503, 0.991534411907196, 0.007028112653642893]\n",
      "weights [1.2584525310457266, 10, 10, 1.0208529790329774, 8.415184088736416, 10, 10, 10, 10, 1.0070768424225784]\n",
      "Episode: 1, Step: 44, Epsilon: 0.7321\n",
      "Episode: 1, Step: 44, Action: [0.14282639 0.05363814 0.11808823 0.19238956 0.01226465 0.14913908\n",
      " 0.1421249  0.0742119  0.0860508  0.02926635], Действие: случайное\n",
      "loss =  tensor(1.6441, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5089, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5183, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5815, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6646, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5450, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5647, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7544, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4600, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3283, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4166, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3259, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3185, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2540, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3241, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2690, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.397\n",
      "Reward: 18.5556\n",
      "Episode: 1, Step: 45, State: [0.0, 0.9990079402923584, 0.9703264236450195, 0.024319065734744072, 0.904330313205719, 0.6736318469047546, 0.8060913681983948, 0.6170212626457214, 0.42010581493377686, 0.6445783376693726]\n",
      "weights [0.9999990000010001, 10, 10, 1.0249241734224144, 10, 3.064015059377155, 5.157041404849503, 2.6111041981182983, 1.7244495656327987, 2.8135515992217814]\n",
      "Episode: 1, Step: 45, Epsilon: 0.7287\n",
      "Episode: 1, Step: 45, Action: [6.9656966e-07 4.6070274e-02 2.8112347e-06 9.5389390e-01 8.0925264e-07\n",
      " 8.3765593e-07 1.6218064e-06 1.0897922e-06 2.1604545e-05 6.3773141e-06], Действие: агент\n",
      "loss =  tensor(1.1042, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0525, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1156, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0778, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0421, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0106, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9732, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9426, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8980, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8371, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8246, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8261, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8037, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7979, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7666, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7896, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1432\n",
      "Reward: 1.3921\n",
      "Episode: 1, Step: 46, State: [0.0, 1.0, 1.0, 0.6225680708885193, 1.0, 1.0, 1.0, 0.9979736804962158, 1.0, 1.0]\n",
      "weights [0.9999990000010001, 10, 10, 2.6494773584120277, 10, 10, 10, 10, 10, 10]\n",
      "Episode: 1, Step: 46, Epsilon: 0.7254\n",
      "Episode: 1, Step: 46, Action: [0.08208415 0.14774958 0.12595155 0.04630219 0.46138726 0.00358902\n",
      " 0.02751662 0.07164027 0.03169205 0.0020873 ], Действие: случайное\n",
      "loss =  tensor(1.9203, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9250, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8053, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9043, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6969, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7670, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7817, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7635, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7068, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6613, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5261, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4380, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5138, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5038, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3943, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5171, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2523\n",
      "Reward: 13.1040\n",
      "Episode: 1, Step: 47, State: [0.17658349871635437, 0.6398809552192688, 0.8862512111663818, 0.42704281210899353, 0.4118831753730774, 1.0, 1.0, 0.9878419637680054, 0.9978836178779602, 1.0]\n",
      "weights [1.2144507475746817, 2.776851815090929, 8.791225111307241, 1.7453280555792134, 1.700339554636621, 10, 10, 10, 10, 10]\n",
      "Episode: 1, Step: 47, Epsilon: 0.7220\n",
      "Episode: 1, Step: 47, Action: [3.0533760e-09 2.7100748e-04 1.3743868e-08 9.9972874e-01 3.9800900e-09\n",
      " 3.8913486e-09 6.8456227e-09 5.2922484e-09 2.2595901e-07 3.5058729e-08], Действие: агент\n",
      "loss =  tensor(0.9094, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9212, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8943, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8721, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8582, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8543, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8051, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7863, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7983, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7967, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7738, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7585, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7595, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7392, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.242\n",
      "Reward: 4.6108\n",
      "Episode: 1, Step: 48, State: [0.3541266918182373, 0.420634925365448, 0.9871414303779602, 0.15369649231433868, 0.7351460456848145, 1.0, 1.0, 0.9939209818840027, 0.988359808921814, 1.0]\n",
      "weights [1.548288865700753, 1.7260244321878393, 10, 1.1816077911892973, 3.7756514790732187, 10, 10, 10, 10, 10]\n",
      "Episode: 1, Step: 48, Epsilon: 0.7186\n",
      "Episode: 1, Step: 48, Action: [0.21511839 0.00852754 0.37864083 0.00858163 0.00089444 0.02113463\n",
      " 0.15868765 0.11765117 0.0713094  0.01945434], Действие: случайное\n",
      "loss =  tensor(2.1961, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9423, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8995, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7789, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7286, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6758, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7297, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6020, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5425, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5396, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5605, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5257, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5345, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4865, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4675, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4120, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2485\n",
      "Reward: 12.8668\n",
      "Episode: 1, Step: 49, State: [0.7955853939056396, 0.858134925365448, 1.0, 0.0, 0.9989929795265198, 1.0, 0.9989847540855408, 0.761904776096344, 0.8941798806190491, 0.2329317331314087]\n",
      "weights [4.891994398599829, 7.048901596636172, 10, 0.9999990000010001, 10, 10, 10, 4.1999826104115074, 9.449909487349574, 1.3036632325035031]\n",
      "Episode: 1, Step: 49, Epsilon: 0.7153\n",
      "Episode: 1, Step: 49, Action: [0.0491207  0.17546577 0.10154896 0.03924484 0.15856284 0.07336275\n",
      " 0.04232564 0.06751743 0.07399134 0.21885975], Действие: случайное\n",
      "loss =  tensor(1.6785, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6294, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7387, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7869, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6444, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6084, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6286, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6083, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5207, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4518, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4658, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4845, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4485, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4292, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4175, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3282\n",
      "Reward: 9.7872\n",
      "Episode: 1, Step: 50, State: [0.06813819706439972, 0.988095223903656, 0.7675568461418152, 0.01264591421931982, 0.9889224767684937, 0.9940298795700073, 0.9705584049224854, 0.9989868402481079, 0.9936507940292358, 0.0]\n",
      "weights [1.0731193442315226, 10, 4.302108628682072, 1.0128068558124879, 10, 10, 10, 10, 10, 0.9999990000010001]\n",
      "Episode: 1, Step: 50, Epsilon: 0.7120\n",
      "Episode: 1, Step: 50, Action: [0.04516703 0.08424487 0.16665792 0.00704866 0.04336506 0.20012211\n",
      " 0.03231049 0.01532451 0.35232817 0.05343118], Действие: случайное\n",
      "loss =  tensor(1.6992, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8073, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7999, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7603, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8149, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7736, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6864, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6692, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5987, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6718, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5250, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4714, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5027, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4130, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4802, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4635, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2694\n",
      "Reward: 14.6219\n",
      "accuracy =  0.2407\n",
      "--------------------------------------\n",
      "Episode: 1, Step: 50, Test Accuracy: 0.2407\n",
      "--------------------------------------\n",
      "Новая лучшая точность: 0.2407\n",
      "Episode: 1, Step: 51, State: [0.8454894423484802, 0.9672619104385376, 0.4727992117404938, 0.10797665268182755, 0.9446122646331787, 0.9621890783309937, 0.9868020415306091, 0.9989868402481079, 0.012698412872850895, 0.9899598360061646]\n",
      "weights [6.472007759156546, 10, 1.8968069196073492, 1.1210456340193529, 10, 10, 10, 10, 1.0128607106255012, 10]\n",
      "Episode: 1, Step: 51, Epsilon: 0.7087\n",
      "Episode: 1, Step: 51, Action: [8.7104368e-09 2.3437389e-03 4.6256833e-08 9.9765539e-01 1.2680406e-08\n",
      " 1.1578191e-08 2.2187756e-08 1.6577307e-08 7.0485009e-07 1.2874229e-07], Действие: агент\n",
      "loss =  tensor(1.1021, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1209, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0692, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0424, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0501, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0451, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0021, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9685, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8768, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8636, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8433, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8272, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8242, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7873, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7728, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7648, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1294\n",
      "Reward: 6.8106\n",
      "Episode: 1, Step: 52, State: [0.0, 0.9940476417541504, 0.9821958541870117, 0.9542801380157471, 1.0, 1.0, 1.0, 1.0, 0.8084656000137329, 1.0]\n",
      "weights [0.9999990000010001, 10, 10, 10, 10, 10, 10, 10, 5.2209669861117005, 10]\n",
      "Episode: 1, Step: 52, Epsilon: 0.7054\n",
      "Episode: 1, Step: 52, Action: [0.03359508 0.23663529 0.02487347 0.25634667 0.06199812 0.02343966\n",
      " 0.00487308 0.15035351 0.06716656 0.14071855], Действие: случайное\n",
      "loss =  tensor(1.5236, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4921, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3719, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4226, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4553, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5574, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3121, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3646, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2567, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1346, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2573, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1147, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1091, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1801, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0678, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1391, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2975\n",
      "Reward: 20.1542\n",
      "Episode: 1, Step: 53, State: [0.007677542977035046, 0.9394841194152832, 0.832838773727417, 0.2714007794857025, 0.9979858994483948, 0.998009979724884, 0.9949238300323486, 0.7142857313156128, 0.9798941612243652, 0.3453815281391144]\n",
      "weights [1.0077359281620382, 10, 5.982212742066204, 1.3724947808746604, 10, 10, 10, 3.499987958657684, 10, 1.5276050331306243]\n",
      "Episode: 1, Step: 53, Epsilon: 0.7021\n",
      "Episode: 1, Step: 53, Action: [0.06826277 0.38200059 0.03319718 0.02770915 0.16432799 0.08969308\n",
      " 0.13596409 0.01463137 0.0389924  0.04522137], Действие: случайное\n",
      "loss =  tensor(1.7033, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7549, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5560, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6128, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6231, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6113, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5940, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5903, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4173, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4987, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4618, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3626, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4043, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3876, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3067, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2904, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1263\n",
      "Reward: 3.7257\n",
      "Episode: 1, Step: 54, State: [0.9980806112289429, 0.961309552192688, 0.9881305694580078, 0.024319065734744072, 0.8912386894226074, 0.9890547394752502, 0.9299492239952087, 1.0, 1.0, 0.9809237122535706]\n",
      "weights [10, 10, 10, 1.0249241734224144, 9.19436149058662, 10, 10, 10, 10, 10]\n",
      "Episode: 1, Step: 54, Epsilon: 0.6989\n",
      "Episode: 1, Step: 54, Action: [0.12016927 0.0344715  0.04087083 0.04615613 0.0527867  0.15169112\n",
      " 0.01865004 0.1039345  0.28170217 0.14956776], Действие: случайное\n",
      "loss =  tensor(2.0210, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9076, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8660, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0646, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7202, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7891, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8821, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6751, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6491, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5735, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6041, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5191, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6014, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3837, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3541, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4664, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2464\n",
      "Reward: 16.3865\n",
      "Episode: 1, Step: 55, State: [1.0, 0.6904761791229248, 0.9980217814445496, 0.09727626293897629, 0.9425981640815735, 0.9990049600601196, 0.9979695677757263, 0.9979736804962158, 0.7629629373550415, 0.0602409653365612]\n",
      "weights [10, 3.2307586744299917, 10, 1.1077573915340713, 10, 10, 10, 10, 4.218731746461431, 1.064101433466614]\n",
      "Episode: 1, Step: 55, Epsilon: 0.6956\n",
      "Episode: 1, Step: 55, Action: [0.05326792 0.07514144 0.13250001 0.00996284 0.06984892 0.04715692\n",
      " 0.14242415 0.22821284 0.04550438 0.19598058], Действие: случайное\n",
      "loss =  tensor(1.6733, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7115, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7568, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8423, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7812, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7034, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6039, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6238, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5312, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5688, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5032, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5290, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4346, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4254, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4038, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3996, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2661\n",
      "Reward: 12.5026\n",
      "Episode: 1, Step: 56, State: [0.05278310924768448, 0.52182537317276, 1.0, 0.8365758657455444, 0.9979858994483948, 1.0, 1.0, 0.9837892651557922, 0.9851852059364319, 0.00401606410741806]\n",
      "weights [1.0557233026983506, 2.091281830140811, 10, 6.119009811813793, 10, 10, 10, 10, 10, 1.0040312498339343]\n",
      "Episode: 1, Step: 56, Epsilon: 0.6924\n",
      "Episode: 1, Step: 56, Action: [0.2114478  0.00102784 0.06507683 0.24383335 0.41338386 0.00332038\n",
      " 0.02668125 0.02125116 0.0128088  0.00116874], Действие: случайное\n",
      "loss =  tensor(1.7971, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7973, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7382, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6927, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6243, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5803, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4393, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4023, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3199, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2473, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1964, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2352, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2267, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2082, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0985, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0473, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2872\n",
      "Reward: 13.5780\n",
      "Episode: 1, Step: 57, State: [0.06621880829334259, 0.3452380895614624, 0.9861523509025574, 0.7042801380157471, 0.07250755280256271, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "weights [1.0709135480216403, 1.527270381473249, 10, 3.381567310774476, 1.078174733224965, 10, 10, 10, 10, 10]\n",
      "Episode: 1, Step: 57, Epsilon: 0.6892\n",
      "Episode: 1, Step: 57, Action: [0.028493   0.1859194  0.074671   0.00278946 0.27685589 0.06015999\n",
      " 0.03662561 0.0099242  0.14221322 0.18234822], Действие: случайное\n",
      "loss =  tensor(2.2873, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.2171, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.2051, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0943, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0013, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8269, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8296, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9626, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6474, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5595, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4974, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4368, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5130, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3277, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3247, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3471, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.327\n",
      "Reward: 16.5987\n",
      "Episode: 1, Step: 58, State: [0.0, 1.0, 0.9495549201965332, 0.032101165503263474, 0.9758307933807373, 0.9970149397850037, 0.9756345152854919, 1.0, 0.8137565851211548, 0.04116465896368027]\n",
      "weights [0.9999990000010001, 10, 10, 1.033164759781113, 10, 10, 10, 10, 5.36928852685604, 1.042930849824893]\n",
      "Episode: 1, Step: 58, Epsilon: 0.6860\n",
      "Episode: 1, Step: 58, Action: [0.02134339 0.09704828 0.00345695 0.103384   0.29871623 0.01129945\n",
      " 0.25198552 0.0335524  0.06716708 0.11204669], Действие: случайное\n",
      "loss =  tensor(1.4932, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6599, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7450, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6495, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6150, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5544, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4821, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4884, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5859, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5353, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4561, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2852, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4574, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4254, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2262, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2932, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2441\n",
      "Reward: 4.1742\n",
      "Episode: 1, Step: 59, State: [0.0, 1.0, 1.0, 0.8482490181922913, 0.9929506778717041, 0.9990049600601196, 0.9329949021339417, 1.0, 0.761904776096344, 0.05220883712172508]\n",
      "weights [0.9999990000010001, 10, 10, 6.589699772535041, 10, 10, 10, 10, 4.1999826104115074, 1.0550836345419645]\n",
      "Episode: 1, Step: 59, Epsilon: 0.6829\n",
      "Episode: 1, Step: 59, Action: [9.0061653e-10 1.1019569e-05 4.4582755e-09 9.9998891e-01 1.1605731e-09\n",
      " 1.4293492e-09 1.7824676e-09 1.4501257e-09 7.7325069e-08 9.8269926e-09], Действие: агент\n",
      "loss =  tensor(1.1801, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1244, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1167, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1018, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1047, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0957, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0601, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0417, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9661, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9542, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9091, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9032, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8795, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8734, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8586, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.0996\n",
      "Reward: 9.4594\n",
      "Episode: 1, Step: 60, State: [0.9913627505302429, 0.0605158731341362, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9957671761512756, 0.9638554453849792]\n",
      "weights [10, 1.064412805912122, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "Episode: 1, Step: 60, Epsilon: 0.6797\n",
      "Episode: 1, Step: 60, Action: [0.00384948 0.10067327 0.16981075 0.00070213 0.09314449 0.00356317\n",
      " 0.38708558 0.16000885 0.07046622 0.01069605], Действие: случайное\n",
      "loss =  tensor(1.9259, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9975, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9169, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9736, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0177, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7421, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7359, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8023, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6637, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7042, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5850, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5348, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5982, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5272, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5171, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6092, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2274\n",
      "Reward: 13.6359\n",
      "accuracy =  0.2088\n",
      "--------------------------------------\n",
      "Episode: 1, Step: 60, Test Accuracy: 0.2088\n",
      "--------------------------------------\n",
      "Episode: 1, Step: 61, State: [1.0, 0.010912698693573475, 1.0, 0.03501945361495018, 0.9838871955871582, 1.0, 0.8527919054031372, 0.9837892651557922, 0.8952381014823914, 0.990963876247406]\n",
      "weights [10, 1.0110320773981059, 10, 1.0362892469251188, 10, 10, 6.793058558905852, 10, 9.545363999564398, 10]\n",
      "Episode: 1, Step: 61, Epsilon: 0.6766\n",
      "Episode: 1, Step: 61, Action: [0.00616062 0.15611874 0.27988946 0.0010558  0.08963657 0.12858672\n",
      " 0.08022213 0.08680436 0.13270011 0.03882549], Действие: случайное\n",
      "loss =  tensor(1.5090, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5950, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6157, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5724, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5353, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5171, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4851, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4738, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5043, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3668, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3055, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3652, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2861, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3258, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2591, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3022\n",
      "Reward: 17.0763\n",
      "Episode: 1, Step: 62, State: [1.0, 0.5873016119003296, 0.7725024819374084, 0.05836575850844383, 0.7210473418235779, 0.9890547394752502, 0.7441624402999878, 0.7203647494316101, 0.45502644777297974, 0.922690749168396]\n",
      "weights [10, 2.4230711962153224, 4.39563302880448, 1.061982342988771, 3.584824829103183, 10, 3.9087149379380763, 3.576074267793949, 1.8349480648473098, 10]\n",
      "Episode: 1, Step: 62, Epsilon: 0.6734\n",
      "Episode: 1, Step: 62, Action: [0.096502   0.14252393 0.0787235  0.24778052 0.09620781 0.05281149\n",
      " 0.02502103 0.13473394 0.06077326 0.06492252], Действие: случайное\n",
      "loss =  tensor(1.5038, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5344, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4711, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4016, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3578, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4304, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4942, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3722, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3720, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2788, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2932, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1782, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1890, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2057, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2164, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1930, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3067\n",
      "Reward: 8.6105\n",
      "Episode: 1, Step: 63, State: [1.0, 0.2976190447807312, 0.8872403502464294, 0.0437743179500103, 0.5810674428939819, 0.9970149397850037, 0.9776649475097656, 0.47922998666763306, 0.8476190567016602, 0.836345374584198]\n",
      "weights [10, 1.4237267808052116, 8.868341945398688, 1.0457771350368175, 2.387013365336436, 10, 10, 1.9202297639438297, 6.562457325026743, 6.110391851543672]\n",
      "Episode: 1, Step: 63, Epsilon: 0.6703\n",
      "Episode: 1, Step: 63, Action: [1.3439841e-09 3.7807207e-05 4.7761661e-09 9.9996209e-01 2.0265609e-09\n",
      " 1.7618623e-09 2.6603302e-09 2.4372504e-09 8.0414388e-08 1.1630555e-08], Действие: агент\n",
      "loss =  tensor(1.0469, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0555, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0252, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0058, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0149, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9919, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9444, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9624, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8773, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8789, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8484, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8340, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8422, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8056, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7963, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7766, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2453\n",
      "Reward: 7.2871\n",
      "Episode: 1, Step: 64, State: [1.0, 0.0, 1.0, 0.6449416279792786, 0.9979858994483948, 1.0, 1.0, 0.6869301199913025, 0.7798941731452942, 0.4367469847202301]\n",
      "weights [10, 0.9999990000010001, 10, 2.816430374190037, 10, 10, 10, 3.1941648484592973, 4.543248450263233, 1.7753979072893018]\n",
      "Episode: 1, Step: 64, Epsilon: 0.6672\n",
      "Episode: 1, Step: 64, Action: [1.4224996e-10 3.8730104e-06 5.9747085e-10 9.9999607e-01 2.4066263e-10\n",
      " 2.3721455e-10 2.8782948e-10 3.0096803e-10 1.1935237e-08 1.5527807e-09], Действие: агент\n",
      "loss =  tensor(0.7956, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8030, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7978, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7800, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7578, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7590, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7441, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7236, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6952, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6883, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6738, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6650, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6546, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6537, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6328, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6313, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2996\n",
      "Reward: 6.7033\n",
      "Episode: 1, Step: 65, State: [0.9980806112289429, 0.004960317630320787, 1.0, 0.36381322145462036, 0.9969788789749146, 1.0, 0.9969543218612671, 0.5298885703086853, 0.723809540271759, 0.39156627655029297]\n",
      "weights [10, 1.0049840350431805, 10, 1.5718629526119847, 10, 10, 10, 2.1271507342544, 3.620676761634671, 1.6435616861743092]\n",
      "Episode: 1, Step: 65, Epsilon: 0.6641\n",
      "Episode: 1, Step: 65, Action: [0.04585624 0.04989185 0.06057414 0.06924976 0.19056018 0.03873749\n",
      " 0.00646458 0.06752789 0.42172302 0.04941484], Действие: случайное\n",
      "loss =  tensor(2.0539, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0875, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8477, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7604, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6022, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6986, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6103, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6658, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5788, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5670, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3792, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3771, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4275, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3182, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3663, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5132, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.209\n",
      "Reward: 6.4219\n",
      "Episode: 1, Step: 66, State: [1.0, 1.0, 1.0, 0.04474708065390587, 0.9879153966903687, 1.0, 0.8883248567581177, 0.9979736804962158, 0.0031746032182127237, 0.9578313231468201]\n",
      "weights [10, 10, 10, 1.0468420801503082, 10, 10, 8.95446396133213, 10, 1.0031837070411243, 10]\n",
      "Episode: 1, Step: 66, Epsilon: 0.6611\n",
      "Episode: 1, Step: 66, Action: [0.14894915 0.09595886 0.0157272  0.03797311 0.02674588 0.16541703\n",
      " 0.04392734 0.37061102 0.03314244 0.06154797], Действие: случайное\n",
      "loss =  tensor(1.8638, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8135, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7743, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7752, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7873, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7053, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6883, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6065, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6107, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6551, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4965, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5511, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4124, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4689, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4298, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5403, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.25\n",
      "Reward: 11.5878\n",
      "Episode: 1, Step: 67, State: [0.7120921015739441, 1.0, 1.0, 0.0009727626456879079, 0.9979858994483948, 0.9990049600601196, 0.9959390759468079, 0.4832826852798462, 0.5100529193878174, 0.8062248826026917]\n",
      "weights [3.4733209201480504, 10, 10, 1.0009727078868775, 10, 10, 10, 1.935290411646399, 2.0410325901277444, 5.160594677153391]\n",
      "Episode: 1, Step: 67, Epsilon: 0.6580\n",
      "Episode: 1, Step: 67, Action: [1.4054800e-09 8.9616660e-05 6.9917165e-09 9.9991024e-01 1.9913662e-09\n",
      " 2.0632971e-09 3.3713652e-09 2.5404172e-09 1.2926888e-07 1.7403933e-08], Действие: агент\n",
      "loss =  tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8836, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8369, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8424, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8351, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8017, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7729, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7882, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6920, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7218, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6814, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6587, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6569, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6336, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6376, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6248, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1132\n",
      "Reward: 1.3567\n",
      "Episode: 1, Step: 68, State: [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.9442755579948425, 0.9978836178779602, 0.9528112411499023]\n",
      "weights [10, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 10, 10]\n",
      "Episode: 1, Step: 68, Epsilon: 0.6550\n",
      "Episode: 1, Step: 68, Action: [1.9324814e-11 2.9843916e-06 1.1322794e-10 9.9999702e-01 2.8455065e-11\n",
      " 2.8125164e-11 5.0015502e-11 3.7506925e-11 4.2908130e-09 3.1218667e-10], Действие: агент\n",
      "loss =  tensor(0.6443, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6336, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6338, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6221, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6093, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5969, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5800, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5803, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5566, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5527, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5334, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5344, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5247, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5118, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5078, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5097, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2121\n",
      "Reward: 12.0559\n",
      "Episode: 1, Step: 69, State: [1.0, 0.4454365074634552, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8399189710617065, 0.7375661134719849, 0.8714859485626221]\n",
      "weights [10, 1.8032167826433672, 10, 0.9999990000010001, 10, 10, 10, 6.246797386516561, 3.8104690013964637, 7.7811897424892225]\n",
      "Episode: 1, Step: 69, Epsilon: 0.6520\n",
      "Episode: 1, Step: 69, Action: [1.1665720e-10 8.6360760e-06 5.5711386e-10 9.9999130e-01 1.8833182e-10\n",
      " 1.7754473e-10 2.7815011e-10 2.3484992e-10 1.4293316e-08 1.4935609e-09], Действие: агент\n",
      "loss =  tensor(0.5154, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5193, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5087, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5057, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5002, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4889, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4867, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4755, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4675, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4569, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4529, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4428, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4370, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4319, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4297, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4259, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.257\n",
      "Reward: 9.7923\n",
      "Episode: 1, Step: 70, State: [0.40499040484428406, 0.4642857015132904, 1.0, 0.0, 1.0, 1.0, 1.0, 0.911854088306427, 0.7259259223937988, 0.9638554453849792]\n",
      "weights [1.6806423417356076, 1.866663137724092, 10, 0.9999990000010001, 10, 10, 10, 10, 3.648635289038679, 10]\n",
      "Episode: 1, Step: 70, Epsilon: 0.6490\n",
      "Episode: 1, Step: 70, Action: [0.11748914 0.16658934 0.05702827 0.12873789 0.2279157  0.04775704\n",
      " 0.01471244 0.16021028 0.03923974 0.04032019], Действие: случайное\n",
      "loss =  tensor(1.6716, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7255, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5951, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5755, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5275, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6067, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4136, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4852, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3753, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4212, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3414, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2041, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3555, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3553, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3413, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2831, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2639\n",
      "Reward: 16.5593\n",
      "accuracy =  0.183\n",
      "--------------------------------------\n",
      "Episode: 1, Step: 70, Test Accuracy: 0.1830\n",
      "--------------------------------------\n",
      "Episode: 1, Step: 71, State: [0.9760076999664307, 1.0, 1.0, 0.14883267879486084, 0.7200402617454529, 1.0, 0.7817258834838867, 0.47213777899742126, 0.6793650984764099, 0.5763052105903625]\n",
      "weights [10, 10, 10, 1.1748557542462756, 3.5719294292286645, 10, 4.581374258142609, 1.8944301482127976, 3.118802340125431, 2.3601839456402534]\n",
      "Episode: 1, Step: 71, Epsilon: 0.6460\n",
      "Episode: 1, Step: 71, Action: [0.01981221 0.01123129 0.01977103 0.09001708 0.38564174 0.01420769\n",
      " 0.02971348 0.20709513 0.16882089 0.05368945], Действие: случайное\n",
      "loss =  tensor(1.9724, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9096, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9352, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0594, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8772, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8917, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6437, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6931, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9189, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5826, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6091, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4735, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5927, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4946, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4075, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4524, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.202\n",
      "Reward: 4.6540\n",
      "Episode: 1, Step: 72, State: [1.0, 1.0, 1.0, 0.4902723729610443, 0.9989929795265198, 0.998009979724884, 0.9624365568161011, 0.5410334467887878, 0.3026455044746399, 0.654618501663208]\n",
      "weights [10, 10, 10, 1.9618282100596551, 10, 10, 10, 2.17880325744903, 1.4339888427302625, 2.8953406869646083]\n",
      "Episode: 1, Step: 72, Epsilon: 0.6430\n",
      "Episode: 1, Step: 72, Action: [3.9686374e-10 5.8759182e-05 2.2315316e-09 9.9994123e-01 5.9282379e-10\n",
      " 6.2985756e-10 8.8070407e-10 7.4886081e-10 4.1107239e-08 5.6892389e-09], Действие: агент\n",
      "loss =  tensor(0.5727, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5680, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5639, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5665, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5518, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5681, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5598, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5528, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5230, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5171, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5038, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4956, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4863, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4777, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4739, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4722, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3084\n",
      "Reward: 16.8077\n",
      "Episode: 1, Step: 73, State: [0.08925143629312515, 0.5724206566810608, 1.0, 0.2217898815870285, 1.0, 1.0, 1.0, 0.8439716100692749, 0.5259259343147278, 0.6967871189117432]\n",
      "weights [1.0979966830067573, 2.3387417490660547, 10, 1.28499834600067, 10, 10, 10, 6.409048964710983, 2.1093705878720006, 3.2980020453249925]\n",
      "Episode: 1, Step: 73, Epsilon: 0.6401\n",
      "Episode: 1, Step: 73, Action: [0.13995434 0.20596581 0.06825818 0.18513987 0.02248321 0.10126264\n",
      " 0.09170498 0.03584855 0.05740445 0.09197798], Действие: случайное\n",
      "loss =  tensor(1.7288, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6576, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6788, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5850, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6799, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5000, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6322, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6423, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4255, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3271, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3668, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3140, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3240, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3022, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3774, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4108, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2275\n",
      "Reward: 4.8600\n",
      "Episode: 1, Step: 74, State: [1.0, 1.0, 1.0, 0.0019455252913758159, 1.0, 1.0, 1.0, 0.9746707081794739, 0.37460318207740784, 0.3644578456878662]\n",
      "weights [10, 10, 10, 1.0019483138369072, 10, 10, 10, 10, 1.5989822339350945, 1.5734572754266043]\n",
      "Episode: 1, Step: 74, Epsilon: 0.6371\n",
      "Episode: 1, Step: 74, Action: [4.6185303e-10 3.5383338e-05 2.2718987e-09 9.9996459e-01 6.5475242e-10\n",
      " 6.7956857e-10 9.7848163e-10 7.8452439e-10 4.7262752e-08 6.1002901e-09], Действие: агент\n",
      "loss =  tensor(0.5229, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5137, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5073, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5129, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5089, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5035, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4952, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4808, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4637, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4533, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4427, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4374, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4282, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4330, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4245, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4172, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3067\n",
      "Reward: 15.0149\n",
      "Episode: 1, Step: 75, State: [0.025911707431077957, 0.711309552192688, 1.0, 0.023346303030848503, 0.9899294972419739, 1.0, 0.9949238300323486, 0.9918946027755737, 0.8444444537162781, 0.4106425642967224]\n",
      "weights [1.0265999304465658, 3.4639058676495784, 10, 1.0239033335971208, 10, 10, 10, 10, 6.4285304854742975, 1.6967603064961758]\n",
      "Episode: 1, Step: 75, Epsilon: 0.6342\n",
      "Episode: 1, Step: 75, Action: [1.47936130e-09 1.30636763e-05 6.35304076e-09 9.99986768e-01\n",
      " 1.91330773e-09 2.13416818e-09 3.16989746e-09 2.41073961e-09\n",
      " 1.10332465e-07 1.38732723e-08], Действие: агент\n",
      "loss =  tensor(0.4367, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4302, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4235, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4223, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4182, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4110, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4010, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3914, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3889, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3781, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3766, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3673, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3627, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3506, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3555, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3557, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3578\n",
      "Reward: 8.0025\n",
      "Episode: 1, Step: 76, State: [0.14107485115528107, 0.4513888955116272, 0.9960435032844543, 0.01361867692321539, 0.9889224767684937, 1.0, 0.9796954393386841, 0.9219858050346375, 0.7164021134376526, 0.2610441744327545]\n",
      "weights [1.1642444479598502, 1.822781509592437, 10, 1.013805678188492, 10, 10, 10, 10, 3.526106932652419, 1.3532590340881823]\n",
      "Episode: 1, Step: 76, Epsilon: 0.6313\n",
      "Episode: 1, Step: 76, Action: [4.0835797e-09 2.6395641e-05 1.5230677e-08 9.9997330e-01 5.4613913e-09\n",
      " 5.9051719e-09 8.0706428e-09 6.6249806e-09 2.1218374e-07 3.2990727e-08], Действие: агент\n",
      "loss =  tensor(0.3599, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3567, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3595, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3502, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3454, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3442, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3402, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3416, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3244, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3246, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3223, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3167, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3074, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3081, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3042, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2959, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3778\n",
      "Reward: 7.7996\n",
      "Episode: 1, Step: 77, State: [0.26199615001678467, 0.4513888955116272, 1.0, 0.0, 1.0, 1.0, 0.9847715497016907, 0.7791286706924438, 0.5798941850662231, 0.19879518449306488]\n",
      "weights [1.3550046453254925, 1.822781509592437, 10, 0.9999990000010001, 10, 10, 10, 4.527502395320596, 2.380347008076111, 1.2481187488227163]\n",
      "Episode: 1, Step: 77, Epsilon: 0.6284\n",
      "Episode: 1, Step: 77, Action: [0.16614898 0.28891113 0.01211202 0.02923749 0.03441066 0.09597084\n",
      " 0.04930757 0.13028242 0.1231199  0.07049899], Действие: случайное\n",
      "loss =  tensor(1.6171, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7197, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5362, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5651, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6279, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5629, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5592, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6110, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4669, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4329, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4311, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4076, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3601, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4148, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3236, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4092, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2063\n",
      "Reward: 3.3972\n",
      "Episode: 1, Step: 78, State: [0.9193857908248901, 1.0, 1.0, 0.0, 0.9939576983451843, 1.0, 0.9593908786773682, 0.8976697325706482, 0.7068783044815063, 0.4708835482597351]\n",
      "weights [10, 10, 10, 0.9999990000010001, 10, 10, 10, 9.772184251410618, 3.4115406800252637, 1.8899395525719376]\n",
      "Episode: 1, Step: 78, Epsilon: 0.6255\n",
      "Episode: 1, Step: 78, Action: [0.02982819 0.14961844 0.04160993 0.02116151 0.18058868 0.02905012\n",
      " 0.00290544 0.00643757 0.24844565 0.29035446], Действие: случайное\n",
      "loss =  tensor(1.8529, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6797, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7576, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8071, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6688, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6288, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6056, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6564, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5527, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4594, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3796, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5090, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5016, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3453, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4421, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3891, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.231\n",
      "Reward: 4.9271\n",
      "Episode: 1, Step: 79, State: [0.9942418336868286, 0.9890872836112976, 1.0, 0.008754863403737545, 0.9335347414016724, 0.9870646595954895, 0.9664974808692932, 0.9817629456520081, 0.820105791091919, 0.02208835259079933]\n",
      "weights [10, 10, 10, 1.0088311702619053, 10, 10, 10, 10, 5.55879173253001, 1.022586222449741]\n",
      "Episode: 1, Step: 79, Epsilon: 0.6226\n",
      "Episode: 1, Step: 79, Action: [0.02786656 0.25564608 0.00235556 0.08000692 0.02477076 0.06489228\n",
      " 0.1983217  0.04385879 0.17434628 0.12793509], Действие: случайное\n",
      "loss =  tensor(1.4444, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4579, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4091, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5109, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3854, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4279, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3550, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3248, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3045, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3551, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3451, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1683, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2340, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1642, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2605, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1961, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3225\n",
      "Reward: 14.2058\n",
      "Episode: 1, Step: 80, State: [1.0, 0.1259920597076416, 1.0, 0.0019455252913758159, 0.9425981640815735, 0.9990049600601196, 0.9756345152854919, 0.9959473013877869, 0.4931216835975647, 0.2439759075641632]\n",
      "weights [10, 1.1441530559921929, 10, 1.0019483138369072, 10, 10, 10, 10, 1.9728561960221178, 1.3227074206996232]\n",
      "Episode: 1, Step: 80, Epsilon: 0.6198\n",
      "Episode: 1, Step: 80, Action: [0.16638064 0.02899658 0.12292967 0.0220016  0.04453493 0.22935399\n",
      " 0.03454427 0.06995832 0.22172611 0.0595739 ], Действие: случайное\n",
      "loss =  tensor(1.9051, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9214, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8732, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8702, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7256, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7404, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7242, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7019, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6422, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5266, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6016, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5203, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5149, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4886, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3729, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3539, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2358\n",
      "Reward: 5.1805\n",
      "accuracy =  0.1952\n",
      "--------------------------------------\n",
      "Episode: 1, Step: 80, Test Accuracy: 0.1952\n",
      "--------------------------------------\n",
      "Episode: 1, Step: 81, State: [1.0, 0.2033730149269104, 1.0, 0.03501945361495018, 0.7361530661582947, 0.998009979724884, 1.0, 0.996960461139679, 0.6931216716766357, 0.9939758777618408]\n",
      "weights [10, 1.25529107530443, 10, 1.0362892469251188, 3.7900618945151443, 10, 10, 10, 3.2586098433658006, 10]\n",
      "Episode: 1, Step: 81, Epsilon: 0.6169\n",
      "Episode: 1, Step: 81, Action: [8.5471949e-11 5.8348578e-06 3.8706435e-10 9.9999416e-01 1.4200842e-10\n",
      " 1.2350430e-10 1.8742645e-10 1.6617419e-10 9.2388754e-09 9.8251274e-10], Действие: агент\n",
      "loss =  tensor(0.5344, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5261, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5224, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5027, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4988, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5027, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4944, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4875, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4506, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4361, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4347, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4250, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4151, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4091, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4058, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4005, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1584\n",
      "Reward: 10.4760\n",
      "Episode: 1, Step: 82, State: [0.03262955695390701, 0.4722222089767456, 1.0, 0.9873540997505188, 1.0, 1.0, 1.0, 1.0, 0.970370352268219, 0.9969879388809204]\n",
      "weights [1.0337290884369763, 1.8947332045329177, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "Episode: 1, Step: 82, Epsilon: 0.6141\n",
      "Episode: 1, Step: 82, Action: [1.5765033e-11 5.9635340e-07 1.0109794e-10 9.9999940e-01 2.3950659e-11\n",
      " 2.7097444e-11 3.8082256e-11 3.2533184e-11 2.6439384e-09 2.1577251e-10], Действие: агент\n",
      "loss =  tensor(0.4270, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4279, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4119, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4097, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4005, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4035, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3929, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3859, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3686, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3619, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3536, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3497, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3557, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3478, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3426, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3363, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.324\n",
      "Reward: 22.1990\n",
      "Episode: 1, Step: 83, State: [0.0, 0.8740079402923584, 1.0, 0.06128404662013054, 1.0, 1.0, 1.0, 0.9898682832717896, 0.15238095819950104, 0.7038152813911438]\n",
      "weights [0.9999990000010001, 7.936945116821772, 10, 1.0652838391801487, 10, 10, 10, 10, 1.1797738971294476, 3.3762600192097825]\n",
      "Episode: 1, Step: 83, Epsilon: 0.6113\n",
      "Episode: 1, Step: 83, Action: [4.6607007e-09 1.3958408e-04 2.3756643e-08 9.9985993e-01 6.3818058e-09\n",
      " 7.1680892e-09 1.0892445e-08 7.5845250e-09 3.3878814e-07 5.1880175e-08], Действие: агент\n",
      "loss =  tensor(0.3566, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3473, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3539, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3447, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3399, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3392, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3300, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3289, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3179, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3120, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3060, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3075, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2960, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2981, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2881, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2949, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3388\n",
      "Reward: 5.6014\n",
      "Episode: 1, Step: 84, State: [0.0, 0.8670634627342224, 1.0, 0.0, 1.0, 1.0, 0.9989847540855408, 0.9716312289237976, 0.14603175222873688, 0.650602400302887]\n",
      "weights [0.9999990000010001, 7.522329814194867, 10, 0.9999990000010001, 10, 10, 10, 10, 1.1710023547216204, 2.8620606976298157]\n",
      "Episode: 1, Step: 84, Epsilon: 0.6085\n",
      "Episode: 1, Step: 84, Action: [6.7776198e-09 1.7388409e-04 3.3100683e-08 9.9982554e-01 9.1720258e-09\n",
      " 1.0252217e-08 1.5521376e-08 1.0787578e-08 4.5086034e-07 7.1856682e-08], Действие: агент\n",
      "loss =  tensor(0.2959, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3062, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2938, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2982, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2903, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2838, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2894, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2834, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2738, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2763, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2629, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2592, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2643, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2591, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2547, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2549, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3429\n",
      "Reward: 5.6101\n",
      "Episode: 1, Step: 85, State: [0.0, 0.8442460298538208, 1.0, 0.0, 1.0, 1.0, 0.9989847540855408, 0.9604862928390503, 0.15449735522270203, 0.6355421543121338]\n",
      "weights [0.9999990000010001, 6.4203408665641915, 10, 0.9999990000010001, 10, 10, 10, 10, 1.1827270126829503, 2.743794016338489]\n",
      "Episode: 1, Step: 85, Epsilon: 0.6057\n",
      "Episode: 1, Step: 85, Action: [7.0884010e-09 1.6848373e-04 3.4100761e-08 9.9983096e-01 9.5772252e-09\n",
      " 1.0675000e-08 1.6080646e-08 1.1239599e-08 4.5803753e-07 7.3506705e-08], Действие: агент\n",
      "loss =  tensor(0.2625, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2627, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2530, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2562, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2619, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2540, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2481, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2472, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2441, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2364, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2354, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2376, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2290, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2291, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2255, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2280, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3332\n",
      "Reward: 5.0804\n",
      "Episode: 1, Step: 86, State: [0.0, 0.8789682388305664, 1.0, 0.0, 1.0, 1.0, 1.0, 0.957446813583374, 0.192592591047287, 0.663654625415802]\n",
      "weights [0.9999990000010001, 8.262225783646308, 10, 0.9999990000010001, 10, 10, 10, 10, 1.2385305737614214, 2.9731255502195664]\n",
      "Episode: 1, Step: 86, Epsilon: 0.6029\n",
      "Episode: 1, Step: 86, Action: [0.11230714 0.04966807 0.1701388  0.01624387 0.20428687 0.14115268\n",
      " 0.09342608 0.06628383 0.04123875 0.1052539 ], Действие: случайное\n",
      "loss =  tensor(2.1739, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.1018, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0818, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7737, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8194, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7555, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8162, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9142, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6971, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6536, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6283, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6822, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5900, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6102, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7024, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6520, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2386\n",
      "Reward: 6.4519\n",
      "Episode: 1, Step: 87, State: [1.0, 1.0, 1.0, 0.01653696410357952, 0.9959717988967896, 1.0, 0.800000011920929, 0.9604862928390503, 0.7756613492965698, 0.07329317182302475]\n",
      "weights [10, 10, 10, 1.0168139998007217, 10, 10, 4.9999752981452605, 10, 4.457526776316363, 1.079088758716116]\n",
      "Episode: 1, Step: 87, Epsilon: 0.6002\n",
      "Episode: 1, Step: 87, Action: [3.4945277e-10 1.3531162e-05 1.5233950e-09 9.9998641e-01 4.4241411e-10\n",
      " 4.4881493e-10 6.5428984e-10 5.3908150e-10 3.1030890e-08 3.6208878e-09], Действие: агент\n",
      "loss =  tensor(0.3278, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3291, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3248, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3169, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3072, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3076, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2959, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2871, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2837, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2719, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2620, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2636, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2635, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2561, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2544, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2602, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3338\n",
      "Reward: 14.4624\n",
      "Episode: 1, Step: 88, State: [0.0, 0.8105158805847168, 1.0, 0.0, 1.0, 1.0, 0.9979695677757263, 0.9949341416358948, 0.9037036895751953, 0.017068272456526756]\n",
      "weights [0.9999990000010001, 5.277459270077878, 10, 0.9999990000010001, 10, 10, 10, 10, 10, 1.0173636221261866]\n",
      "Episode: 1, Step: 88, Epsilon: 0.5974\n",
      "Episode: 1, Step: 88, Action: [0.09217556 0.09328673 0.23819503 0.00762956 0.07542336 0.18436876\n",
      " 0.05473443 0.02284961 0.17179771 0.05953925], Действие: случайное\n",
      "loss =  tensor(1.7567, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7782, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7754, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8342, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7296, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6618, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6492, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5406, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4890, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5493, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4813, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5445, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5178, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4675, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3858, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4315, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3135\n",
      "Reward: 11.3957\n",
      "Episode: 1, Step: 89, State: [0.0009596928721293807, 0.9821428656578064, 0.829871416091919, 0.0, 0.9415911436080933, 0.9990049600601196, 0.9959390759468079, 0.9959473013877869, 0.32486772537231445, 0.8283132314682007]\n",
      "weights [1.000959612846125, 10, 5.87787248418998, 0.9999990000010001, 10, 10, 10, 10, 1.4811890297533743, 5.824526747313301]\n",
      "Episode: 1, Step: 89, Epsilon: 0.5947\n",
      "Episode: 1, Step: 89, Action: [0.09101481 0.28497669 0.29557674 0.03391721 0.00344421 0.08620988\n",
      " 0.01074071 0.02706761 0.09607762 0.07097453], Действие: случайное\n",
      "loss =  tensor(1.8073, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6422, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7906, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5492, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4872, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5063, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5381, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5416, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4727, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4849, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4664, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3583, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3092, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3635, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3056, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2785, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2753\n",
      "Reward: 5.6832\n",
      "Episode: 1, Step: 90, State: [0.011516314931213856, 0.8878968358039856, 0.8644906282424927, 0.0009727626456879079, 0.9939576983451843, 0.9990049600601196, 0.9989847540855408, 1.0, 0.7862433791160583, 0.763052225112915]\n",
      "weights [1.0116494621567278, 8.920275238406823, 7.379508941127229, 1.0009727078868775, 10, 10, 10, 10, 4.678195780177323, 4.220321461786573]\n",
      "Episode: 1, Step: 90, Epsilon: 0.5920\n",
      "Episode: 1, Step: 90, Action: [6.7467176e-10 1.1603391e-05 3.3649215e-09 9.9998832e-01 8.7336993e-10\n",
      " 9.2444752e-10 1.5734052e-09 1.1157775e-09 6.7719682e-08 7.0684263e-09], Действие: агент\n",
      "loss =  tensor(0.3707, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3749, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3649, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3736, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3594, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3489, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3465, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3502, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3210, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3192, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3166, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3149, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3021, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2984, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2992, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2899, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3596\n",
      "Reward: 9.9472\n",
      "accuracy =  0.3128\n",
      "--------------------------------------\n",
      "Episode: 1, Step: 90, Test Accuracy: 0.3128\n",
      "--------------------------------------\n",
      "Новая лучшая точность: 0.3128\n",
      "Episode: 1, Step: 91, State: [0.0009596928721293807, 0.7807539701461792, 1.0, 0.0, 1.0, 0.9990049600601196, 0.9989847540855408, 0.9848024249076843, 0.48677247762680054, 0.1927710771560669]\n",
      "weights [1.000959612846125, 4.561065208804575, 10, 0.9999990000010001, 10, 10, 10, 10, 1.9484497770621554, 1.2388044244902654]\n",
      "Episode: 1, Step: 91, Epsilon: 0.5893\n",
      "Episode: 1, Step: 91, Action: [6.1840328e-09 4.5789289e-05 2.4868140e-08 9.9995375e-01 7.6336111e-09\n",
      " 8.5956087e-09 1.2001525e-08 8.9077252e-09 3.2675729e-07 5.0877809e-08], Действие: агент\n",
      "loss =  tensor(0.2994, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3073, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3030, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3079, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2925, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2917, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2812, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2877, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2703, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2694, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2594, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2558, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2492, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2517, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2488, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2489, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3587\n",
      "Reward: 5.0665\n",
      "Episode: 1, Step: 92, State: [0.00671785045415163, 0.7966269850730896, 1.0, 0.0, 1.0, 1.0, 0.9989847540855408, 0.9878419637680054, 0.49735450744628906, 0.16566264629364014]\n",
      "weights [1.0067622716213627, 4.9170490161163665, 10, 0.9999990000010001, 10, 10, 10, 10, 1.9894697661560696, 1.1985545139543514]\n",
      "Episode: 1, Step: 92, Epsilon: 0.5866\n",
      "Episode: 1, Step: 92, Action: [0.13840816 0.0537343  0.05154636 0.13252553 0.06035756 0.13986919\n",
      " 0.23081168 0.08868877 0.0231287  0.08092975], Действие: случайное\n",
      "loss =  tensor(1.7419, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7916, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6869, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6711, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6249, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7612, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5039, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6683, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5491, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3620, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4048, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4190, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3729, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2399, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4473, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3322, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2846\n",
      "Reward: 10.6973\n",
      "Episode: 1, Step: 93, State: [0.7917466163635254, 0.9722222089767456, 0.9980217814445496, 0.387159526348114, 0.8640483617782593, 0.9054726362228394, 0.47309646010398865, 0.9503546357154846, 0.7195767164230347, 0.09036144614219666]\n",
      "weights [4.801819690602928, 10, 10, 1.6317433512471982, 7.3555027182994825, 10, 1.897876985833824, 10, 3.566024979165329, 1.0993365402361581]\n",
      "Episode: 1, Step: 93, Epsilon: 0.5839\n",
      "Episode: 1, Step: 93, Action: [1.0621863e-09 2.9714367e-05 4.5651687e-09 9.9997020e-01 1.2841307e-09\n",
      " 1.2934595e-09 1.8400218e-09 1.5632422e-09 6.8301148e-08 9.9708641e-09], Действие: агент\n",
      "loss =  tensor(0.2955, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2870, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3011, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2917, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2990, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2938, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2935, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2945, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2695, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2642, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2626, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2604, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2537, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2518, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2478, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2461, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3255\n",
      "Reward: 8.5264\n",
      "Episode: 1, Step: 94, State: [0.0, 0.9841269850730896, 1.0, 0.004863813053816557, 1.0, 1.0, 0.9918781518936157, 0.9878419637680054, 0.7894179821014404, 0.04116465896368027]\n",
      "weights [0.9999990000010001, 10, 10, 1.0048865755572247, 10, 10, 10, 10, 4.748721003142392, 1.042930849824893]\n",
      "Episode: 1, Step: 94, Epsilon: 0.5813\n",
      "Episode: 1, Step: 94, Action: [0.25147354 0.0572572  0.01717552 0.05044426 0.01277597 0.34017165\n",
      " 0.07407874 0.02928289 0.04706509 0.12027514], Действие: случайное\n",
      "loss =  tensor(1.5876, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4386, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4165, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3936, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4471, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4357, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4900, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4350, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2734, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2839, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2292, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3142, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1844, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1661, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1554, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1420, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2495\n",
      "Reward: 2.9898\n",
      "Episode: 1, Step: 95, State: [0.27543187141418457, 0.9920634627342224, 1.0, 0.0, 1.0, 0.9850746393203735, 1.0, 1.0, 0.9174603223800659, 0.38654619455337524]\n",
      "weights [1.3801305638728485, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 10, 1.6301119350951234]\n",
      "Episode: 1, Step: 95, Epsilon: 0.5786\n",
      "Episode: 1, Step: 95, Action: [2.8369546e-10 3.5647245e-06 1.3311364e-09 9.9999642e-01 3.4540340e-10\n",
      " 3.7261774e-10 5.9262700e-10 4.3198203e-10 2.8870963e-08 2.8116378e-09], Действие: агент\n",
      "loss =  tensor(0.3058, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2916, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2912, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2983, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2931, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2943, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2926, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2932, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2616, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2719, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2552, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2587, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2505, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2473, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2495, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2409, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3111\n",
      "Reward: 5.3690\n",
      "Episode: 1, Step: 96, State: [0.0, 1.0, 1.0, 0.022373540326952934, 1.0, 1.0, 1.0, 0.9989868402481079, 0.8507936596870422, 0.07429718971252441]\n",
      "weights [0.9999990000010001, 10, 10, 1.0228845252919094, 10, 10, 10, 10, 6.702083140832958, 1.0802591378439415]\n",
      "Episode: 1, Step: 96, Epsilon: 0.5760\n",
      "Episode: 1, Step: 96, Action: [1.53573798e-09 7.93655363e-06 6.35514574e-09 9.99991894e-01\n",
      " 1.77037351e-09 2.00021977e-09 2.90450752e-09 2.12150852e-09\n",
      " 1.04667436e-07 1.27150503e-08], Действие: агент\n",
      "loss =  tensor(0.2576, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2573, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2528, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2510, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2473, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2457, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2453, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2410, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2270, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2251, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2225, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2240, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2224, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2144, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2153, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2096, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3261\n",
      "Reward: 4.8299\n",
      "Episode: 1, Step: 97, State: [0.0, 1.0, 1.0, 0.0019455252913758159, 1.0, 1.0, 0.9939086437225342, 0.975683867931366, 0.7809523940086365, 0.0401606410741806]\n",
      "weights [0.9999990000010001, 10, 10, 1.0019483138369072, 10, 10, 10, 10, 4.565196822295355, 1.0418399171286403]\n",
      "Episode: 1, Step: 97, Epsilon: 0.5733\n",
      "Episode: 1, Step: 97, Action: [0.0871832  0.090668   0.01374655 0.05714356 0.15561921 0.09462826\n",
      " 0.04838854 0.36383334 0.04587826 0.04291107], Действие: случайное\n",
      "loss =  tensor(2.0323, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8883, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9814, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9155, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7836, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7015, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8131, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5818, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5277, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4441, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5647, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5379, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4104, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4972, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4640, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2628\n",
      "Reward: 9.9783\n",
      "Episode: 1, Step: 98, State: [1.0, 1.0, 1.0, 0.11964980512857437, 1.0, 0.9731343388557434, 0.9126903414726257, 0.44680851697921753, 0.6338624358177185, 0.2791164517402649]\n",
      "weights [10, 10, 10, 1.1359103115047728, 10, 10, 10, 1.8076890606672102, 2.7312064279089476, 1.3871846780653971]\n",
      "Episode: 1, Step: 98, Epsilon: 0.5707\n",
      "Episode: 1, Step: 98, Action: [8.1284590e-10 2.8961327e-05 3.4753853e-09 9.9997091e-01 1.0411102e-09\n",
      " 1.0394059e-09 1.5189032e-09 1.2594216e-09 5.7784547e-08 7.6946565e-09], Действие: агент\n",
      "loss =  tensor(0.3039, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3019, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2878, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2734, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2742, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2654, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2648, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2565, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2417, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2369, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2359, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2324, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2297, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2267, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2244, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2235, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2226\n",
      "Reward: 11.5080\n",
      "Episode: 1, Step: 99, State: [0.0, 1.0, 1.0, 0.1498054414987564, 1.0, 1.0, 1.0, 0.9452887773513794, 0.9386243224143982, 0.8012048006057739]\n",
      "weights [0.9999990000010001, 10, 10, 1.1761999812876431, 10, 10, 10, 10, 10, 5.030277254028049]\n",
      "Episode: 1, Step: 99, Epsilon: 0.5681\n",
      "Episode: 1, Step: 99, Action: [1.2654944e-10 1.8544583e-06 6.9453798e-10 9.9999809e-01 1.5887938e-10\n",
      " 1.7348700e-10 2.9812056e-10 2.0563071e-10 1.6744002e-08 1.4119017e-09], Действие: агент\n",
      "loss =  tensor(0.2382, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2324, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2300, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2287, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2209, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2261, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2217, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2252, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2102, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2064, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2021, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2008, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1985, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1968, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1977, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1943, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2747\n",
      "Reward: 7.6102\n",
      "Episode: 1, Step: 100, State: [0.0, 0.9980158805847168, 1.0, 0.014591439627110958, 1.0, 1.0, 1.0, 0.7497466802597046, 0.8677248954772949, 0.6807228922843933]\n",
      "weights [0.9999990000010001, 10, 10, 1.0148064725712522, 10, 10, 10, 3.9959350193745418, 7.5599444329595515, 3.1320656688767983]\n",
      "Episode: 1, Step: 100, Epsilon: 0.5656\n",
      "Episode: 1, Step: 100, Action: [6.2285138e-10 6.3999300e-06 3.0193856e-09 9.9999356e-01 7.5918455e-10\n",
      " 8.2575330e-10 1.3984037e-09 9.6611807e-10 5.7761394e-08 5.9502456e-09], Действие: агент\n",
      "loss =  tensor(0.2009, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2018, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1953, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1937, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1939, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1920, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1881, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1910, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1822, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1802, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1796, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1793, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1732, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1725, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1719, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1715, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3271\n",
      "Reward: 7.8521\n",
      "accuracy =  0.272\n",
      "--------------------------------------\n",
      "Episode: 1, Step: 100, Test Accuracy: 0.2720\n",
      "--------------------------------------\n",
      "Восстанавливаем лучшее состояние модели...\n",
      "Episode: 2, Step: 1, State: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "weights [np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815)]\n",
      "Episode: 2, Step: 1, Epsilon: 0.5893\n",
      "Episode: 2, Step: 1, Action: [2.6899957e-04 9.8761344e-01 3.5400726e-04 9.8726498e-03 2.8181024e-04\n",
      " 1.9774666e-04 2.9441025e-04 2.9649839e-04 3.6938375e-04 4.5098923e-04], Действие: агент\n",
      "loss =  tensor(3.4092, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.4734, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.5376, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.3784, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.4928, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.3838, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.1782, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.4170, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.0914, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.1635, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.9955, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.7056, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.8373, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.6868, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.8296, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.6693, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3001\n",
      "Reward: 3.2666\n",
      "Episode: 2, Step: 2, State: [0.21017274260520935, 0.596230149269104, 0.8318496346473694, 0.0019455252913758159, 0.9899294972419739, 0.9960198998451233, 1.0, 0.9989868402481079, 0.9439153671264648, 0.4909638464450836]\n",
      "weights [1.266098029080968, 2.4766522848041777, 5.947022778571543, 1.0019483138369072, 10, 10, 10, 10, 10, 1.9644931475362675]\n",
      "Episode: 2, Step: 2, Epsilon: 0.5866\n",
      "Episode: 2, Step: 2, Action: [6.8591671e-10 6.9486114e-06 2.8876797e-09 9.9999297e-01 8.9530733e-10\n",
      " 9.0665259e-10 1.4297477e-09 1.1347011e-09 5.3860457e-08 5.9067298e-09], Действие: агент\n",
      "loss =  tensor(0.3711, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3645, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3606, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3760, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3772, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3601, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3653, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3548, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3486, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3333, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3347, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3346, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3457, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3272, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3294, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3210, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3587\n",
      "Reward: 9.6065\n",
      "Episode: 2, Step: 3, State: [0.2581574022769928, 0.5178571343421936, 1.0, 0.0, 1.0, 1.0, 0.9949238300323486, 0.9817629456520081, 0.5428571701049805, 0.15160642564296722]\n",
      "weights [1.3479930312391593, 2.074069735670418, 10, 0.9999990000010001, 10, 10, 10, 10, 2.1874953452388155, 1.1786968354410605]\n",
      "Episode: 2, Step: 3, Epsilon: 0.5839\n",
      "Episode: 2, Step: 3, Action: [3.41804118e-09 2.30477654e-05 1.28294255e-08 9.99976754e-01\n",
      " 4.47465442e-09 4.73594941e-09 6.37267394e-09 5.18442667e-09\n",
      " 1.75906266e-07 2.71826455e-08], Действие: агент\n",
      "loss =  tensor(0.3470, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3470, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3390, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3298, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3236, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3324, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3207, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3093, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3142, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2974, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3005, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2901, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2822, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2797, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2842, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2749, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.397\n",
      "Reward: 6.8704\n",
      "Episode: 2, Step: 4, State: [0.2696737051010132, 0.2400793582201004, 0.9901087880134583, 0.0, 1.0, 0.993034839630127, 0.9756345152854919, 0.9209726452827454, 0.4634920656681061, 0.20783132314682007]\n",
      "weights [1.3692491119865815, 1.3159251494111752, 10, 0.9999990000010001, 10, 10, 10, 10, 1.8639018588670553, 1.2623558174713359]\n",
      "Episode: 2, Step: 4, Epsilon: 0.5813\n",
      "Episode: 2, Step: 4, Action: [6.6650543e-09 3.8210259e-05 2.3115993e-08 9.9996150e-01 9.2000638e-09\n",
      " 9.3691632e-09 1.2280629e-08 1.0494346e-08 2.7377729e-07 4.8284026e-08], Действие: агент\n",
      "loss =  tensor(0.2925, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2873, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3121, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2856, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2797, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2782, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2714, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2683, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2636, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2585, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2650, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2520, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2550, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2549, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2427, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2449, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.382\n",
      "Reward: 5.3717\n",
      "Episode: 2, Step: 5, State: [0.27543187141418457, 0.3125, 1.0, 0.0, 1.0, 1.0, 0.9908629655838013, 0.9594731330871582, 0.494179904460907, 0.17971888184547424]\n",
      "weights [1.3801305638728485, 1.4545433388460525, 10, 0.9999990000010001, 10, 10, 10, 10, 1.9769835794100716, 1.2190927704846282]\n",
      "Episode: 2, Step: 5, Epsilon: 0.5786\n",
      "Episode: 2, Step: 5, Action: [0.04402373 0.10812943 0.01566768 0.04074341 0.29090606 0.1160955\n",
      " 0.15266746 0.04714275 0.08523616 0.09938782], Действие: случайное\n",
      "loss =  tensor(2.1151, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9920, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9302, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8587, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8603, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8023, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8116, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6605, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8172, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5101, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4348, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6115, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4013, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6063, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4771, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6140, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1599\n",
      "Reward: 3.5642\n",
      "Episode: 2, Step: 6, State: [1.0, 1.0, 1.0, 0.8054474592208862, 1.0, 0.9870646595954895, 0.8629441857337952, 1.0, 0.5873016119003296, 0.13554216921329498]\n",
      "weights [10, 10, 10, 5.13997327417109, 10, 10, 7.29624430097802, 10, 2.4230711962153224, 1.1567930876360475]\n",
      "Episode: 2, Step: 6, Epsilon: 0.5760\n",
      "Episode: 2, Step: 6, Action: [0.01554391 0.30599037 0.13479974 0.01960303 0.11318294 0.07088192\n",
      " 0.00277244 0.12104741 0.17885206 0.03732618], Действие: случайное\n",
      "loss =  tensor(1.4161, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4303, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4304, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4328, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3533, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3999, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5316, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3287, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2915, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2453, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1968, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2445, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1868, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2598, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1242, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1430, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2186\n",
      "Reward: 11.0793\n",
      "Episode: 2, Step: 7, State: [0.9740883111953735, 0.6954365372657776, 0.9812067151069641, 0.0, 0.9838871955871582, 0.9990049600601196, 1.0, 0.9645389914512634, 0.21058201789855957, 0.9929718971252441]\n",
      "weights [10, 3.283377157737041, 10, 0.9999990000010001, 10, 10, 10, 10, 1.2667544392433927, 10]\n",
      "Episode: 2, Step: 7, Epsilon: 0.5733\n",
      "Episode: 2, Step: 7, Action: [1.2943908e-10 1.5232588e-05 7.2479267e-10 9.9998474e-01 2.0515002e-10\n",
      " 1.8963037e-10 3.0980069e-10 2.4156219e-10 1.7325835e-08 1.8299650e-09], Действие: агент\n",
      "loss =  tensor(0.4068, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3922, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3786, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3828, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3624, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3583, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3612, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3536, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3161, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3046, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3094, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3069, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2925, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2885, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2791, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2849, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1742\n",
      "Reward: 6.9177\n",
      "Episode: 2, Step: 8, State: [0.5930902361869812, 0.341269850730896, 1.0, 0.4717898964881897, 1.0, 1.0, 1.0, 1.0, 0.8835979104042053, 0.9989959597587585]\n",
      "weights [2.4575412816052076, 1.518070006419996, 10, 1.8931824669180604, 10, 10, 10, 10, 8.590837266196818, 10]\n",
      "Episode: 2, Step: 8, Epsilon: 0.5707\n",
      "Episode: 2, Step: 8, Action: [0.23410244 0.00781691 0.18591686 0.08771285 0.09024318 0.04281564\n",
      " 0.00739885 0.02010971 0.03727001 0.28661354], Действие: случайное\n",
      "loss =  tensor(1.7391, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6941, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6644, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6116, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5021, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5241, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5283, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4926, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2415, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2429, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2949, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1059, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1885, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1157, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1188, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0987, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2361\n",
      "Reward: 12.4983\n",
      "Episode: 2, Step: 9, State: [0.9990403056144714, 0.6805555820465088, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.9746031761169434, 0.01004016026854515]\n",
      "weights [10, 3.130425242617167, 10, 0.9999990000010001, 10, 10, 10, 10, 10, 1.0101409670621602]\n",
      "Episode: 2, Step: 9, Epsilon: 0.5681\n",
      "Episode: 2, Step: 9, Action: [1.0787843e-10 1.9813385e-06 4.3436715e-10 9.9999797e-01 1.3936856e-10\n",
      " 1.3688946e-10 1.9466456e-10 1.6931663e-10 9.7667447e-09 9.5156327e-10], Действие: агент\n",
      "loss =  tensor(0.3181, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3141, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3175, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3204, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3086, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3159, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3098, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3196, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2915, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2895, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2887, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2813, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2753, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2744, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2739, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2656, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3398\n",
      "Reward: 13.0521\n",
      "Episode: 2, Step: 10, State: [0.002879078732803464, 0.6666666865348816, 1.0, 0.0019455252913758159, 0.9989929795265198, 1.0, 1.0, 1.0, 0.9978836178779602, 0.00200803205370903]\n",
      "weights [1.002886385978904, 2.9999911788398723, 10, 1.0019483138369072, 10, 10, 10, 10, 10, 1.0020110683323142]\n",
      "Episode: 2, Step: 10, Epsilon: 0.5656\n",
      "Episode: 2, Step: 10, Action: [1.5430313e-09 4.3612449e-06 5.6703726e-09 9.9999559e-01 1.8005109e-09\n",
      " 1.9831818e-09 2.8063956e-09 2.1952238e-09 8.7938140e-08 1.0853832e-08], Действие: агент\n",
      "loss =  tensor(0.2842, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2853, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2803, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2794, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2747, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2678, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2628, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2639, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2406, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2540, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2425, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2416, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2407, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2401, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2336, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2347, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3079\n",
      "Reward: 3.0907\n",
      "accuracy =  0.2914\n",
      "--------------------------------------\n",
      "Episode: 2, Step: 10, Test Accuracy: 0.2914\n",
      "--------------------------------------\n",
      "Episode: 2, Step: 11, State: [0.0, 0.9930555820465088, 1.0, 0.0, 1.0, 1.0, 1.0, 0.9989868402481079, 0.9947090148925781, 0.0]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 10, 0.9999990000010001]\n",
      "Episode: 2, Step: 11, Epsilon: 0.5630\n",
      "Episode: 2, Step: 11, Action: [1.1159915e-09 4.6869027e-06 4.4947361e-09 9.9999523e-01 1.2965868e-09\n",
      " 1.4116095e-09 2.0669073e-09 1.5310226e-09 7.7570185e-08 8.7812362e-09], Действие: агент\n",
      "loss =  tensor(0.2457, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2406, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2433, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2352, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2368, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2321, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2326, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2281, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2261, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2157, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2192, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2193, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2065, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2111, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2062, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2059, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3078\n",
      "Reward: 3.1219\n",
      "Episode: 2, Step: 12, State: [0.0, 0.9930555820465088, 1.0, 0.0, 1.0, 1.0, 1.0, 0.9989868402481079, 0.9957671761512756, 0.0]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 10, 0.9999990000010001]\n",
      "Episode: 2, Step: 12, Epsilon: 0.5604\n",
      "Episode: 2, Step: 12, Action: [1.0854301e-09 4.5094534e-06 4.3721058e-09 9.9999535e-01 1.2594907e-09\n",
      " 1.3698163e-09 2.0093274e-09 1.4869045e-09 7.5559548e-08 8.5186995e-09], Действие: агент\n",
      "loss =  tensor(0.2124, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2105, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2098, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2068, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2013, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2054, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1999, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1994, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1908, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1931, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1875, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1885, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1905, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1823, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1846, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1812, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3075\n",
      "Reward: 3.1027\n",
      "Episode: 2, Step: 13, State: [0.0009596928721293807, 0.9980158805847168, 1.0, 0.0, 1.0, 1.0, 0.9989847540855408, 0.9989868402481079, 0.9936507940292358, 0.0]\n",
      "weights [1.000959612846125, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 10, 0.9999990000010001]\n",
      "Episode: 2, Step: 13, Epsilon: 0.5579\n",
      "Episode: 2, Step: 13, Action: [0.12734193 0.00489914 0.00282099 0.23483482 0.00562774 0.06563336\n",
      " 0.14239441 0.39158902 0.001731   0.02312758], Действие: случайное\n",
      "loss =  tensor(1.8993, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0065, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9166, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5593, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5846, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7531, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6470, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6643, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5284, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4320, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4082, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4276, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3088, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2107, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1803, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1801, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2302\n",
      "Reward: 12.4335\n",
      "Episode: 2, Step: 14, State: [1.0, 1.0, 1.0, 0.44260701537132263, 0.7210473418235779, 1.0, 0.9593908786773682, 0.20871327817440033, 0.9851852059364319, 0.38052210211753845]\n",
      "weights [10, 10, 10, 1.7940631359094703, 3.584824829103183, 10, 10, 1.263762816504817, 10, 1.6142599908055908]\n",
      "Episode: 2, Step: 14, Epsilon: 0.5553\n",
      "Episode: 2, Step: 14, Action: [0.05316541 0.02331365 0.12969668 0.11269071 0.09235377 0.15615531\n",
      " 0.04765643 0.08555571 0.02804761 0.27136471], Действие: случайное\n",
      "loss =  tensor(1.7651, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6410, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7348, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6652, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6364, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7355, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6381, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5770, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3607, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3812, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3508, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2879, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3839, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4321, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2397, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2357, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2129\n",
      "Reward: 4.2258\n",
      "Episode: 2, Step: 15, State: [0.9913627505302429, 1.0, 1.0, 0.0, 1.0, 1.0, 0.9888324737548828, 0.9665653705596924, 0.9417989253997803, 0.0030120480805635452]\n",
      "weights [10, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 10, 1.0030201418729532]\n",
      "Episode: 2, Step: 15, Epsilon: 0.5528\n",
      "Episode: 2, Step: 15, Action: [0.01817772 0.34188505 0.0330205  0.09008798 0.00291589 0.10797642\n",
      " 0.01166646 0.02417239 0.34578989 0.0243077 ], Действие: случайное\n",
      "loss =  tensor(1.6361, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6640, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5745, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6187, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4806, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4260, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3429, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3690, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2649, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2224, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1804, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1693, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1649, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0473, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0534, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0098, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1989\n",
      "Reward: 11.1658\n",
      "Episode: 2, Step: 16, State: [1.0, 0.9960317611694336, 0.9930761456489563, 0.0019455252913758159, 0.9969788789749146, 0.9791044592857361, 1.0, 0.9989868402481079, 0.01904761977493763, 1.0]\n",
      "weights [10, 10, 10, 1.0019483138369072, 10, 10, 10, 10, 1.0194164372730616, 10]\n",
      "Episode: 2, Step: 16, Epsilon: 0.5503\n",
      "Episode: 2, Step: 16, Action: [1.1237489e-10 1.9968036e-05 7.0565637e-10 9.9997997e-01 1.7178384e-10\n",
      " 1.6248572e-10 2.7696376e-10 2.0137497e-10 1.7914882e-08 1.7751470e-09], Действие: агент\n",
      "loss =  tensor(0.4603, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4197, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4268, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3799, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3711, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3676, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3483, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3512, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3027, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2997, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2872, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2858, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2613, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2654, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2569, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2544, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1927\n",
      "Reward: 10.8641\n",
      "Episode: 2, Step: 17, State: [0.0, 1.0, 1.0, 0.15369649231433868, 1.0, 1.0, 1.0, 1.0, 0.9841269850730896, 1.0]\n",
      "weights [0.9999990000010001, 10, 10, 1.1816077911892973, 10, 10, 10, 10, 10, 10]\n",
      "Episode: 2, Step: 17, Epsilon: 0.5478\n",
      "Episode: 2, Step: 17, Action: [4.24423552e-11 8.51234972e-07 2.53315119e-10 9.99999166e-01\n",
      " 5.43706018e-11 5.77318887e-11 1.06322805e-10 7.10455722e-11\n",
      " 7.15687332e-09 5.11759413e-10], Действие: агент\n",
      "loss =  tensor(0.2670, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2606, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2636, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2543, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2544, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2473, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2443, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2484, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2320, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2293, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2257, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2189, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2144, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2149, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2133, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2091, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2887\n",
      "Reward: 10.8271\n",
      "Episode: 2, Step: 18, State: [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.13544973731040955, 1.0]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 1.1566694112377245, 10]\n",
      "Episode: 2, Step: 18, Epsilon: 0.5453\n",
      "Episode: 2, Step: 18, Action: [1.1258607e-09 3.8716367e-05 6.5471055e-09 9.9996114e-01 1.5262356e-09\n",
      " 1.6329580e-09 2.8362610e-09 1.8149819e-09 1.1831958e-07 1.3634360e-08], Действие: агент\n",
      "loss =  tensor(0.2195, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2212, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2134, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2150, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2170, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2145, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2086, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2033, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2008, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1993, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1939, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1917, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1919, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1868, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1899, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1853, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2988\n",
      "Reward: 3.3675\n",
      "Episode: 2, Step: 19, State: [0.0, 0.9742063283920288, 1.0, 0.0, 1.0, 1.0, 1.0, 0.9989868402481079, 0.05820105969905853, 0.9989959597587585]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 1.0617966270845816, 10]\n",
      "Episode: 2, Step: 19, Epsilon: 0.5429\n",
      "Episode: 2, Step: 19, Action: [1.4873994e-09 5.3050218e-05 8.5791205e-09 9.9994671e-01 2.0324251e-09\n",
      " 2.1707514e-09 3.7315768e-09 2.3907341e-09 1.4767127e-07 1.7834543e-08], Действие: агент\n",
      "loss =  tensor(0.1993, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1878, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1874, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1857, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1897, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1835, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1870, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1791, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1806, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1770, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1733, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1722, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1703, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1673, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1643, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1620, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3022\n",
      "Reward: 3.7159\n",
      "Episode: 2, Step: 20, State: [0.00671785045415163, 0.9474206566810608, 1.0, 0.0, 1.0, 1.0, 1.0, 0.9939209818840027, 0.06243386119604111, 0.9859437942504883]\n",
      "weights [1.0067622716213627, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 1.0665902830976839, 10]\n",
      "Episode: 2, Step: 20, Epsilon: 0.5404\n",
      "Episode: 2, Step: 20, Action: [1.5284645e-09 5.1822666e-05 8.6975289e-09 9.9994802e-01 2.0906223e-09\n",
      " 2.2234279e-09 3.8045496e-09 2.4540134e-09 1.4779560e-07 1.8011715e-08], Действие: агент\n",
      "loss =  tensor(0.1681, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1731, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1649, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1641, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1664, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1622, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1608, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1628, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1586, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1529, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1576, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1555, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1528, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1490, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1480, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1532, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2919\n",
      "Reward: 3.6394\n",
      "accuracy =  0.2816\n",
      "--------------------------------------\n",
      "Episode: 2, Step: 20, Test Accuracy: 0.2816\n",
      "--------------------------------------\n",
      "Episode: 2, Step: 21, State: [0.1458733230829239, 0.983134925365448, 1.0, 0.0, 1.0, 1.0, 1.0, 0.9868287444114685, 0.017989417538046837, 0.9568272829055786]\n",
      "weights [1.170785149603677, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 1.0183179280767227, 10]\n",
      "Episode: 2, Step: 21, Epsilon: 0.5380\n",
      "Episode: 2, Step: 21, Action: [1.2439219e-09 5.2614218e-05 7.1591910e-09 9.9994719e-01 1.7132186e-09\n",
      " 1.8007500e-09 3.0640612e-09 2.0014010e-09 1.2530840e-07 1.5161124e-08], Действие: агент\n",
      "loss =  tensor(0.1541, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1550, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1511, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1496, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1515, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1494, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1481, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1461, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1438, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1402, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1404, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1399, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1421, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1386, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1382, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1371, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2734\n",
      "Reward: 3.7030\n",
      "Episode: 2, Step: 22, State: [0.34261035919189453, 0.9851190447807312, 1.0, 0.0, 1.0, 1.0, 1.0, 0.9848024249076843, 0.017989417538046837, 0.9367470145225525]\n",
      "weights [1.5211655565566582, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 1.0183179280767227, 10]\n",
      "Episode: 2, Step: 22, Epsilon: 0.5355\n",
      "Episode: 2, Step: 22, Action: [7.3049589e-10 3.9225772e-05 4.2527950e-09 9.9996066e-01 1.0237865e-09\n",
      " 1.0494031e-09 1.7806571e-09 1.1961859e-09 8.0175973e-08 9.3086996e-09], Действие: агент\n",
      "loss =  tensor(0.1398, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1394, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1399, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1397, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1372, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1369, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1354, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1341, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1338, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1320, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1310, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1272, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1302, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1286, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1248, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1263, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2567\n",
      "Reward: 4.5376\n",
      "Episode: 2, Step: 23, State: [0.548944354057312, 0.9404761791229248, 1.0, 0.0, 1.0, 1.0, 0.9979695677757263, 0.9604862928390503, 0.06984127312898636, 0.9106425642967224]\n",
      "weights [2.2170164412721274, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 1.0750841722248325, 10]\n",
      "Episode: 2, Step: 23, Epsilon: 0.5331\n",
      "Episode: 2, Step: 23, Action: [2.83126883e-01 1.86788649e-01 1.32210456e-01 5.23570541e-03\n",
      " 1.72714177e-04 1.91730032e-02 1.21286489e-01 1.51346923e-01\n",
      " 5.85710564e-03 9.48020709e-02], Действие: случайное\n",
      "loss =  tensor(2.2192, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0344, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8818, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7289, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7321, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6563, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6867, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7219, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5338, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5309, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5069, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4334, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5389, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4206, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4624, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5340, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1589\n",
      "Reward: 10.1527\n",
      "Episode: 2, Step: 24, State: [1.0, 1.0, 1.0, 0.5992217659950256, 1.0, 1.0, 1.0, 1.0, 0.7544973492622375, 0.05120481923222542]\n",
      "weights [10, 10, 10, 2.495139256610257, 10, 10, 10, 10, 4.0732591837021666, 1.0539671430704862]\n",
      "Episode: 2, Step: 24, Epsilon: 0.5307\n",
      "Episode: 2, Step: 24, Action: [0.2339887  0.12887434 0.00884159 0.0349199  0.03538041 0.16681592\n",
      " 0.07626551 0.15420725 0.10324317 0.0574632 ], Действие: случайное\n",
      "loss =  tensor(1.5915, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5769, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6335, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5318, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4974, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5089, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4993, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4940, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4834, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3802, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3478, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3553, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3825, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3570, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3106, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2602, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1475\n",
      "Reward: 6.1487\n",
      "Episode: 2, Step: 25, State: [1.0, 0.7966269850730896, 1.0, 0.0038910505827516317, 0.9848942756652832, 1.0, 0.9979695677757263, 0.8642350435256958, 1.0, 0.904618501663208]\n",
      "weights [10, 4.9170490161163665, 10, 1.00390524217234, 10, 10, 10, 7.365616727263034, 10, 10]\n",
      "Episode: 2, Step: 25, Epsilon: 0.5283\n",
      "Episode: 2, Step: 25, Action: [8.9179445e-12 6.3049913e-07 4.8363116e-11 9.9999940e-01 1.2486852e-11\n",
      " 1.1226047e-11 2.0460585e-11 1.5665578e-11 1.5997101e-09 1.0625127e-10], Действие: агент\n",
      "loss =  tensor(0.2722, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2932, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2693, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2712, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2431, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2301, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2245, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2110, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1989, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1935, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1918, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1940, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1853, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1830, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1897, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1729, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2484\n",
      "Reward: 14.4442\n",
      "Episode: 2, Step: 26, State: [0.16410748660564423, 0.1061507910490036, 0.9920870661735535, 0.42023345828056335, 0.9446122646331787, 1.0, 0.9837563633918762, 0.9766970872879028, 0.9989417791366577, 0.986947774887085]\n",
      "weights [1.196324632236047, 1.118755681864838, 10, 1.7248292255793853, 10, 10, 10, 10, 10, 10]\n",
      "Episode: 2, Step: 26, Epsilon: 0.5259\n",
      "Episode: 2, Step: 26, Action: [0.05399705 0.05538303 0.01116862 0.49144621 0.17973857 0.01738528\n",
      " 0.05882843 0.02168548 0.1010762  0.00929113], Действие: случайное\n",
      "loss =  tensor(1.3349, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1066, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0753, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9887, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1692, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1316, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0161, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9892, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8589, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9586, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7734, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8314, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8662, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8257, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7650, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6872, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4041\n",
      "Reward: 28.6816\n",
      "Episode: 2, Step: 27, State: [1.0, 0.0476190485060215, 0.9920870661735535, 0.5661478638648987, 0.11278952658176422, 0.9213930368423462, 0.5279187560081482, 0.5075987577438354, 0.42010581493377686, 0.8313252925872803]\n",
      "weights [10, 1.0499988984790443, 10, 2.304927443669789, 1.127126992786978, 10, 2.118274967395851, 2.030859964036812, 1.7244495656327987, 5.928535977935319]\n",
      "Episode: 2, Step: 27, Epsilon: 0.5235\n",
      "Episode: 2, Step: 27, Action: [0.06185792 0.0098602  0.04441704 0.000762   0.02812738 0.00133747\n",
      " 0.01627212 0.18347705 0.03740383 0.61648499], Действие: случайное\n",
      "loss =  tensor(2.6201, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.6995, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.9739, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.9017, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.3763, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.3245, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.2953, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.6359, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8928, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8959, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0317, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7552, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9022, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.1630, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0218, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6881, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.203\n",
      "Reward: 8.1543\n",
      "Episode: 2, Step: 28, State: [0.9980806112289429, 1.0, 1.0, 0.09241244941949844, 1.0, 1.0, 1.0, 1.0, 0.8783068656921387, 0.01606425642967224]\n",
      "weights [10, 10, 10, 1.1018208629454296, 10, 10, 10, 10, 8.217322927580092, 1.0163254970755384]\n",
      "Episode: 2, Step: 28, Epsilon: 0.5212\n",
      "Episode: 2, Step: 28, Action: [5.0662623e-11 1.1708998e-06 2.2927793e-10 9.9999881e-01 6.1500985e-11\n",
      " 6.1349266e-11 9.1640043e-11 7.4550303e-11 5.4750058e-09 4.8678600e-10], Действие: агент\n",
      "loss =  tensor(0.3009, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3200, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3217, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2986, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3041, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2842, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2929, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2697, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2306, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2253, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2152, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2147, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2087, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2114, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2016, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1939, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1107\n",
      "Reward: 10.0663\n",
      "Episode: 2, Step: 29, State: [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9347389340400696]\n",
      "weights [0.9999990000010001, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "Episode: 2, Step: 29, Epsilon: 0.5188\n",
      "Episode: 2, Step: 29, Action: [0.02573723 0.30327973 0.25758477 0.00432856 0.05767456 0.03061109\n",
      " 0.14790628 0.05751583 0.09651652 0.01884542], Действие: случайное\n",
      "loss =  tensor(2.1589, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0577, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8810, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7412, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7405, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8085, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7405, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8701, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5640, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6341, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5976, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6339, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5887, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4418, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4365, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5456, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2897\n",
      "Reward: 19.5176\n",
      "Episode: 2, Step: 30, State: [0.0, 1.0, 1.0, 0.009727626107633114, 1.0, 1.0, 1.0, 0.9888551235198975, 0.5894179940223694, 0.5602409839630127]\n",
      "weights [0.9999990000010001, 10, 10, 1.0098221626109178, 10, 10, 10, 10, 2.435561105650052, 2.2739675357749944]\n",
      "Episode: 2, Step: 30, Epsilon: 0.5165\n",
      "Episode: 2, Step: 30, Action: [0.0520068  0.10799516 0.02000599 0.16948494 0.00885841 0.22287705\n",
      " 0.0506487  0.33403334 0.028878   0.00521162], Действие: случайное\n",
      "loss =  tensor(1.7068, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4812, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8091, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5843, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4957, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5344, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6580, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6446, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3984, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4078, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5530, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3020, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3188, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3195, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3057, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2815\n",
      "Reward: 12.7533\n",
      "accuracy =  0.2529\n",
      "--------------------------------------\n",
      "Episode: 2, Step: 30, Test Accuracy: 0.2529\n",
      "--------------------------------------\n",
      "Episode: 2, Step: 31, State: [0.5134357213973999, 0.8898809552192688, 0.9831849932670593, 0.0, 0.9989929795265198, 0.9950248599052429, 0.9939086437225342, 0.06889564543962479, 0.8158730268478394, 0.9528112411499023]\n",
      "weights [2.0552226884580995, 9.080998849856806, 10, 0.9999990000010001, 10, 10, 10, 1.0739923200980341, 5.431005310494646, 10]\n",
      "Episode: 2, Step: 31, Epsilon: 0.5142\n",
      "Episode: 2, Step: 31, Action: [0.0895458  0.00255396 0.08722085 0.09026523 0.19310813 0.24151591\n",
      " 0.01267608 0.08400096 0.00468913 0.19442396], Действие: случайное\n",
      "loss =  tensor(1.7408, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8319, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8346, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5805, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6684, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7371, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5663, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4677, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4974, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4914, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3668, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3584, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3302, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2455, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3697, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2566\n",
      "Reward: 8.7534\n",
      "Episode: 2, Step: 32, State: [1.0, 1.0, 1.0, 0.030155641958117485, 1.0, 0.5681592226028442, 0.8700507879257202, 0.10131712257862091, 0.9989417791366577, 0.8805220723152161]\n",
      "weights [10, 10, 10, 1.0310922166179148, 10, 2.315662940318813, 7.695254852130584, 1.1127383333829581, 10, 8.369676723566322]\n",
      "Episode: 2, Step: 32, Epsilon: 0.5118\n",
      "Episode: 2, Step: 32, Action: [0.20550145 0.00345218 0.09057031 0.08320261 0.16236666 0.0091533\n",
      " 0.23079027 0.07597799 0.10059646 0.03838876], Действие: случайное\n",
      "loss =  tensor(1.4976, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4830, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5568, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4452, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4801, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4490, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4909, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3957, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1853, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2826, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2539, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3110, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2619, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1813, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2372, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2591, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3815\n",
      "Reward: 25.9657\n",
      "Episode: 2, Step: 33, State: [0.0019193857442587614, 0.3611111044883728, 0.9673590660095215, 0.23249027132987976, 0.7713997960090637, 0.998009979724884, 0.8233502507209778, 0.5633231997489929, 0.8296296000480652, 0.6847389340400696]\n",
      "weights [1.001922073021743, 1.5652149251776684, 10, 1.3029133830255613, 4.374430154093364, 10, 5.660887395504259, 2.2900179478443587, 5.869529746671801, 3.171964241733731]\n",
      "Episode: 2, Step: 33, Epsilon: 0.5095\n",
      "Episode: 2, Step: 33, Action: [0.18257783 0.19770214 0.24328736 0.03988124 0.02091322 0.00278839\n",
      " 0.1402215  0.05615321 0.02315825 0.09331686], Действие: случайное\n",
      "loss =  tensor(1.5197, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4239, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3774, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4432, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3834, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3356, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4801, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3085, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3331, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2520, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2404, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1644, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1326, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1329, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2269, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0635, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4054\n",
      "Reward: 12.8651\n",
      "Episode: 2, Step: 34, State: [0.0, 0.9176587462425232, 0.578635036945343, 0.0593385212123394, 0.8831822872161865, 0.998009979724884, 0.6558375358581543, 0.8986828923225403, 0.8370370268821716, 0.17168675363063812]\n",
      "weights [0.9999990000010001, 10, 2.373233928888286, 1.0630805656124547, 8.560272375630568, 10, 2.9055960442909003, 9.8699040371287, 6.136325599259701, 1.2072712794487903]\n",
      "Episode: 2, Step: 34, Epsilon: 0.5073\n",
      "Episode: 2, Step: 34, Action: [0.17316898 0.23564608 0.13933966 0.0410811  0.16098226 0.10777109\n",
      " 0.02343621 0.02896293 0.07368778 0.01592391], Действие: случайное\n",
      "loss =  tensor(1.6402, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6067, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6279, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5026, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5552, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4816, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5677, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4671, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4491, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4112, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2675, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2887, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2528, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2353, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2305, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1635, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1564\n",
      "Reward: 1.6980\n",
      "Episode: 2, Step: 35, State: [0.0, 1.0, 0.9990108609199524, 0.8365758657455444, 0.9979858994483948, 1.0, 1.0, 1.0, 0.9841269850730896, 0.6626505851745605]\n",
      "weights [0.9999990000010001, 10, 10, 6.119009811813793, 10, 10, 10, 10, 10, 2.9642767758784165]\n",
      "Episode: 2, Step: 35, Epsilon: 0.5050\n",
      "Episode: 2, Step: 35, Action: [1.1635191e-11 2.1928206e-07 7.3229860e-11 9.9999976e-01 1.4264872e-11\n",
      " 1.6237980e-11 2.5128058e-11 1.8774010e-11 1.7919567e-09 1.3323240e-10], Действие: агент\n",
      "loss =  tensor(0.4164, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4180, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4182, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4097, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4048, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3983, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3849, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3994, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3455, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3374, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3318, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3238, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3157, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3138, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3106, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3096, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3414\n",
      "Reward: 14.2727\n",
      "Episode: 2, Step: 36, State: [0.0, 0.8521825671195984, 1.0, 0.0, 1.0, 0.998009979724884, 0.9989847540855408, 0.996960461139679, 0.7111111283302307, 0.0803212821483612]\n",
      "weights [0.9999990000010001, 6.765056160547243, 10, 0.9999990000010001, 10, 10, 10, 10, 3.461526685653772, 1.0873350587049897]\n",
      "Episode: 2, Step: 36, Epsilon: 0.5027\n",
      "Episode: 2, Step: 36, Action: [0.04713462 0.00210673 0.07993525 0.20006331 0.14544164 0.27200616\n",
      " 0.03128348 0.03328442 0.08643282 0.10231156], Действие: случайное\n",
      "loss =  tensor(1.6754, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5439, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6694, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5571, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4740, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5019, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4524, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5358, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2464, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3251, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1807, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1515, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1387, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2091, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1347, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1897, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3724\n",
      "Reward: 8.1682\n",
      "Episode: 2, Step: 37, State: [0.0, 1.0, 0.9940652847290039, 0.022373540326952934, 0.9436052441596985, 0.8537313342094421, 0.9644669890403748, 0.8571428656578064, 0.6253968477249146, 0.05823293328285217]\n",
      "weights [0.9999990000010001, 10, 10, 1.0228845252919094, 10, 6.836687529127813, 10, 6.999951417569695, 2.669484558371002, 1.0618325629640846]\n",
      "Episode: 2, Step: 37, Epsilon: 0.5004\n",
      "Episode: 2, Step: 37, Action: [0.06253456 0.12949612 0.02992338 0.15322804 0.30567514 0.03895214\n",
      " 0.16513605 0.07386786 0.03355653 0.00763016], Действие: случайное\n",
      "loss =  tensor(1.6017, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5200, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4973, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5393, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5963, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3787, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3815, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5912, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2873, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2821, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2382, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1520, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2394, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1200, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1529, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1400, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3902\n",
      "Reward: 12.8447\n",
      "Episode: 2, Step: 38, State: [0.061420343816280365, 0.988095223903656, 1.0, 0.03599221631884575, 0.9979858994483948, 0.9661691784858704, 0.41624364256858826, 0.6028369069099426, 0.426455020904541, 0.6224899888038635]\n",
      "weights [1.0654385357418426, 10, 10, 1.037334946452884, 10, 10, 1.7130405077892221, 2.5178509774629827, 1.7435393786163453, 2.648929356607425]\n",
      "Episode: 2, Step: 38, Epsilon: 0.4982\n",
      "Episode: 2, Step: 38, Action: [1.7888466e-08 2.8729800e-04 7.7624101e-08 9.9971169e-01 2.0948107e-08\n",
      " 2.1176326e-08 3.7284185e-08 2.5596883e-08 7.8721075e-07 1.4108703e-07], Действие: агент\n",
      "loss =  tensor(0.4104, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4021, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3843, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3810, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3880, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3891, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3894, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3801, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3404, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3191, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3217, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3105, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3107, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3084, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3003, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2950, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4009\n",
      "Reward: 16.3368\n",
      "Episode: 2, Step: 39, State: [0.5806142091751099, 0.2202380895614624, 0.9337289929389954, 0.005836575757712126, 0.773413896560669, 0.8507462739944458, 0.2609136998653412, 0.6514691114425659, 0.7809523940086365, 0.9568272829055786]\n",
      "weights [2.384433706252656, 1.2824410940982065, 10, 1.0058698295929869, 4.413313841878698, 6.6999553499082305, 1.353020136887488, 2.869177922682996, 4.565196822295355, 10]\n",
      "Episode: 2, Step: 39, Epsilon: 0.4960\n",
      "Episode: 2, Step: 39, Action: [5.6763594e-09 1.3140675e-04 2.0125132e-08 9.9986827e-01 7.7739211e-09\n",
      " 6.1184275e-09 1.1136583e-08 9.2940189e-09 2.1235800e-07 3.8379774e-08], Действие: агент\n",
      "loss =  tensor(0.3314, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3242, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3248, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3059, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3080, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3016, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2915, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2948, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2817, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2708, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2624, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2589, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2540, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2507, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2438, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2451, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3263\n",
      "Reward: 9.1875\n",
      "Episode: 2, Step: 40, State: [0.6132437586784363, 0.9057539701461792, 1.0, 0.0, 0.9989929795265198, 0.9880596995353699, 0.5512690544128418, 0.4478216767311096, 0.48465609550476074, 0.7489959597587585]\n",
      "weights [2.5856012329154154, 10, 10, 0.9999990000010001, 10, 10, 2.228501914860367, 1.811005877728308, 1.940448020883144, 3.983983744067044]\n",
      "Episode: 2, Step: 40, Epsilon: 0.4937\n",
      "Episode: 2, Step: 40, Action: [0.08100573 0.02468358 0.0910166  0.01433977 0.17140134 0.04766657\n",
      " 0.05790878 0.08416868 0.15987347 0.26793549], Действие: случайное\n",
      "loss =  tensor(1.9205, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8431, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.1476, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8997, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7804, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8224, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5555, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4451, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3816, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4075, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2973, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4213, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2375, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4313, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3417, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3636, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1899\n",
      "Reward: 5.1393\n",
      "accuracy =  0.1354\n",
      "--------------------------------------\n",
      "Episode: 2, Step: 40, Test Accuracy: 0.1354\n",
      "--------------------------------------\n",
      "Episode: 2, Step: 41, State: [1.0, 1.0, 1.0, 0.994163453578949, 1.0, 1.0, 0.8274111747741699, 0.6301925182342529, 0.26455026865005493, 0.33433735370635986]\n",
      "weights [10, 10, 10, 10, 10, 10, 5.794084319232153, 2.704102391662947, 1.3597103889807352, 1.5022601963738247]\n",
      "Episode: 2, Step: 41, Epsilon: 0.4915\n",
      "Episode: 2, Step: 41, Action: [0.1013828  0.04119212 0.12670011 0.00878746 0.34525661 0.17951869\n",
      " 0.06598411 0.00716471 0.04065645 0.08335695], Действие: случайное\n",
      "loss =  tensor(1.6442, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6086, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5320, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5088, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4582, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6362, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5139, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5023, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3410, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2859, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3021, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3249, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2794, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3728, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2065, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2280, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3468\n",
      "Reward: 24.8607\n",
      "Episode: 2, Step: 42, State: [0.0019193857442587614, 0.6795634627342224, 1.0, 0.0, 0.9969788789749146, 1.0, 1.0, 0.975683867931366, 0.9375661611557007, 0.005020080134272575]\n",
      "weights [1.001922073021743, 3.1207330094120005, 10, 0.9999990000010001, 10, 10, 10, 10, 10, 1.0050443983739406]\n",
      "Episode: 2, Step: 42, Epsilon: 0.4893\n",
      "Episode: 2, Step: 42, Action: [1.1721240e-09 2.7364572e-06 4.2318797e-09 9.9999714e-01 1.3238959e-09\n",
      " 1.4076841e-09 2.0616076e-09 1.5761404e-09 5.7220564e-08 7.5698123e-09], Действие: агент\n",
      "loss =  tensor(0.4116, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4076, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3966, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4029, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3818, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3795, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3551, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3527, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3251, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3235, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3155, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3046, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2869, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2901, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2838, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2704, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1885\n",
      "Reward: 1.9562\n",
      "Episode: 2, Step: 43, State: [0.0, 1.0, 1.0, 0.9562256932258606, 1.0, 1.0, 1.0, 1.0, 0.988359808921814, 0.2098393589258194]\n",
      "weights [0.9999990000010001, 10, 10, 10, 10, 10, 10, 10, 10, 1.2655638391159507]\n",
      "Episode: 2, Step: 43, Epsilon: 0.4871\n",
      "Episode: 2, Step: 43, Action: [2.6252131e-11 3.0042816e-07 1.4443106e-10 9.9999964e-01 3.2297758e-11\n",
      " 3.5799006e-11 4.8479033e-11 3.8869387e-11 2.7649643e-09 2.5279495e-10], Действие: агент\n",
      "loss =  tensor(0.2940, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3011, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2908, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2824, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2863, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2795, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2806, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2730, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2563, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2567, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2528, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2374, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2436, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2412, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2319, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2375, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3301\n",
      "Reward: 15.0639\n",
      "Episode: 2, Step: 44, State: [0.0, 0.9751983880996704, 1.0, 0.0, 1.0, 1.0, 0.9878172874450684, 0.9746707081794739, 0.7777777910232544, 0.03714859485626221]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 4.499980018309628, 1.0385807779653586]\n",
      "Episode: 2, Step: 44, Epsilon: 0.4850\n",
      "Episode: 2, Step: 44, Action: [1.2842879e-09 4.5371821e-06 5.0736282e-09 9.9999535e-01 1.4021346e-09\n",
      " 1.5399378e-09 2.3138997e-09 1.6493099e-09 7.0590218e-08 9.2772758e-09], Действие: агент\n",
      "loss =  tensor(0.2384, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2407, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2403, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2382, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2340, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2366, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2279, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2303, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2206, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2153, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2101, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2068, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2061, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2033, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2062, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2026, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3644\n",
      "Reward: 7.8058\n",
      "Episode: 2, Step: 45, State: [0.0, 0.9732142686843872, 1.0, 0.0, 1.0, 0.9940298795700073, 0.9015228152275085, 0.825734555721283, 0.5947089791297913, 0.10742972046136856]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 10, 5.738339381049326, 2.467356741573359, 1.1203587017911871]\n",
      "Episode: 2, Step: 45, Epsilon: 0.4828\n",
      "Episode: 2, Step: 45, Action: [4.5500634e-09 2.1201577e-05 1.7645693e-08 9.9997854e-01 5.0171325e-09\n",
      " 5.4762626e-09 8.2678460e-09 5.8467449e-09 2.0319803e-07 3.1664889e-08], Действие: агент\n",
      "loss =  tensor(0.2037, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2128, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1997, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2067, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2023, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2005, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2002, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1974, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1939, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1875, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1831, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1878, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1813, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1792, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1788, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1764, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3906\n",
      "Reward: 8.3976\n",
      "Episode: 2, Step: 46, State: [0.0, 0.9573412537574768, 0.9990108609199524, 0.0, 1.0, 0.9830845594406128, 0.8101522922515869, 0.6869301199913025, 0.5312169194221497, 0.1606425642967224]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 5.267352155618551, 3.1941648484592973, 2.1331782401128945, 1.1913861319117198]\n",
      "Episode: 2, Step: 46, Epsilon: 0.4806\n",
      "Episode: 2, Step: 46, Action: [0.12873744 0.08000057 0.06892785 0.07558959 0.26397889 0.0788837\n",
      " 0.02610941 0.0466894  0.18935176 0.0417314 ], Действие: случайное\n",
      "loss =  tensor(1.4736, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4032, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3661, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3842, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4243, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3886, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2560, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3083, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1639, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1472, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2574, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1608, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1607, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1143, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0584, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0866, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2224\n",
      "Reward: 5.7922\n",
      "Episode: 2, Step: 47, State: [1.0, 1.0, 1.0, 0.2665369510650635, 0.7593151926994324, 0.9960198998451233, 0.9746192693710327, 0.9554204940795898, 0.051851850003004074, 0.736947774887085]\n",
      "weights [10, 10, 10, 1.3633933407535113, 4.154794215810171, 10, 10, 10, 1.05468638557886, 3.8015120307715375]\n",
      "Episode: 2, Step: 47, Epsilon: 0.4785\n",
      "Episode: 2, Step: 47, Action: [0.16031709 0.00682313 0.03140192 0.09856107 0.061587   0.09506671\n",
      " 0.00118786 0.05262533 0.31231261 0.18011728], Действие: случайное\n",
      "loss =  tensor(1.3770, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4295, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3028, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2625, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1747, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3225, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3055, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1962, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2460, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0967, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0807, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0253, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9688, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0572, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0225, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9944, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3045\n",
      "Reward: 8.8329\n",
      "Episode: 2, Step: 48, State: [0.7840691208839417, 1.0, 0.9980217814445496, 0.021400777623057365, 0.669687807559967, 0.9960198998451233, 0.9949238300323486, 0.9685916900634766, 0.22857142984867096, 0.2821285128593445]\n",
      "weights [4.631090157199639, 10, 10, 1.0218677424485751, 3.0274297935634107, 10, 10, 10, 1.296294618060639, 1.3930050502187112]\n",
      "Episode: 2, Step: 48, Epsilon: 0.4763\n",
      "Episode: 2, Step: 48, Action: [8.4567775e-10 1.7383803e-05 3.5803895e-09 9.9998260e-01 1.0407254e-09\n",
      " 9.9423070e-10 1.4506256e-09 1.1189957e-09 5.0373966e-08 7.5279463e-09], Действие: агент\n",
      "loss =  tensor(0.2790, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2829, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2852, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2696, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2724, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2605, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2516, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2418, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2248, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2219, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2226, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2061, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2123, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1995, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2035, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2020, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1798\n",
      "Reward: 5.6863\n",
      "Episode: 2, Step: 49, State: [0.0, 1.0, 1.0, 0.9892995953559875, 1.0, 1.0, 0.9989847540855408, 1.0, 0.7470899224281311, 0.49297189712524414]\n",
      "weights [0.9999990000010001, 10, 10, 10, 10, 10, 10, 10, 3.953958875984123, 1.9722733750985801]\n",
      "Episode: 2, Step: 49, Epsilon: 0.4742\n",
      "Episode: 2, Step: 49, Action: [2.1888253e-11 3.9245634e-07 1.3439623e-10 9.9999964e-01 2.6376302e-11\n",
      " 3.0789298e-11 4.4024461e-11 3.3519909e-11 2.5427096e-09 2.3265298e-10], Действие: агент\n",
      "loss =  tensor(0.2221, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2128, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2153, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2086, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2090, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2050, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1972, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1975, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1877, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1874, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1822, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1837, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1753, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1776, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1749, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1752, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3425\n",
      "Reward: 15.6219\n",
      "Episode: 2, Step: 50, State: [0.0, 1.0, 0.9990108609199524, 0.009727626107633114, 0.9989929795265198, 0.9990049600601196, 0.9837563633918762, 0.9685916900634766, 0.22751322388648987, 0.41265061497688293]\n",
      "weights [0.9999990000010001, 10, 10, 1.0098221626109178, 10, 10, 10, 10, 1.2945188660863145, 1.7025612402733705]\n",
      "Episode: 2, Step: 50, Epsilon: 0.4721\n",
      "Episode: 2, Step: 50, Action: [0.25431738 0.07131568 0.02572352 0.0093574  0.02218063 0.3292801\n",
      " 0.12461478 0.06994132 0.02525859 0.06801058], Действие: случайное\n",
      "loss =  tensor(1.5994, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6197, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5002, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4674, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4950, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4562, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4289, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3259, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2371, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3203, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2491, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2278, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1686, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1830, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2203, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1173, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3342\n",
      "Reward: 15.3506\n",
      "accuracy =  0.2216\n",
      "--------------------------------------\n",
      "Episode: 2, Step: 50, Test Accuracy: 0.2216\n",
      "--------------------------------------\n",
      "Episode: 2, Step: 51, State: [0.8368521928787231, 1.0, 1.0, 0.019455252215266228, 0.8912386894226074, 0.21293532848358154, 0.8081218004226685, 0.8156028389930725, 0.8380952477455139, 0.2560240924358368]\n",
      "weights [6.129373653689352, 10, 10, 1.0198402290349202, 9.19436149058662, 1.2705420096309457, 5.2116123175559625, 5.423047575634075, 6.1764328078238, 1.3441277408381878]\n",
      "Episode: 2, Step: 51, Epsilon: 0.4700\n",
      "Episode: 2, Step: 51, Action: [2.2701834e-09 5.0373095e-05 8.4265377e-09 9.9994946e-01 2.5776905e-09\n",
      " 2.2724667e-09 4.0568469e-09 3.1032570e-09 1.0281261e-07 1.5373910e-08], Действие: агент\n",
      "loss =  tensor(0.2031, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2075, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2102, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2148, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2074, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1999, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2114, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2051, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1901, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1942, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1898, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1782, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1855, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1833, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1765, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1804, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3682\n",
      "Reward: 11.3552\n",
      "Episode: 2, Step: 52, State: [0.0, 1.0, 1.0, 0.0, 0.9979858994483948, 0.806965172290802, 0.8619289398193359, 0.8753799200057983, 0.7989417910575867, 0.029116466641426086]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 5.180385485260625, 7.242594907988795, 8.024324617043343, 4.973659278080699, 1.0299885986860942]\n",
      "Episode: 2, Step: 52, Epsilon: 0.4679\n",
      "Episode: 2, Step: 52, Action: [0.11293249 0.02366516 0.0833023  0.02771575 0.15494711 0.15228711\n",
      " 0.07198252 0.03850543 0.05943027 0.27523186], Действие: случайное\n",
      "loss =  tensor(1.4560, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3099, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3656, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6167, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3809, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4864, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3391, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3785, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2225, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1690, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1204, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1078, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1265, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1996, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0964, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0090, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3346\n",
      "Reward: 4.8080\n",
      "Episode: 2, Step: 53, State: [0.0009596928721293807, 1.0, 1.0, 0.03307392820715904, 1.0, 0.9293532371520996, 0.9695431590080261, 0.9888551235198975, 0.7682539820671082, 0.01606425642967224]\n",
      "weights [1.000959612846125, 10, 10, 1.0342041599330096, 10, 10, 10, 10, 4.31505013061085, 1.0163254970755384]\n",
      "Episode: 2, Step: 53, Epsilon: 0.4658\n",
      "Episode: 2, Step: 53, Action: [1.3446139e-09 4.3358395e-06 5.2936007e-09 9.9999559e-01 1.4456478e-09\n",
      " 1.5765650e-09 2.3936981e-09 1.7028891e-09 6.8054241e-08 9.4205346e-09], Действие: агент\n",
      "loss =  tensor(0.2306, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2352, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2288, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2528, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2205, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2248, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2152, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2170, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1993, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1930, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1891, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1860, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1915, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1891, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1799, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1840, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2051\n",
      "Reward: 2.2311\n",
      "Episode: 2, Step: 54, State: [0.0, 1.0, 1.0, 0.9961089491844177, 1.0, 1.0, 1.0, 0.9989868402481079, 0.9428571462631226, 0.046184737235307693]\n",
      "weights [0.9999990000010001, 10, 10, 10, 10, 10, 10, 10, 10, 1.0484199515548638]\n",
      "Episode: 2, Step: 54, Epsilon: 0.4637\n",
      "Episode: 2, Step: 54, Action: [3.6506055e-11 3.1415107e-07 1.9007063e-10 9.9999964e-01 4.4532704e-11\n",
      " 4.8842114e-11 6.3186865e-11 5.1663274e-11 3.1035430e-09 3.2246006e-10], Действие: агент\n",
      "loss =  tensor(0.1935, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1973, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1931, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1880, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1862, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1824, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1868, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1799, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1784, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1743, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1668, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1621, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1648, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1647, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1594, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1602, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3216\n",
      "Reward: 13.7936\n",
      "Episode: 2, Step: 55, State: [0.0, 1.0, 1.0, 0.05447470769286156, 1.0, 0.9990049600601196, 0.9837563633918762, 0.9858155846595764, 0.8010581731796265, 0.01305220928043127]\n",
      "weights [0.9999990000010001, 10, 10, 1.057612049644799, 10, 10, 10, 10, 5.026569773751657, 1.0132237958069898]\n",
      "Episode: 2, Step: 55, Epsilon: 0.4617\n",
      "Episode: 2, Step: 55, Action: [0.14053742 0.03092353 0.08941679 0.04867553 0.16583824 0.0633388\n",
      " 0.02118455 0.15794646 0.12419604 0.15794263], Действие: случайное\n",
      "loss =  tensor(1.4283, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3369, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1444, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4245, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2740, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3665, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3646, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1497, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1191, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1630, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1144, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1118, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9840, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0263, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9708, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.273\n",
      "Reward: 9.5856\n",
      "Episode: 2, Step: 56, State: [1.0, 1.0, 1.0, 0.05058365687727928, 0.9869083762168884, 0.96517413854599, 0.9583756327629089, 0.7102330327033997, 0.16719576716423035, 0.4056224822998047]\n",
      "weights [10, 10, 10, 1.0532775783417947, 10, 10, 10, 3.45103708090833, 1.2007609469442435, 1.6824295801760456]\n",
      "Episode: 2, Step: 56, Epsilon: 0.4596\n",
      "Episode: 2, Step: 56, Action: [4.8479631e-10 1.8949837e-05 2.2790623e-09 9.9998105e-01 6.3092270e-10\n",
      " 5.9935418e-10 9.3034347e-10 7.2364897e-10 3.4602092e-08 4.8122213e-09], Действие: агент\n",
      "loss =  tensor(0.2008, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2002, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2037, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1967, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1905, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1912, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1908, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1867, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1762, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1703, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1691, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1647, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1679, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1646, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1631, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1634, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.352\n",
      "Reward: 13.5402\n",
      "Episode: 2, Step: 57, State: [0.0, 1.0, 1.0, 0.0009727626456879079, 1.0, 1.0, 0.9939086437225342, 0.9017223715782166, 0.5216931104660034, 0.1004016101360321]\n",
      "weights [0.9999990000010001, 10, 10, 1.0009727078868775, 10, 10, 10, 10, 2.0907035444769164, 1.1116059117728103]\n",
      "Episode: 2, Step: 57, Epsilon: 0.4576\n",
      "Episode: 2, Step: 57, Action: [2.6487461e-09 1.0928685e-05 1.0538944e-08 9.9998891e-01 2.9175244e-09\n",
      " 3.2030396e-09 4.7946038e-09 3.3455201e-09 1.2164686e-07 1.8789025e-08], Действие: агент\n",
      "loss =  tensor(0.1737, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1668, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1702, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1651, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1681, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1604, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1597, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1573, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1570, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1518, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1490, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1459, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1449, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1443, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1456, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1446, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3446\n",
      "Reward: 4.5378\n",
      "Episode: 2, Step: 58, State: [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.9959390759468079, 0.9402229189872742, 0.5820105671882629, 0.07831325381994247]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 2.3923992548662, 1.084966144059643]\n",
      "Episode: 2, Step: 58, Epsilon: 0.4555\n",
      "Episode: 2, Step: 58, Action: [0.19034274 0.09975622 0.01222913 0.16669603 0.03043258 0.12442849\n",
      " 0.02379059 0.0107078  0.0355123  0.30610412], Действие: случайное\n",
      "loss =  tensor(0.9878, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0559, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0448, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0285, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9317, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0291, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9753, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9439, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7907, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8353, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8066, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7798, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7915, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7968, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7333, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3416\n",
      "Reward: 15.6900\n",
      "Episode: 2, Step: 59, State: [1.0, 1.0, 1.0, 0.1157587543129921, 0.7341389656066895, 0.16517412662506104, 0.92081218957901, 0.8632218837738037, 0.7492063641548157, 0.04216867312788963]\n",
      "weights [10, 10, 10, 1.130911811641678, 3.7613493866545147, 1.197853150027764, 10, 7.311057620421131, 3.987326110983094, 1.044024065533048]\n",
      "Episode: 2, Step: 59, Epsilon: 0.4535\n",
      "Episode: 2, Step: 59, Action: [2.4290272e-09 4.7182999e-05 8.3758174e-09 9.9995267e-01 2.7128579e-09\n",
      " 2.3692539e-09 3.8483572e-09 3.1290979e-09 8.9940208e-08 1.5254029e-08], Действие: агент\n",
      "loss =  tensor(0.1651, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1638, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1700, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1653, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1658, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1667, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1599, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1602, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1528, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1493, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1488, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1484, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1404, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1426, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1424, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1393, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3715\n",
      "Reward: 15.1817\n",
      "Episode: 2, Step: 60, State: [0.0, 0.932539701461792, 0.9713155031204224, 0.0, 0.826787531375885, 0.7820895314216614, 0.9360405802726746, 0.975683867931366, 0.920634925365448, 0.001004016026854515]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 5.77322310986144, 4.589019598298483, 10, 10, 10, 1.0010040230780932]\n",
      "Episode: 2, Step: 60, Epsilon: 0.4515\n",
      "Episode: 2, Step: 60, Action: [0.00298834 0.09448717 0.3951478  0.02307584 0.02351623 0.08666453\n",
      " 0.27606038 0.06189649 0.02825171 0.00791151], Действие: случайное\n",
      "loss =  tensor(2.1004, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.1359, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.1038, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9534, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0391, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9717, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9034, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7514, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6794, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6429, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4361, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5145, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5402, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4144, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3901, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3615\n",
      "Reward: 9.0540\n",
      "accuracy =  0.3082\n",
      "--------------------------------------\n",
      "Episode: 2, Step: 60, Test Accuracy: 0.3082\n",
      "--------------------------------------\n",
      "Episode: 2, Step: 61, State: [0.0, 1.0, 1.0, 0.0, 1.0, 0.998009979724884, 0.7563451528549194, 0.9665653705596924, 0.6687830686569214, 0.03915662690997124]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 4.104149404650108, 10, 3.019160212567691, 1.0407512683703903]\n",
      "Episode: 2, Step: 61, Epsilon: 0.4495\n",
      "Episode: 2, Step: 61, Action: [2.9818017e-09 1.0264442e-05 1.1509258e-08 9.9998963e-01 3.1872214e-09\n",
      " 3.4131862e-09 5.2642695e-09 3.7157777e-09 1.2667704e-07 2.0461547e-08], Действие: агент\n",
      "loss =  tensor(0.1842, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1916, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1836, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1824, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1831, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1950, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1773, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1753, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1674, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1626, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1681, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1659, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1618, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1598, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1604, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1600, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3372\n",
      "Reward: 4.9066\n",
      "Episode: 2, Step: 62, State: [0.0, 0.9940476417541504, 1.0, 0.0, 1.0, 1.0, 0.8649746179580688, 0.9675785303115845, 0.6126984357833862, 0.23192770779132843]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 7.405960115923565, 10, 2.5819607004737306, 1.3019590840405346]\n",
      "Episode: 2, Step: 62, Epsilon: 0.4475\n",
      "Episode: 2, Step: 62, Action: [1.4597035e-09 6.4862597e-06 6.0959069e-09 9.9999344e-01 1.6195919e-09\n",
      " 1.7248722e-09 2.7425091e-09 1.8958581e-09 7.4567232e-08 1.0927571e-08], Действие: агент\n",
      "loss =  tensor(0.1643, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1647, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1662, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1662, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1646, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1603, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1541, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1536, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1466, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1483, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1455, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1455, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1436, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1374, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1420, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1378, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4111\n",
      "Reward: 15.0785\n",
      "Episode: 2, Step: 63, State: [0.016314778476953506, 0.5823412537574768, 0.9545004963874817, 0.0, 0.9979858994483948, 0.9492537379264832, 0.40406090021133423, 0.7882472276687622, 0.6772486567497253, 0.5612449645996094]\n",
      "weights [1.0165843315886796, 2.3942934625529566, 10, 0.9999990000010001, 10, 10, 1.678020996329368, 4.722466046251779, 3.0983508591432947, 2.2791709271587375]\n",
      "Episode: 2, Step: 63, Epsilon: 0.4455\n",
      "Episode: 2, Step: 63, Action: [0.07092284 0.14243941 0.01168143 0.19947053 0.05238373 0.04246075\n",
      " 0.15870721 0.22278877 0.00746522 0.09168012], Действие: случайное\n",
      "loss =  tensor(1.4307, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4921, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4381, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4187, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3721, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3087, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2227, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2825, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0667, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2076, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1428, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0106, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0177, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0866, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0309, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0184, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2711\n",
      "Reward: 8.2151\n",
      "Episode: 2, Step: 64, State: [1.0, 1.0, 0.9990108609199524, 0.11770427972078323, 0.9707955718040466, 0.9243780970573425, 0.8852791786193848, 0.06585612893104553, 0.8359788656234741, 0.48995983600616455]\n",
      "weights [10, 10, 10, 1.1334055505539384, 10, 10, 8.71673747823683, 1.0704977685695438, 6.096738125016836, 1.9606260643152449]\n",
      "Episode: 2, Step: 64, Epsilon: 0.4436\n",
      "Episode: 2, Step: 64, Action: [4.8479837e-10 1.2920376e-05 1.9475612e-09 9.9998701e-01 5.8165367e-10\n",
      " 5.3210769e-10 8.8192614e-10 7.1115114e-10 2.5365461e-08 3.6053636e-09], Действие: агент\n",
      "loss =  tensor(0.1609, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1677, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1669, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1689, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1650, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1674, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1630, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1613, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1563, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1433, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1494, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1481, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1466, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1430, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1398, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1370, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3646\n",
      "Reward: 17.4806\n",
      "Episode: 2, Step: 65, State: [0.0019193857442587614, 0.6746031641960144, 0.9891197085380554, 0.13813228905200958, 0.9989929795265198, 1.0, 0.9786801934242249, 0.5400202870368958, 0.8370370268821716, 0.24598392844200134]\n",
      "weights [1.001922073021743, 3.073161189069444, 10, 1.1602695251578115, 10, 10, 10, 2.1740041958676897, 6.136325599259701, 1.3262299193488225]\n",
      "Episode: 2, Step: 65, Epsilon: 0.4416\n",
      "Episode: 2, Step: 65, Action: [2.3256288e-09 6.7195001e-06 8.3175218e-09 9.9999321e-01 2.6412910e-09\n",
      " 2.7555700e-09 4.1373500e-09 3.1652416e-09 8.1466538e-08 1.3591643e-08], Действие: агент\n",
      "loss =  tensor(0.1488, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1428, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1431, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1438, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1385, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1389, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1371, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1413, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1365, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1279, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1291, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1260, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1250, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1240, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1221, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1213, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4241\n",
      "Reward: 9.7453\n",
      "Episode: 2, Step: 66, State: [0.3512476086616516, 0.1865079402923584, 0.9960435032844543, 0.0, 0.9989929795265198, 0.9691542387008667, 0.8324872851371765, 0.6160081028938293, 0.7841269969940186, 0.0632530152797699]\n",
      "weights [1.5414177611265292, 1.2292667873028769, 10, 0.9999990000010001, 10, 10, 5.969660459257901, 2.6042148371393155, 4.632331758689313, 1.0675229798318282]\n",
      "Episode: 2, Step: 66, Epsilon: 0.4396\n",
      "Episode: 2, Step: 66, Action: [6.1261840e-09 1.4666404e-05 1.7885577e-08 9.9998510e-01 7.5837825e-09\n",
      " 7.0674195e-09 9.9639408e-09 8.8090948e-09 1.4814570e-07 3.0940484e-08], Действие: агент\n",
      "loss =  tensor(0.1278, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1289, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1222, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1237, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1246, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1240, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1227, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1216, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1167, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1154, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1165, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1122, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1129, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1139, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1083, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1106, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4252\n",
      "Reward: 8.3444\n",
      "Episode: 2, Step: 67, State: [0.2936660349369049, 0.4345238208770752, 0.9950544238090515, 0.0, 0.9989929795265198, 0.9462686777114868, 0.717766523361206, 0.5369807481765747, 0.7597883343696594, 0.1004016101360321]\n",
      "weights [1.4157588813554947, 1.7684179608291806, 10, 0.9999990000010001, 10, 10, 3.5431532387866578, 2.1597327461636695, 4.162977823737587, 1.1116059117728103]\n",
      "Episode: 2, Step: 67, Epsilon: 0.4377\n",
      "Episode: 2, Step: 67, Action: [0.00340397 0.06731279 0.02031564 0.12856791 0.0196094  0.23040303\n",
      " 0.22338885 0.06409586 0.15356995 0.08933259], Действие: случайное\n",
      "loss =  tensor(1.7059, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8215, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.1989, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8897, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7355, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6173, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9528, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7228, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4912, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3706, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7220, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1944, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2019, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3241, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0965, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3019, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2198\n",
      "Reward: 2.9769\n",
      "Episode: 2, Step: 68, State: [1.0, 1.0, 1.0, 0.015564202331006527, 1.0, 1.0, 1.0, 0.9989868402481079, 0.7851851582527161, 0.014056225307285786]\n",
      "weights [10, 10, 10, 1.0158092448066325, 10, 10, 10, 10, 4.65515015962571, 1.0142555908485507]\n",
      "Episode: 2, Step: 68, Epsilon: 0.4358\n",
      "Episode: 2, Step: 68, Action: [0.03029261 0.05329828 0.1885669  0.1011794  0.23765515 0.04548939\n",
      " 0.03974405 0.02271384 0.19786959 0.0831908 ], Действие: случайное\n",
      "loss =  tensor(1.4869, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4883, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5209, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5127, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4454, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4156, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3913, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4120, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2801, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1508, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0696, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1796, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1343, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1206, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0743, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0775, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2675\n",
      "Reward: 16.4493\n",
      "Episode: 2, Step: 69, State: [1.0, 1.0, 0.9980217814445496, 0.6099221706390381, 0.7079557180404663, 0.5174129605293274, 0.6081218123435974, 0.9807497262954712, 0.17037037014961243, 0.6907630562782288]\n",
      "weights [10, 10, 10, 2.5635843955905737, 3.4241265371257112, 2.0721607628254763, 2.551806861651439, 10, 1.205355689652317, 3.2337558191103613]\n",
      "Episode: 2, Step: 69, Epsilon: 0.4338\n",
      "Episode: 2, Step: 69, Action: [3.8002268e-10 3.9985483e-05 2.0194415e-09 9.9995995e-01 4.9538784e-10\n",
      " 4.3641341e-10 7.1904666e-10 5.8245281e-10 2.5232273e-08 3.9158761e-09], Действие: агент\n",
      "loss =  tensor(0.2380, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2389, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2332, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2294, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2244, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2286, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2245, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2077, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1719, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1651, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1585, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1576, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1570, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1605, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1574, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1513, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3739\n",
      "Reward: 21.2060\n",
      "Episode: 2, Step: 70, State: [0.09309021383523941, 0.2926587164402008, 1.0, 0.09630350023508072, 1.0, 1.0, 1.0, 1.0, 0.46666666865348816, 0.34939759969711304]\n",
      "weights [1.102644290105871, 1.413742714442801, 10, 1.1065649736334693, 10, 10, 10, 10, 1.8749964913664847, 1.5370346966131012]\n",
      "Episode: 2, Step: 70, Epsilon: 0.4319\n",
      "Episode: 2, Step: 70, Action: [0.08264268 0.01378581 0.16902946 0.07803456 0.18374326 0.12635445\n",
      " 0.0343548  0.06257273 0.21346281 0.03601944], Действие: случайное\n",
      "loss =  tensor(1.3385, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2605, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2905, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3921, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2913, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2449, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2597, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2122, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2120, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9898, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0734, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0421, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9794, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9007, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9953, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9355, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.359\n",
      "Reward: 22.1518\n",
      "accuracy =  0.195\n",
      "--------------------------------------\n",
      "Episode: 2, Step: 70, Test Accuracy: 0.1950\n",
      "--------------------------------------\n",
      "Episode: 2, Step: 71, State: [1.0, 1.0, 0.6211671829223633, 0.11964980512857437, 0.4501510560512543, 0.37512436509132385, 0.7878172397613525, 0.7771023511886597, 0.4899470806121826, 0.7821285128593445]\n",
      "weights [10, 10, 2.6396798673204613, 1.1359103115047728, 1.818678006618502, 1.6003158769828976, 4.712896024065552, 4.486343929551552, 1.9605770331109917, 4.5898406592036265]\n",
      "Episode: 2, Step: 71, Epsilon: 0.4300\n",
      "Episode: 2, Step: 71, Action: [5.1912470e-09 3.2943417e-04 1.9899097e-08 9.9967027e-01 6.2803074e-09\n",
      " 4.8062860e-09 9.0192511e-09 7.3018107e-09 1.9470689e-07 3.6049592e-08], Действие: агент\n",
      "loss =  tensor(0.1746, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1846, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1916, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1891, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1740, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1784, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1732, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1869, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1650, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1551, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1548, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1509, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1493, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1494, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1501, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1464, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3591\n",
      "Reward: 16.8040\n",
      "Episode: 2, Step: 72, State: [0.0, 0.8978174328804016, 0.9910979270935059, 0.005836575757712126, 0.9959717988967896, 0.993034839630127, 0.9705584049224854, 0.9270516633987427, 0.2232804298400879, 0.4287148714065552]\n",
      "weights [0.9999990000010001, 9.786309366451977, 10, 1.0058698295929869, 10, 10, 10, 10, 1.2874642933611489, 1.7504363399511997]\n",
      "Episode: 2, Step: 72, Epsilon: 0.4281\n",
      "Episode: 2, Step: 72, Action: [0.04885015 0.00805762 0.13917659 0.08712996 0.12003188 0.11075879\n",
      " 0.11614283 0.11341889 0.07077087 0.18566242], Действие: случайное\n",
      "loss =  tensor(1.3700, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5778, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4096, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3991, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5190, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4102, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2973, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4003, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0538, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0746, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0415, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0299, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2023, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0162, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0138, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0212, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4449\n",
      "Reward: 24.1683\n",
      "Episode: 2, Step: 73, State: [0.8090211153030396, 1.0, 0.5895153284072876, 0.0038910505827516317, 0.6243705749511719, 0.5830845832824707, 0.46700507402420044, 0.6301925182342529, 0.820105791091919, 0.03714859485626221]\n",
      "weights [5.236153543535549, 10, 2.4361386260327476, 1.00390524217234, 2.662191168007784, 2.3985623014637096, 1.8761869486510945, 2.704102391662947, 5.55879173253001, 1.0385807779653586]\n",
      "Episode: 2, Step: 73, Epsilon: 0.4262\n",
      "Episode: 2, Step: 73, Action: [0.01868424 0.16725952 0.11748505 0.00789083 0.25972461 0.0171034\n",
      " 0.16542162 0.02303364 0.10435905 0.11903804], Действие: случайное\n",
      "loss =  tensor(1.4296, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4610, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3339, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3544, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3299, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4086, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3971, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4852, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2531, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1891, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1633, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1541, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0211, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0848, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9884, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0597, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.5218\n",
      "Reward: 14.5183\n",
      "Episode: 2, Step: 74, State: [0.010556621477007866, 1.0, 0.31058359146118164, 0.02626459114253521, 0.7432023882865906, 0.804975152015686, 0.48426395654678345, 0.7548125386238098, 0.4412698447704315, 0.23694778978824615]\n",
      "weights [1.0106682312883164, 10, 1.4505000709504043, 1.0269719719871127, 3.8941020487914986, 5.127525455397228, 1.938972607638008, 4.078495351645892, 1.7897695352053982, 1.3105245959485463]\n",
      "Episode: 2, Step: 74, Epsilon: 0.4244\n",
      "Episode: 2, Step: 74, Action: [7.2788418e-07 7.7458420e-03 2.1669846e-06 9.9223256e-01 7.7414768e-07\n",
      " 6.8104146e-07 1.1465759e-06 8.7422103e-07 1.1782146e-05 3.3898039e-06], Действие: агент\n",
      "loss =  tensor(0.2447, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2489, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2396, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2415, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2399, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2275, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2318, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2219, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2009, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1919, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1948, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1793, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1815, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1772, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1707, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1740, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3391\n",
      "Reward: 4.2328\n",
      "Episode: 2, Step: 75, State: [0.0, 0.9920634627342224, 1.0, 0.11284046620130539, 1.0, 1.0, 0.9695431590080261, 0.9918946027755737, 0.43386244773864746, 0.1405622512102127]\n",
      "weights [0.9999990000010001, 10, 10, 1.127191710972695, 10, 10, 10, 10, 1.7663520634757255, 1.1635500510166001]\n",
      "Episode: 2, Step: 75, Epsilon: 0.4225\n",
      "Episode: 2, Step: 75, Action: [1.43385681e-09 5.76207503e-06 6.00415051e-09 9.99994159e-01\n",
      " 1.59179137e-09 1.74231540e-09 2.59438915e-09 1.81521487e-09\n",
      " 6.50072423e-08 1.04903854e-08], Действие: агент\n",
      "loss =  tensor(0.1840, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1884, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1788, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1828, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1776, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1813, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1759, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1763, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1633, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1604, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1570, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1538, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1518, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1509, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1484, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1482, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4159\n",
      "Reward: 11.6688\n",
      "Episode: 2, Step: 76, State: [0.07197696715593338, 0.3571428656578064, 0.9990108609199524, 0.0, 1.0, 0.998009979724884, 0.9370558261871338, 0.9483282566070557, 0.43597882986068726, 0.1295180767774582]\n",
      "weights [1.0775583008721794, 1.555553156410244, 10, 0.9999990000010001, 10, 10, 10, 10, 1.772979951750835, 1.1487876135444264]\n",
      "Episode: 2, Step: 76, Epsilon: 0.4206\n",
      "Episode: 2, Step: 76, Action: [5.0859534e-09 1.1839568e-05 1.6928993e-08 9.9998796e-01 6.2575003e-09\n",
      " 6.2218684e-09 8.6875129e-09 6.9105339e-09 1.4476441e-07 2.9799617e-08], Действие: агент\n",
      "loss =  tensor(0.1551, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1578, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1536, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1498, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1515, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1490, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1501, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1482, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1421, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1384, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1368, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1345, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1318, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1332, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1294, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1311, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4207\n",
      "Reward: 7.9584\n",
      "Episode: 2, Step: 77, State: [0.44337812066078186, 0.1140872985124588, 0.9831849932670593, 0.0, 0.9989929795265198, 0.9870646595954895, 0.8538070917129517, 0.8834853172302246, 0.3957671821117401, 0.15160642564296722]\n",
      "weights [1.796548501899754, 1.128778117237487, 10, 0.9999990000010001, 10, 10, 6.840230292198791, 8.582535640081266, 1.6549884670389776, 1.1786968354410605]\n",
      "Episode: 2, Step: 77, Epsilon: 0.4188\n",
      "Episode: 2, Step: 77, Action: [4.6589830e-09 1.6440892e-05 1.4656794e-08 9.9998343e-01 6.1867884e-09\n",
      " 5.6307501e-09 7.7242062e-09 6.7965815e-09 1.2339004e-07 2.7154535e-08], Действие: агент\n",
      "loss =  tensor(0.1318, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1354, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1312, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1317, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1318, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1319, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1310, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1286, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1244, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1219, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1203, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1204, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1153, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1175, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1155, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1167, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.391\n",
      "Reward: 7.0353\n",
      "Episode: 2, Step: 78, State: [0.6381957530975342, 0.2519841194152832, 0.9960435032844543, 0.0, 1.0, 0.9900497794151306, 0.8223350048065186, 0.8652482032775879, 0.3682539761066437, 0.16465863585472107]\n",
      "weights [2.763917904898644, 1.3368682257789566, 10, 0.9999990000010001, 10, 10, 5.628539096133631, 7.420996256277921, 1.5829120869254898, 1.1971139534186064]\n",
      "Episode: 2, Step: 78, Epsilon: 0.4170\n",
      "Episode: 2, Step: 78, Action: [2.4818252e-09 1.2891391e-05 8.3036333e-09 9.9998701e-01 3.2892391e-09\n",
      " 2.9595488e-09 4.1570201e-09 3.6417447e-09 7.6858804e-08 1.5851214e-08], Действие: агент\n",
      "loss =  tensor(0.1198, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1180, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1164, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1159, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1187, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1148, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1151, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1162, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1100, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1119, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1094, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1066, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1065, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1045, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1037, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1053, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.411\n",
      "Reward: 8.8191\n",
      "Episode: 2, Step: 79, State: [0.6055662035942078, 0.3125, 0.9802176356315613, 0.0, 0.9949647784233093, 0.9661691784858704, 0.7116751074790955, 0.7852076888084412, 0.3375661373138428, 0.19979919493198395]\n",
      "weights [2.5352732799243345, 1.4545433388460525, 10, 0.9999990000010001, 10, 10, 3.468297596364839, 4.655638457513099, 1.5095823851193826, 1.2496847591027382]\n",
      "Episode: 2, Step: 79, Epsilon: 0.4151\n",
      "Episode: 2, Step: 79, Action: [5.4933298e-09 3.1813524e-05 1.8173335e-08 9.9996793e-01 7.1487101e-09\n",
      " 6.4102625e-09 9.2351282e-09 7.9657489e-09 1.5185815e-07 3.4075715e-08], Действие: агент\n",
      "loss =  tensor(0.1042, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1057, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1074, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1071, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1040, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1077, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1031, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1047, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0984, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0997, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0954, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1000, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0974, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0994, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0960, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0955, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3902\n",
      "Reward: 6.8539\n",
      "Episode: 2, Step: 80, State: [0.533589243888855, 0.4781745970249176, 0.9940652847290039, 0.0, 0.9969788789749146, 0.9810945391654968, 0.772588849067688, 0.8206686973571777, 0.34497353434562683, 0.18273092806339264]\n",
      "weights [2.1440282902339667, 1.9163461149123777, 10, 0.9999990000010001, 10, 10, 4.3973024128233344, 5.576240227014253, 1.5266535411625815, 1.223585732963884]\n",
      "Episode: 2, Step: 80, Epsilon: 0.4133\n",
      "Episode: 2, Step: 80, Action: [3.3988692e-09 1.7495764e-05 1.1864259e-08 9.9998236e-01 4.2725059e-09\n",
      " 3.9751131e-09 5.7900138e-09 4.7717554e-09 1.0586244e-07 2.2061007e-08], Действие: агент\n",
      "loss =  tensor(0.0980, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0965, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0975, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0980, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0970, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0936, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0937, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0942, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0913, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0902, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0906, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0892, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0885, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0901, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0872, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0869, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4007\n",
      "Reward: 7.8896\n",
      "accuracy =  0.2849\n",
      "--------------------------------------\n",
      "Episode: 2, Step: 80, Test Accuracy: 0.2849\n",
      "--------------------------------------\n",
      "Episode: 2, Step: 81, State: [0.5249519944190979, 0.4781745970249176, 0.9881305694580078, 0.0, 0.9969788789749146, 0.967164158821106, 0.7167512774467468, 0.7933130860328674, 0.3365079462528229, 0.19678714871406555]\n",
      "weights [2.105045981050259, 1.9163461149123777, 10, 0.9999990000010001, 10, 10, 3.530453590513199, 4.838212263146744, 1.5071747840498844, 1.2449984501624487]\n",
      "Episode: 2, Step: 81, Epsilon: 0.4115\n",
      "Episode: 2, Step: 81, Action: [0.02479735 0.3898381  0.05679137 0.11567183 0.05317315 0.00176355\n",
      " 0.044134   0.07305589 0.01141127 0.2293635 ], Действие: случайное\n",
      "loss =  tensor(1.3079, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1718, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1868, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2564, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2119, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1999, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0804, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0634, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9587, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9488, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0191, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9594, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8317, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8946, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8796, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1441\n",
      "Reward: 1.7652\n",
      "Episode: 2, Step: 82, State: [1.0, 1.0, 1.0, 0.0, 0.9899294972419739, 0.9990049600601196, 0.9756345152854919, 0.9736575484275818, 0.9968253970146179, 0.6495984196662903]\n",
      "weights [10, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 10, 2.853860262808679]\n",
      "Episode: 2, Step: 82, Epsilon: 0.4097\n",
      "Episode: 2, Step: 82, Action: [0.15898292 0.10758834 0.00475992 0.01533781 0.1903163  0.044138\n",
      " 0.02273543 0.052398   0.07986028 0.32388301], Действие: случайное\n",
      "loss =  tensor(1.3174, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3276, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2847, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2148, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2090, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0841, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1528, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0893, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0319, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0408, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9408, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9859, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8904, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8324, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8694, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1986\n",
      "Reward: 11.0985\n",
      "Episode: 2, Step: 83, State: [1.0, 1.0, 1.0, 0.46108949184417725, 0.20443101227283478, 0.9900497794151306, 0.9888324737548828, 0.9736575484275818, 0.9417989253997803, 0.45783132314682007]\n",
      "weights [10, 10, 10, 1.8555922166554597, 1.2569604377068866, 10, 10, 10, 10, 1.8444410351462739]\n",
      "Episode: 2, Step: 83, Epsilon: 0.4079\n",
      "Episode: 2, Step: 83, Action: [0.10740961 0.05809846 0.02624354 0.0533042  0.08373942 0.26862807\n",
      " 0.10856953 0.0104349  0.25658441 0.02698786], Действие: случайное\n",
      "loss =  tensor(1.6570, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5535, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6315, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4016, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3476, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3567, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4628, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3048, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2133, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0940, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1202, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0604, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0420, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2316, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0926, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0353, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3751\n",
      "Reward: 25.0325\n",
      "Episode: 2, Step: 84, State: [0.6794625520706177, 0.012896825559437275, 0.9990108609199524, 0.0, 0.9597180485725403, 0.993034839630127, 0.982741117477417, 0.9878419637680054, 0.12275132536888123, 0.5100401639938354]\n",
      "weights [3.1197505524214355, 1.013064300499738, 10, 0.9999990000010001, 10, 10, 10, 10, 1.1399263276107767, 2.040979454911817]\n",
      "Episode: 2, Step: 84, Epsilon: 0.4061\n",
      "Episode: 2, Step: 84, Action: [9.2379715e-10 5.8736759e-06 3.3577472e-09 9.9999404e-01 1.3675694e-09\n",
      " 1.1696771e-09 1.6678837e-09 1.4704880e-09 3.3431277e-08 6.5985963e-09], Действие: агент\n",
      "loss =  tensor(0.1918, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1877, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1895, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1830, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1797, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1764, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1686, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1686, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1477, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1389, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1408, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1358, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1333, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1295, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1310, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1296, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2041\n",
      "Reward: 4.4858\n",
      "Episode: 2, Step: 85, State: [0.0, 0.9305555820465088, 1.0, 0.9931906461715698, 1.0, 1.0, 0.9989847540855408, 1.0, 0.2359788417816162, 0.8002008199691772]\n",
      "weights [0.9999990000010001, 10, 10, 10, 10, 10, 10, 10, 1.3088625627454191, 5.005000495223438]\n",
      "Episode: 2, Step: 85, Epsilon: 0.4043\n",
      "Episode: 2, Step: 85, Action: [2.6592400e-11 4.2126385e-07 1.7349222e-10 9.9999952e-01 3.3856987e-11\n",
      " 3.7965645e-11 5.5762204e-11 4.0716586e-11 2.4071773e-09 2.8624880e-10], Действие: агент\n",
      "loss =  tensor(0.1424, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1371, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1411, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1327, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1262, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1353, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1328, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1312, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1245, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1184, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1190, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1176, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1173, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1127, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1110, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1138, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3961\n",
      "Reward: 20.2921\n",
      "Episode: 2, Step: 86, State: [0.03550863638520241, 0.5089285969734192, 1.0, 0.0038910505827516317, 1.0, 1.0, 0.9857867956161499, 0.9959473013877869, 0.16931216418743134, 0.36345380544662476]\n",
      "weights [1.0368148444971863, 2.036359595523579, 10, 1.00390524217234, 10, 10, 10, 10, 1.2038201994394369, 1.5709754257916988]\n",
      "Episode: 2, Step: 86, Epsilon: 0.4026\n",
      "Episode: 2, Step: 86, Action: [2.87576807e-09 7.13177178e-06 1.09420375e-08 9.99992728e-01\n",
      " 3.57648777e-09 3.59289709e-09 5.29301003e-09 3.91409261e-09\n",
      " 9.44397200e-08 1.90318730e-08], Действие: агент\n",
      "loss =  tensor(0.1222, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1181, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1125, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1128, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1147, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1113, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1105, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1136, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1077, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1063, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1036, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1045, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0995, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1010, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0995, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1022, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4299\n",
      "Reward: 7.4165\n",
      "Episode: 2, Step: 87, State: [0.05662187933921814, 0.3621031641960144, 0.9960435032844543, 0.0, 0.9969788789749146, 0.9751243591308594, 0.896446704864502, 0.9300912022590637, 0.3301587402820587, 0.18775101006031036]\n",
      "weights [1.0600192203740513, 1.5676491498668161, 10, 0.9999990000010001, 10, 10, 9.65676989729423, 10, 1.4928887891025004, 1.231148060801147]\n",
      "Episode: 2, Step: 87, Epsilon: 0.4008\n",
      "Episode: 2, Step: 87, Action: [0.01778616 0.17628839 0.19807806 0.04547514 0.00201938 0.02604087\n",
      " 0.1812186  0.21471444 0.02833035 0.11004861], Действие: случайное\n",
      "loss =  tensor(1.4715, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5730, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4658, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4523, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3218, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4674, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2806, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3716, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1693, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1789, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0555, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0750, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0859, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9860, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0999, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0432, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3727\n",
      "Reward: 7.0211\n",
      "Episode: 2, Step: 88, State: [0.0, 0.954365074634552, 0.9990108609199524, 0.0, 1.0, 0.9990049600601196, 0.9644669890403748, 0.719351589679718, 0.6402116417884827, 0.03915662690997124]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 10, 3.5631644437049865, 2.7794040517788408, 1.0407512683703903]\n",
      "Episode: 2, Step: 88, Epsilon: 0.3991\n",
      "Episode: 2, Step: 88, Action: [0.12754407 0.07072402 0.26985757 0.06411832 0.0711049  0.01559968\n",
      " 0.07883541 0.26026828 0.00392643 0.03802132], Действие: случайное\n",
      "loss =  tensor(1.4811, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4191, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4567, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3442, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3236, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2479, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3578, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2392, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1414, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0737, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9656, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9930, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0427, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9425, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9460, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9327, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2176\n",
      "Reward: 6.3892\n",
      "Episode: 2, Step: 89, State: [1.0, 1.0, 1.0, 0.0038910505827516317, 0.8952668905258179, 0.9343283772468567, 0.9776649475097656, 0.027355622500181198, 1.0, 1.0]\n",
      "weights [10, 10, 10, 1.00390524217234, 9.547987804741958, 10, 10, 1.028123942325718, 10, 10]\n",
      "Episode: 2, Step: 89, Epsilon: 0.3973\n",
      "Episode: 2, Step: 89, Action: [4.4124645e-11 8.1289181e-07 1.9235431e-10 9.9999917e-01 5.3789872e-11\n",
      " 4.5789265e-11 8.7601995e-11 6.5782532e-11 2.6660216e-09 3.3433836e-10], Действие: агент\n",
      "loss =  tensor(0.1749, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1894, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1834, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1868, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1765, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1793, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1744, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1721, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1492, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1428, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1433, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1422, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1332, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1378, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1337, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1355, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2058\n",
      "Reward: 14.9444\n",
      "Episode: 2, Step: 90, State: [0.0, 0.7628968358039856, 1.0, 0.7859922051429749, 0.9989929795265198, 1.0, 0.9979695677757263, 0.6332319974899292, 0.9534391760826111, 0.8514056205749512]\n",
      "weights [0.9999990000010001, 4.2175556190286825, 10, 4.672705159935504, 10, 10, 10, 2.726511763961138, 10, 6.729684354044116]\n",
      "Episode: 2, Step: 90, Epsilon: 0.3956\n",
      "Episode: 2, Step: 90, Action: [1.3131821e-11 6.0497328e-08 6.9977260e-11 9.9999988e-01 1.5945337e-11\n",
      " 1.6581665e-11 2.6548621e-11 2.0300284e-11 9.3228658e-10 1.0864058e-10], Действие: агент\n",
      "loss =  tensor(0.1416, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1420, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1377, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1385, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1383, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1356, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1328, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1355, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1254, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1218, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1196, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1172, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1172, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1137, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1130, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1124, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3719\n",
      "Reward: 15.3254\n",
      "accuracy =  0.3\n",
      "--------------------------------------\n",
      "Episode: 2, Step: 90, Test Accuracy: 0.3000\n",
      "--------------------------------------\n",
      "Episode: 2, Step: 91, State: [0.0, 0.9027777910232544, 1.0, 0.0009727626456879079, 1.0, 1.0, 0.9868020415306091, 0.4609929025173187, 0.7671957612037659, 0.2098393589258194]\n",
      "weights [0.9999990000010001, 10, 10, 1.0009727078868775, 10, 10, 10, 1.8552596977119267, 4.295435984047005, 1.2655638391159507]\n",
      "Episode: 2, Step: 91, Epsilon: 0.3939\n",
      "Episode: 2, Step: 91, Action: [2.0286481e-09 2.1726962e-06 7.0046351e-09 9.9999774e-01 2.1371733e-09\n",
      " 2.2396189e-09 3.4848444e-09 2.5023288e-09 5.5906810e-08 1.0925950e-08], Действие: агент\n",
      "loss =  tensor(0.1207, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1180, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1191, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1138, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1138, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1117, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1133, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1115, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1067, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1072, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1039, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1025, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1032, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1010, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0993, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1002, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4009\n",
      "Reward: 9.3419\n",
      "Episode: 2, Step: 92, State: [0.0, 0.829365074634552, 0.922848641872406, 0.0, 0.9859012961387634, 0.9751243591308594, 0.8284264206886292, 0.16413374245166779, 0.879365086555481, 0.45582330226898193]\n",
      "weights [0.9999990000010001, 5.860430608960671, 10, 0.9999990000010001, 10, 10, 5.8283692375268235, 1.1963622105896128, 8.289405463489146, 1.8376350301924549]\n",
      "Episode: 2, Step: 92, Epsilon: 0.3921\n",
      "Episode: 2, Step: 92, Action: [0.00313588 0.10350117 0.01091995 0.02876979 0.04258521 0.11363827\n",
      " 0.04150926 0.34847295 0.30404469 0.00342283], Действие: случайное\n",
      "loss =  tensor(2.5136, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7798, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9448, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9505, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9941, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9809, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0971, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7588, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5141, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3749, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3953, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5930, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2700, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3604, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2885, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1135, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2691\n",
      "Reward: 6.3735\n",
      "Episode: 2, Step: 93, State: [0.9980806112289429, 1.0, 1.0, 0.0, 1.0, 1.0, 0.9939086437225342, 0.5511651635169983, 0.6084656119346619, 0.15461847186088562]\n",
      "weights [10, 10, 10, 0.9999990000010001, 10, 10, 10, 2.2279860891586183, 2.55404755350779, 1.1828964601400445]\n",
      "Episode: 2, Step: 93, Epsilon: 0.3904\n",
      "Episode: 2, Step: 93, Action: [0.22947307 0.04613354 0.06462641 0.02258909 0.00938935 0.03861503\n",
      " 0.24215754 0.09745977 0.16485912 0.08469707], Действие: случайное\n",
      "loss =  tensor(1.7211, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6013, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5203, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5302, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4883, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4041, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2347, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1832, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0933, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2290, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1574, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0851, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0873, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9474, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0385, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0372, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2688\n",
      "Reward: 14.0826\n",
      "Episode: 2, Step: 94, State: [1.0, 0.8085317611694336, 0.9960435032844543, 0.47081711888313293, 0.6022155284881592, 0.9532338380813599, 0.4771573543548584, 0.9989868402481079, 0.4772486686706543, 0.5030120611190796]\n",
      "weights [10, 5.222771062901194, 10, 1.8897023051598882, 2.513917856776811, 10, 1.9126176789737794, 10, 1.9129517748051468, 2.0121172158312404]\n",
      "Episode: 2, Step: 94, Epsilon: 0.3887\n",
      "Episode: 2, Step: 94, Action: [8.29004920e-11 1.20242112e-06 3.62309321e-10 9.99998808e-01\n",
      " 1.01286264e-10 8.66013580e-11 1.33975345e-10 1.13832943e-10\n",
      " 3.76693432e-09 6.81385559e-10], Действие: агент\n",
      "loss =  tensor(0.1976, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2058, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1889, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1876, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1851, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1798, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1712, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1681, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1440, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1395, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1426, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1363, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1321, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1347, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1259, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1247, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3721\n",
      "Reward: 17.6524\n",
      "Episode: 2, Step: 95, State: [0.29846447706222534, 0.0773809552192688, 0.7972304821014404, 0.6070038676261902, 0.8519637584686279, 0.9940298795700073, 0.9045685529708862, 1.0, 0.6433862447738647, 0.1295180767774582]\n",
      "weights [1.4254425354967564, 1.0838697963013135, 4.931683414155267, 2.5445478290381596, 6.755056968472895, 10, 10, 10, 2.804146450322516, 1.1487876135444264]\n",
      "Episode: 2, Step: 95, Epsilon: 0.3871\n",
      "Episode: 2, Step: 95, Action: [0.06809346 0.21221902 0.07160941 0.19770112 0.00824189 0.14103429\n",
      " 0.0318108  0.11187231 0.0013036  0.1561141 ], Действие: случайное\n",
      "loss =  tensor(1.1729, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1654, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1146, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1459, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1319, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0831, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0645, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1135, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8862, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0796, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8338, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7884, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7536, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8346, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6858, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7769, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4328\n",
      "Reward: 14.1624\n",
      "Episode: 2, Step: 96, State: [0.0, 0.841269850730896, 0.6983184814453125, 0.002918287878856063, 0.9597180485725403, 0.7402985095977783, 0.7411167621612549, 0.8318135738372803, 0.9058201313018799, 0.011044176295399666]\n",
      "weights [0.9999990000010001, 6.299960685754598, 3.3147429449702273, 1.0029258233478444, 10, 3.850559917431756, 3.862730339816533, 5.945747686468009, 10, 1.0111664898109831]\n",
      "Episode: 2, Step: 96, Epsilon: 0.3854\n",
      "Episode: 2, Step: 96, Action: [9.0552827e-09 8.3701252e-06 2.7792028e-08 9.9999142e-01 9.0719823e-09\n",
      " 8.7787235e-09 1.4626247e-08 1.1175343e-08 1.8344402e-07 4.0870219e-08], Действие: агент\n",
      "loss =  tensor(0.1446, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1513, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1459, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1492, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1408, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1455, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1410, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1377, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1292, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1304, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1269, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1225, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1291, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1243, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1269, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1229, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4457\n",
      "Reward: 10.8835\n",
      "Episode: 2, Step: 97, State: [0.007677542977035046, 0.7073412537574768, 0.9881305694580078, 0.0, 0.9959717988967896, 0.772139310836792, 0.6984771490097046, 0.3880445659160614, 0.9650793671607971, 0.07530120760202408]\n",
      "weights [1.0077359281620382, 3.416937289255057, 10, 0.9999990000010001, 10, 4.388627169720229, 3.3164872255236126, 1.6341032536032387, 10, 1.0814320585135548]\n",
      "Episode: 2, Step: 97, Epsilon: 0.3837\n",
      "Episode: 2, Step: 97, Action: [1.2464777e-08 8.8632087e-06 3.5749210e-08 9.9999082e-01 1.2754701e-08\n",
      " 1.2578292e-08 2.0149033e-08 1.5549578e-08 2.0328679e-07 5.2672817e-08], Действие: агент\n",
      "loss =  tensor(0.1255, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1295, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1259, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1263, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1265, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1229, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1191, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1196, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1143, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1131, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1118, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1092, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1070, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1070, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1068, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1076, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4358\n",
      "Reward: 7.7500\n",
      "Episode: 2, Step: 98, State: [0.3023032546043396, 0.2232142835855484, 0.9940652847290039, 0.0, 0.9979858994483948, 0.8925372958183289, 0.8253806829452515, 0.42451873421669006, 0.9693121910095215, 0.06124497950077057]\n",
      "weights [1.4332854113394127, 1.2873546610269964, 10, 0.9999990000010001, 10, 9.30546743772637, 5.726710481727456, 1.7376730082878635, 10, 1.0652395064994642]\n",
      "Episode: 2, Step: 98, Epsilon: 0.3820\n",
      "Episode: 2, Step: 98, Action: [4.5814765e-09 3.8580993e-06 1.2272109e-08 9.9999607e-01 5.3075451e-09\n",
      " 4.8275171e-09 7.1838619e-09 6.3361578e-09 7.3953132e-08 1.8887034e-08], Действие: агент\n",
      "loss =  tensor(0.1132, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1110, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1105, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1083, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1082, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1085, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1065, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1092, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1010, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1033, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1029, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1003, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0953, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0940, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0959, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0939, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4163\n",
      "Reward: 7.7930\n",
      "Episode: 2, Step: 99, State: [0.7648752331733704, 0.0486111119389534, 0.9831849932670593, 0.0, 0.9859012961387634, 0.8965173959732056, 0.7685279250144958, 0.4204660654067993, 0.9375661611557007, 0.05923694744706154]\n",
      "weights [4.253043013943051, 1.05109378662624, 10, 0.9999990000010001, 10, 9.663366572941117, 4.320156891088194, 1.725521517873536, 10, 1.0629657854021035]\n",
      "Episode: 2, Step: 99, Epsilon: 0.3804\n",
      "Episode: 2, Step: 99, Action: [0.26148693 0.15698156 0.0109534  0.07205062 0.02273908 0.0565052\n",
      " 0.01860918 0.29088767 0.01891543 0.09087093], Действие: случайное\n",
      "loss =  tensor(1.2240, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2323, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0366, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0642, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0716, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0713, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0178, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0088, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9414, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8949, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8670, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8699, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8478, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8722, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7953, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8179, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2038\n",
      "Reward: 3.5606\n",
      "Episode: 2, Step: 100, State: [1.0, 1.0, 1.0, 0.0904669240117073, 0.9969788789749146, 0.9233830571174622, 0.9695431590080261, 0.0030395137146115303, 0.9978836178779602, 0.9929718971252441]\n",
      "weights [10, 10, 10, 1.09946402933107, 10, 10, 10, 1.0030477744189825, 10, 10]\n",
      "Episode: 2, Step: 100, Epsilon: 0.3787\n",
      "Episode: 2, Step: 100, Action: [2.1829009e-11 3.1975316e-07 9.7640125e-11 9.9999964e-01 2.6619198e-11\n",
      " 2.3069532e-11 4.3757744e-11 3.3212526e-11 1.2992291e-09 1.6669160e-10], Действие: агент\n",
      "loss =  tensor(0.1163, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1125, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1160, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1168, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1122, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1138, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1087, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1123, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1041, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1053, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1067, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1029, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1034, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0998, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1008, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0977, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4616\n",
      "Reward: 28.0550\n",
      "accuracy =  0.3849\n",
      "--------------------------------------\n",
      "Episode: 2, Step: 100, Test Accuracy: 0.3849\n",
      "--------------------------------------\n",
      "Новая лучшая точность: 0.3849\n",
      "Восстанавливаем лучшее состояние модели...\n",
      "Episode: 3, Step: 1, State: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "weights [np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815)]\n",
      "Episode: 3, Step: 1, Epsilon: 0.3771\n",
      "Episode: 3, Step: 1, Action: [1.0636068e-04 9.9580353e-01 1.3849602e-04 3.2208140e-03 1.1201202e-04\n",
      " 7.8675883e-05 1.1481340e-04 1.1626898e-04 1.3840769e-04 1.7056029e-04], Действие: агент\n",
      "loss =  tensor(3.9448, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.9400, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.8954, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.7314, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.8554, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.8097, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.6707, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.7415, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.3815, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.4160, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.1900, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.1284, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.1856, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.1698, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.1059, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.0587, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3491\n",
      "Reward: 3.8024\n",
      "Episode: 3, Step: 2, State: [0.003838771488517523, 0.4751984179019928, 0.8447082042694092, 0.023346303030848503, 0.9738166928291321, 0.9850746393203735, 0.9888324737548828, 0.6646403074264526, 0.9989417791366577, 0.6194779276847839]\n",
      "weights [1.0038525567208587, 1.9054784296264178, 6.439448754176895, 1.0239033335971208, 10, 10, 10, 2.981864070967983, 10, 2.6279615422941407]\n",
      "Episode: 3, Step: 2, Epsilon: 0.3755\n",
      "Episode: 3, Step: 2, Action: [3.3578990e-10 3.7462411e-07 1.1973876e-09 9.9999964e-01 3.9277961e-10\n",
      " 3.6550801e-10 6.3036665e-10 4.8918403e-10 1.0432119e-08 1.8137090e-09], Действие: агент\n",
      "loss =  tensor(0.1463, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1464, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1519, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1520, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1535, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1562, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1571, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1619, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1546, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1497, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1502, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1521, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1508, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1516, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1477, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1459, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3971\n",
      "Reward: 7.6824\n",
      "Episode: 3, Step: 3, State: [0.014395393431186676, 0.6458333134651184, 1.0, 0.0, 0.9989929795265198, 0.9960198998451233, 0.9776649475097656, 0.4224924147129059, 0.9386243224143982, 0.09236947447061539]\n",
      "weights [1.0146046180493005, 2.823521281074046, 10, 0.9999990000010001, 10, 10, 10, 1.731575989477065, 10, 1.1017686934317763]\n",
      "Episode: 3, Step: 3, Epsilon: 0.3738\n",
      "Episode: 3, Step: 3, Action: [1.9576993e-09 1.0908628e-06 5.8863403e-09 9.9999881e-01 2.0689106e-09\n",
      " 2.1034241e-09 3.1635150e-09 2.4602966e-09 3.8794905e-08 8.7781693e-09], Действие: агент\n",
      "loss =  tensor(0.1595, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1576, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1563, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1548, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1543, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1528, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1514, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1509, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1444, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1449, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1435, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1365, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1386, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1369, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1345, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1353, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.452\n",
      "Reward: 8.0063\n",
      "Episode: 3, Step: 4, State: [0.04606525972485542, 0.233134925365448, 1.0, 0.0, 0.9929506778717041, 0.967164158821106, 0.9421319961547852, 0.22188450396060944, 0.9333333373069763, 0.19979919493198395]\n",
      "weights [1.048288640188247, 1.3040086568916838, 10, 0.9999990000010001, 10, 10, 10, 1.285154607427031, 10, 1.2496847591027382]\n",
      "Episode: 3, Step: 4, Epsilon: 0.3722\n",
      "Episode: 3, Step: 4, Action: [7.4437256e-09 5.1711850e-06 1.9859364e-08 9.9999464e-01 8.6581924e-09\n",
      " 8.1379641e-09 1.2128353e-08 1.0195113e-08 1.0778548e-07 2.9811641e-08], Действие: агент\n",
      "loss =  tensor(0.1393, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1438, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1359, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1356, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1389, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1341, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1322, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1346, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1279, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1252, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1245, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1251, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1249, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1242, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1216, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1192, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4456\n",
      "Reward: 8.0035\n",
      "Episode: 3, Step: 5, State: [0.002879078732803464, 0.5267857313156128, 0.9950544238090515, 0.0, 0.9768378734588623, 0.932338297367096, 0.8659898638725281, 0.2512664496898651, 0.8984127044677734, 0.14759035408496857]\n",
      "weights [1.002886385978904, 2.1132031575822925, 10, 0.9999990000010001, 10, 10, 7.46206642893316, 1.3355868239094721, 9.843653688261487, 1.1731434899273656]\n",
      "Episode: 3, Step: 5, Epsilon: 0.3706\n",
      "Episode: 3, Step: 5, Action: [8.9105647e-09 5.7173534e-06 2.4442569e-08 9.9999404e-01 9.5513126e-09\n",
      " 9.4286996e-09 1.4157043e-08 1.1299170e-08 1.3146645e-07 3.6124945e-08], Действие: агент\n",
      "loss =  tensor(0.1255, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1241, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1206, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1231, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1255, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1178, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1198, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1192, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1152, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1137, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1124, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1116, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1106, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1101, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1105, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1096, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4572\n",
      "Reward: 7.8542\n",
      "Episode: 3, Step: 6, State: [0.00959692895412445, 0.3710317313671112, 0.9960435032844543, 0.0, 0.9869083762168884, 0.9432835578918457, 0.8903553485870361, 0.2046605944633484, 0.9037036895751953, 0.17670682072639465]\n",
      "weights [1.009688902978752, 1.58990279791185, 10, 0.9999990000010001, 10, 10, 9.12028874025884, 1.2573232706884236, 10, 1.2146326612952647]\n",
      "Episode: 3, Step: 6, Epsilon: 0.3690\n",
      "Episode: 3, Step: 6, Action: [1.06436850e-08 7.13779264e-06 2.83239441e-08 9.99992609e-01\n",
      " 1.18650370e-08 1.14408305e-08 1.70525443e-08 1.39916621e-08\n",
      " 1.46921039e-07 4.20526156e-08], Действие: агент\n",
      "loss =  tensor(0.1105, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1127, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1103, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1112, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1096, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1056, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1079, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1097, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1046, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1014, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1015, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1037, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1013, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0998, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0989, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1006, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4473\n",
      "Reward: 7.6911\n",
      "Episode: 3, Step: 7, State: [0.002879078732803464, 0.4950396716594696, 0.9950544238090515, 0.0, 0.9889224767684937, 0.9442785978317261, 0.8832487463951111, 0.2512664496898651, 0.8899471163749695, 0.1295180767774582]\n",
      "weights [1.002886385978904, 1.9803496701149967, 10, 0.9999990000010001, 10, 10, 8.565145161002063, 1.3355868239094721, 9.086458079091006, 1.1487876135444264]\n",
      "Episode: 3, Step: 7, Epsilon: 0.3674\n",
      "Episode: 3, Step: 7, Action: [0.15652773 0.23031434 0.1467049  0.10770297 0.08765192 0.0084709\n",
      " 0.20354244 0.00524955 0.02653103 0.02730421], Действие: случайное\n",
      "loss =  tensor(1.4548, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5401, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4070, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5444, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3790, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4960, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3475, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4021, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1078, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0953, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1106, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0477, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1361, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9475, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9673, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9467, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3813\n",
      "Reward: 10.2691\n",
      "Episode: 3, Step: 8, State: [0.024952014908194542, 0.3511904776096344, 0.9624134302139282, 0.0, 0.9375629425048828, 0.9920397996902466, 0.4680202901363373, 0.996960461139679, 0.8984127044677734, 0.6144578456878662]\n",
      "weights [1.0255894988761465, 1.5412820314870548, 10, 0.9999990000010001, 10, 10, 1.8797674078375555, 10, 9.843653688261487, 2.5937433691026066]\n",
      "Episode: 3, Step: 8, Epsilon: 0.3658\n",
      "Episode: 3, Step: 8, Action: [5.7905719e-10 8.3967137e-07 2.0433573e-09 9.9999917e-01 6.8478112e-10\n",
      " 6.1074368e-10 1.0808890e-09 8.3738061e-10 1.5576987e-08 3.2814211e-09], Действие: агент\n",
      "loss =  tensor(0.1327, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1312, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1352, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1367, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1398, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1360, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1336, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1316, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1272, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1216, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1213, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1207, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1203, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1161, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1163, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1149, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3734\n",
      "Reward: 9.3204\n",
      "Episode: 3, Step: 9, State: [0.0, 0.9573412537574768, 0.9990108609199524, 0.0, 0.9969788789749146, 1.0, 0.3725888431072235, 0.978723406791687, 0.5597883462905884, 0.43574297428131104]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 1.593848619307034, 10, 2.2716293854199594, 1.7722388595648444]\n",
      "Episode: 3, Step: 9, Epsilon: 0.3643\n",
      "Episode: 3, Step: 9, Action: [0.02573769 0.24295742 0.01191499 0.39145274 0.05277684 0.02226321\n",
      " 0.20266868 0.02788641 0.00512189 0.01722013], Действие: случайное\n",
      "loss =  tensor(0.8380, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9985, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8274, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8189, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7981, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6915, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7702, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7795, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5883, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5643, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5251, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5170, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5036, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5909, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4593, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.4155, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3702\n",
      "Reward: 6.3476\n",
      "Episode: 3, Step: 10, State: [0.008637236431241035, 1.0, 1.0, 0.0, 1.0, 0.998009979724884, 0.38172587752342224, 0.8348531126976013, 0.7343915104866028, 0.3815261125564575]\n",
      "weights [1.008711470752322, 10, 10, 0.9999990000010001, 10, 10, 1.6174029386697233, 6.055178884419647, 3.7649257254777435, 1.6168805238535817]\n",
      "Episode: 3, Step: 10, Epsilon: 0.3627\n",
      "Episode: 3, Step: 10, Action: [1.1490686e-09 1.5800970e-06 4.4333528e-09 9.9999833e-01 1.1906655e-09\n",
      " 1.1904883e-09 2.1151463e-09 1.4666792e-09 3.3321157e-08 7.1796729e-09], Действие: агент\n",
      "loss =  tensor(0.1334, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1390, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1356, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1362, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1344, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1368, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1372, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1274, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1253, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1151, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1171, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1162, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1130, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1144, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1131, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1134, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3492\n",
      "Reward: 14.2846\n",
      "accuracy =  0.2791\n",
      "--------------------------------------\n",
      "Episode: 3, Step: 10, Test Accuracy: 0.2791\n",
      "--------------------------------------\n",
      "Episode: 3, Step: 11, State: [0.8157389760017395, 0.1259920597076416, 0.9901087880134583, 0.0, 0.9425981640815735, 0.9552238583564758, 0.09137056022882462, 0.7720364928245544, 0.9417989253997803, 0.8955823183059692]\n",
      "weights [5.427054247539582, 1.1441530559921929, 10, 0.9999990000010001, 10, 10, 1.100557450234481, 4.386647782983085, 10, 9.576830350436865]\n",
      "Episode: 3, Step: 11, Epsilon: 0.3611\n",
      "Episode: 3, Step: 11, Action: [2.9863115e-10 3.4070454e-06 1.0477227e-09 9.9999654e-01 3.9736062e-10\n",
      " 2.9734662e-10 5.6643545e-10 4.8879456e-10 8.6239105e-09 1.8363888e-09], Действие: агент\n",
      "loss =  tensor(0.1251, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1220, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1189, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1141, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1156, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1142, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1147, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1104, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1058, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1033, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1053, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1026, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1024, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0980, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0965, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0978, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3498\n",
      "Reward: 7.4196\n",
      "Episode: 3, Step: 12, State: [1.0, 0.0009920635493472219, 0.9821958541870117, 0.0, 0.938569962978363, 0.9532338380813599, 0.08832487463951111, 0.7548125386238098, 0.9523809552192688, 0.8473895788192749]\n",
      "weights [10, 1.0009920467307012, 10, 0.9999990000010001, 10, 10, 1.0968807586187328, 4.078495351645892, 10, 6.552589526152061]\n",
      "Episode: 3, Step: 12, Epsilon: 0.3596\n",
      "Episode: 3, Step: 12, Action: [2.8088476e-10 4.1224439e-06 9.4189156e-10 9.9999583e-01 3.8495929e-10\n",
      " 2.7757951e-10 5.1667437e-10 4.7036297e-10 7.6838047e-09 1.6740762e-09], Действие: агент\n",
      "loss =  tensor(0.1037, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1025, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1036, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1043, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0988, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1004, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1043, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1000, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0971, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0944, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0916, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0913, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0920, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0909, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0879, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0893, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3609\n",
      "Reward: 7.6563\n",
      "Episode: 3, Step: 13, State: [1.0, 0.0029761905316263437, 0.9940652847290039, 0.0, 0.9637462496757507, 0.9582089781761169, 0.1532994955778122, 0.7021276354789734, 0.9259259104728699, 0.7048192620277405]\n",
      "weights [10, 1.002984068704582, 10, 0.9999990000010001, 10, 10, 1.1810537654381839, 3.3571313152083158, 10, 3.387743452116871]\n",
      "Episode: 3, Step: 13, Epsilon: 0.3580\n",
      "Episode: 3, Step: 13, Action: [4.0185857e-10 4.6363257e-06 1.2924167e-09 9.9999535e-01 5.4361915e-10\n",
      " 4.0082129e-10 7.1471024e-10 6.6071659e-10 9.9865325e-09 2.2827669e-09], Действие: агент\n",
      "loss =  tensor(0.0933, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0925, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0917, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0921, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0899, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0892, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0893, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0910, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0848, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0832, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0848, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0844, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0856, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0856, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0823, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0783, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3657\n",
      "Reward: 6.8075\n",
      "Episode: 3, Step: 14, State: [1.0, 0.0019841270986944437, 0.9950544238090515, 0.0, 0.9707955718040466, 0.9592039585113525, 0.17157360911369324, 0.6717325448989868, 0.9132274985313416, 0.672690749168396]\n",
      "weights [10, 1.0019870677065101, 10, 0.9999990000010001, 10, 10, 1.2071063933921033, 3.0462872215129075, 10, 3.055205260022499]\n",
      "Episode: 3, Step: 14, Epsilon: 0.3565\n",
      "Episode: 3, Step: 14, Action: [4.7471294e-10 5.2238656e-06 1.5051654e-09 9.9999475e-01 6.4064215e-10\n",
      " 4.7484061e-10 8.3679896e-10 7.7771550e-10 1.1350522e-08 2.6533629e-09], Действие: агент\n",
      "loss =  tensor(0.0838, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0840, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0823, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0835, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0809, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0801, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0798, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0807, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0785, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0783, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0771, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0767, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0757, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0754, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0741, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0748, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3642\n",
      "Reward: 6.5376\n",
      "Episode: 3, Step: 15, State: [1.0, 0.0019841270986944437, 0.9940652847290039, 0.0, 0.9697884917259216, 0.9592039585113525, 0.1786801964044571, 0.6788247227668762, 0.9216931462287903, 0.6676706671714783]\n",
      "weights [10, 1.0019870677065101, 10, 0.9999990000010001, 10, 10, 1.2175510417150557, 3.1135549879798763, 10, 3.0090542487916307]\n",
      "Episode: 3, Step: 15, Epsilon: 0.3550\n",
      "Episode: 3, Step: 15, Action: [0.18773123 0.00325914 0.00083104 0.08439779 0.04648202 0.14136126\n",
      " 0.03993951 0.01750764 0.27414943 0.20434093], Действие: случайное\n",
      "loss =  tensor(1.7375, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8113, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6716, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3835, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2803, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4994, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1824, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0831, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9915, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1215, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9340, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0144, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8601, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8993, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0501, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1854\n",
      "Reward: 8.2398\n",
      "Episode: 3, Step: 16, State: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5340101718902588, 0.1762917935848236, 0.5312169194221497, 0.8604417443275452]\n",
      "weights [10, 10, 10, 10, 10, 10, 2.145964984024319, 1.2140206667739577, 2.1331782401128945, 7.165415114759548]\n",
      "Episode: 3, Step: 16, Epsilon: 0.3535\n",
      "Episode: 3, Step: 16, Action: [1.9381663e-11 9.3305573e-07 1.0915123e-10 9.9999905e-01 2.4920319e-11\n",
      " 2.3572989e-11 3.6810884e-11 3.2161204e-11 1.2144465e-09 1.8871048e-10], Действие: агент\n",
      "loss =  tensor(0.1623, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1616, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1446, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1326, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1305, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1330, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1260, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1131, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1010, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1006, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0983, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0899, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0892, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0887, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0883, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0897, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1823\n",
      "Reward: 15.8270\n",
      "Episode: 3, Step: 17, State: [0.0, 0.8253968358039856, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9417989253997803, 0.4477911591529846]\n",
      "weights [0.9999990000010001, 5.727240267175864, 10, 10, 10, 10, 10, 10, 10, 1.8109057934681767]\n",
      "Episode: 3, Step: 17, Epsilon: 0.3519\n",
      "Episode: 3, Step: 17, Action: [0.14368491 0.00370254 0.04232205 0.0054026  0.05502926 0.01533156\n",
      " 0.24447316 0.12070361 0.23703854 0.13231176], Действие: случайное\n",
      "loss =  tensor(1.7086, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5247, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3594, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4666, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4453, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3115, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3641, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3023, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0995, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0914, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0983, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0926, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9433, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3154, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1032, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8941, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2309\n",
      "Reward: 5.8396\n",
      "Episode: 3, Step: 18, State: [0.0, 1.0, 1.0, 0.8745136260986328, 1.0, 1.0, 1.0, 0.9989868402481079, 0.8179894089698792, 0.031124498695135117]\n",
      "weights [0.9999990000010001, 10, 10, 7.968929215030015, 10, 10, 10, 10, 5.4941555883356425, 1.032123287801096]\n",
      "Episode: 3, Step: 18, Epsilon: 0.3504\n",
      "Episode: 3, Step: 18, Action: [0.10480513 0.01082587 0.24047249 0.02921495 0.20291595 0.00952636\n",
      " 0.08500736 0.04635657 0.12414985 0.14672546], Действие: случайное\n",
      "loss =  tensor(1.4571, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4567, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2218, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3050, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2102, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4695, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2381, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1969, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0112, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0547, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0234, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9697, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8990, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0204, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8448, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9078, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4437\n",
      "Reward: 25.8171\n",
      "Episode: 3, Step: 19, State: [0.3512476086616516, 0.042658731341362, 0.9703264236450195, 0.038910504430532455, 0.8922457098960876, 0.9990049600601196, 0.8223350048065186, 0.8865247964859009, 0.5111111402511597, 0.07530120760202408]\n",
      "weights [1.5414177611265292, 1.0445584956790126, 10, 1.0404847458276836, 9.28028683358064, 10, 5.628539096133631, 8.81242030515898, 2.0454504834969063, 1.0814320585135548]\n",
      "Episode: 3, Step: 19, Epsilon: 0.3489\n",
      "Episode: 3, Step: 19, Action: [3.3185710e-09 4.1112112e-06 9.1719778e-09 9.9999583e-01 4.1422719e-09\n",
      " 3.6960095e-09 5.0244586e-09 4.5977142e-09 5.2246232e-08 1.5400509e-08], Действие: агент\n",
      "loss =  tensor(0.1462, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1656, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1587, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1486, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1571, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1454, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1377, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1294, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1132, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1147, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1030, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1081, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1012, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1004, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0993, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1014, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4405\n",
      "Reward: 7.7955\n",
      "Episode: 3, Step: 20, State: [0.0019193857442587614, 0.3730158805847168, 1.0, 0.0009727626456879079, 0.9989929795265198, 1.0, 0.8944162726402283, 0.8176291584968567, 0.2063492089509964, 0.32630521059036255]\n",
      "weights [1.001922073021743, 1.5949341842954499, 10, 1.0009727078868775, 10, 10, 9.471066744270484, 5.483302640132437, 1.259998416532592, 1.484349487884293]\n",
      "Episode: 3, Step: 20, Epsilon: 0.3474\n",
      "Episode: 3, Step: 20, Action: [5.53762547e-09 7.79503716e-06 1.81311144e-08 9.99992013e-01\n",
      " 6.73503298e-09 6.62418209e-09 9.59637880e-09 7.45683693e-09\n",
      " 1.07324034e-07 2.98369329e-08], Действие: агент\n",
      "loss =  tensor(0.1060, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1050, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1122, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0967, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0985, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0981, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0965, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0964, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0929, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0907, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0885, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0895, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0869, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0875, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0841, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0881, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.456\n",
      "Reward: 10.4731\n",
      "accuracy =  0.3343\n",
      "--------------------------------------\n",
      "Episode: 3, Step: 20, Test Accuracy: 0.3343\n",
      "--------------------------------------\n",
      "Episode: 3, Step: 21, State: [0.0, 0.6597222089767456, 0.997032642364502, 0.0, 0.9929506778717041, 0.9900497794151306, 0.5807106494903564, 0.6788247227668762, 0.41798943281173706, 0.1495983898639679]\n",
      "weights [0.9999990000010001, 2.9387667594353855, 10, 0.9999990000010001, 10, 10, 2.3849821461059366, 3.1135549879798763, 1.7181789097956717, 1.1759136061918225]\n",
      "Episode: 3, Step: 21, Epsilon: 0.3460\n",
      "Episode: 3, Step: 21, Action: [2.49971856e-02 2.07333645e-01 3.09313293e-02 2.87595192e-04\n",
      " 5.86163493e-02 1.24447444e-02 1.42785291e-03 1.14039749e-01\n",
      " 1.17205064e-01 4.32716485e-01], Действие: случайное\n",
      "loss =  tensor(1.6009, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7832, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5939, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4548, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5190, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3667, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2310, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2101, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1300, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9758, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0663, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0308, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0072, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8771, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9058, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9605, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3821\n",
      "Reward: 5.6467\n",
      "Episode: 3, Step: 22, State: [0.16410748660564423, 0.7867063283920288, 0.997032642364502, 0.0, 0.9899294972419739, 0.9950248599052429, 0.893401026725769, 0.6251266598701477, 0.7523809671401978, 0.01606425642967224]\n",
      "weights [1.196324632236047, 4.688349654781663, 10, 0.9999990000010001, 10, 10, 9.380865391283695, 2.667560547498693, 4.03844547006494, 1.0163254970755384]\n",
      "Episode: 3, Step: 22, Epsilon: 0.3445\n",
      "Episode: 3, Step: 22, Action: [0.04276998 0.07562808 0.14317285 0.0564272  0.00729099 0.00633858\n",
      " 0.14320412 0.34361682 0.04569298 0.1358584 ], Действие: случайное\n",
      "loss =  tensor(1.4643, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4559, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3223, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4597, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4424, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5717, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5755, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1969, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1529, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0349, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1253, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0420, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1357, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1936, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9625, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9308, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3463\n",
      "Reward: 4.7062\n",
      "Episode: 3, Step: 23, State: [0.0, 0.9970238208770752, 0.9930761456489563, 0.0, 1.0, 1.0, 1.0, 0.8135765194892883, 0.770370364189148, 0.014056225307285786]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 10, 5.364102382157592, 4.354819627916308, 1.0142555908485507]\n",
      "Episode: 3, Step: 23, Epsilon: 0.3430\n",
      "Episode: 3, Step: 23, Action: [3.9983275e-10 2.5207748e-07 1.3979536e-09 9.9999976e-01 4.0193623e-10\n",
      " 4.2936144e-10 6.5949063e-10 4.7582399e-10 1.0503378e-08 2.1747000e-09], Действие: агент\n",
      "loss =  tensor(0.1677, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1667, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1531, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1610, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1446, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1462, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1392, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1179, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1178, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1125, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1107, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1097, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1059, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1049, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1091, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1039, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1625\n",
      "Reward: 2.6927\n",
      "Episode: 3, Step: 24, State: [0.0, 1.0, 1.0, 0.9523346424102783, 1.0, 1.0, 0.9989847540855408, 0.8318135738372803, 0.8941798806190491, 0.7319276928901672]\n",
      "weights [0.9999990000010001, 10, 10, 10, 10, 10, 10, 5.945747686468009, 9.449909487349574, 3.7303229134644442]\n",
      "Episode: 3, Step: 24, Epsilon: 0.3416\n",
      "Episode: 3, Step: 24, Action: [0.10751194 0.03361143 0.25385758 0.037734   0.04537285 0.14444382\n",
      " 0.06925369 0.20832066 0.09106565 0.00882838], Действие: случайное\n",
      "loss =  tensor(1.4103, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4167, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3629, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3318, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2989, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3067, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1571, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1113, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1720, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0124, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9801, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9471, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9357, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8990, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8717, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8932, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2014\n",
      "Reward: 18.2042\n",
      "Episode: 3, Step: 25, State: [1.0, 1.0, 1.0, 0.6206225752830505, 0.8539778590202332, 0.9412935376167297, 0.0680203065276146, 0.49949342012405396, 0.9936507940292358, 0.9979919791221619]\n",
      "weights [10, 10, 10, 2.6358905379136686, 6.84822962504663, 10, 1.0729836004157847, 1.997971739504637, 10, 10]\n",
      "Episode: 3, Step: 25, Epsilon: 0.3401\n",
      "Episode: 3, Step: 25, Action: [1.4411396e-11 5.7356323e-07 7.1757440e-11 9.9999940e-01 1.7115979e-11\n",
      " 1.4340269e-11 2.7401701e-11 2.2338907e-11 7.5035134e-10 1.2459429e-10], Действие: агент\n",
      "loss =  tensor(0.1297, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1368, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1360, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1367, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1300, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1288, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1289, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1241, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1129, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1168, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1119, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1098, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1086, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1080, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1072, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1018, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4672\n",
      "Reward: 27.7963\n",
      "Episode: 3, Step: 26, State: [0.0, 0.5158730149269104, 0.7952522039413452, 0.0, 0.9073514342308044, 0.8258706331253052, 0.5949238538742065, 0.09726443886756897, 0.7195767164230347, 0.9146586060523987]\n",
      "weights [0.9999990000010001, 2.0655694998689826, 4.884033602393091, 0.9999990000010001, 10, 5.742823712762321, 2.4686655605336423, 1.1077428820934843, 3.566024979165329, 10]\n",
      "Episode: 3, Step: 26, Epsilon: 0.3387\n",
      "Episode: 3, Step: 26, Action: [2.71091523e-08 1.01605256e-04 8.44467252e-08 9.99897718e-01\n",
      " 3.16398108e-08 2.78087775e-08 5.15972332e-08 3.97737985e-08\n",
      " 4.09721252e-07 1.22078760e-07], Действие: агент\n",
      "loss =  tensor(0.1111, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1159, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1127, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1122, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1068, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1058, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1061, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1055, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0980, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0972, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0950, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0930, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0947, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0961, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0957, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0962, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3773\n",
      "Reward: 7.1256\n",
      "Episode: 3, Step: 27, State: [0.0, 0.9692460298538208, 0.9772502183914185, 0.0019455252913758159, 0.9869083762168884, 0.9562188982963562, 0.7583756446838379, 0.1225937157869339, 0.6761904954910278, 0.8152610659599304]\n",
      "weights [0.9999990000010001, 10, 10, 1.0019483138369072, 10, 10, 4.138638507914533, 1.139721561460349, 3.08822594102191, 5.413014815644043]\n",
      "Episode: 3, Step: 27, Epsilon: 0.3372\n",
      "Episode: 3, Step: 27, Action: [2.4070148e-09 6.9499170e-06 9.0135277e-09 9.9999297e-01 2.6348950e-09\n",
      " 2.5950146e-09 4.7241264e-09 3.2641034e-09 5.7856404e-08 1.3603000e-08], Действие: агент\n",
      "loss =  tensor(0.0972, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1001, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0995, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0921, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0941, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0952, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0920, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0932, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0903, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0900, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0873, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0861, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0859, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0824, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0825, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0835, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3977\n",
      "Reward: 7.9222\n",
      "Episode: 3, Step: 28, State: [0.0, 0.9732142686843872, 0.9930761456489563, 0.0, 0.9989929795265198, 0.9850746393203735, 0.8426395654678345, 0.15501520037651062, 0.5566137433052063, 0.5491967797279358]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 6.354797177421477, 1.183451840783102, 2.255364774022704, 2.218257849042521]\n",
      "Episode: 3, Step: 28, Epsilon: 0.3358\n",
      "Episode: 3, Step: 28, Action: [4.4615489e-09 9.3867193e-06 1.5613288e-08 9.9999046e-01 4.7722404e-09\n",
      " 4.8811075e-09 8.1436760e-09 5.7020779e-09 9.1722661e-08 2.3550129e-08], Действие: агент\n",
      "loss =  tensor(0.0840, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0867, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0880, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0856, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0836, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0821, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0808, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0833, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0799, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0800, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0776, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0773, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0772, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0763, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0735, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0755, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4245\n",
      "Reward: 8.7189\n",
      "Episode: 3, Step: 29, State: [0.0, 0.91567462682724, 0.9446092844009399, 0.0, 0.9919435977935791, 0.9691542387008667, 0.6873096227645874, 0.13880445063114166, 0.5862433910369873, 0.5522088408470154]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 3.1980414965109216, 1.1611751123862095, 2.4168739821033567, 2.2331788968604025]\n",
      "Episode: 3, Step: 29, Epsilon: 0.3344\n",
      "Episode: 3, Step: 29, Action: [1.0112601e-08 2.3265397e-05 3.3910869e-08 9.9997652e-01 1.0782892e-08\n",
      " 1.0740791e-08 1.8315468e-08 1.3083958e-08 1.8050844e-07 5.0403649e-08], Действие: агент\n",
      "loss =  tensor(0.0778, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0768, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0741, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0733, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0761, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0743, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0747, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0748, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0718, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0713, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0728, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0694, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0695, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0694, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0688, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0687, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4352\n",
      "Reward: 8.4586\n",
      "Episode: 3, Step: 30, State: [0.0, 0.879960298538208, 0.9307616353034973, 0.0, 0.9919435977935791, 0.967164158821106, 0.6629441380500793, 0.14690983295440674, 0.5830687880516052, 0.5160642862319946]\n",
      "weights [0.9999990000010001, 8.330507801291816, 10, 0.9999990000010001, 10, 10, 2.966858452947261, 1.172207659192133, 2.398471433346037, 2.0663858962339248]\n",
      "Episode: 3, Step: 30, Epsilon: 0.3329\n",
      "Episode: 3, Step: 30, Action: [1.3442055e-08 2.9928220e-05 4.3917037e-08 9.9996972e-01 1.4320132e-08\n",
      " 1.4188380e-08 2.4014115e-08 1.7355674e-08 2.2420159e-07 6.4981975e-08], Действие: агент\n",
      "loss =  tensor(0.0710, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0708, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0698, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0687, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0697, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0696, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0678, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0706, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0672, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0657, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0676, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0659, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0639, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0641, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0657, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0644, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4557\n",
      "Reward: 9.7150\n",
      "accuracy =  0.3198\n",
      "--------------------------------------\n",
      "Episode: 3, Step: 30, Test Accuracy: 0.3198\n",
      "--------------------------------------\n",
      "Episode: 3, Step: 31, State: [0.0, 0.7361111044883728, 0.9268051385879517, 0.0, 0.9788519740104675, 0.9552238583564758, 0.5766497254371643, 0.14488348364830017, 0.6211640238761902, 0.5361445546150208]\n",
      "weights [0.9999990000010001, 3.789459229051608, 10, 0.9999990000010001, 10, 10, 2.3621046163912647, 1.169429909781794, 2.6396578555552206, 2.1558393980492103]\n",
      "Episode: 3, Step: 31, Epsilon: 0.3315\n",
      "Episode: 3, Step: 31, Action: [2.0949647e-08 4.6522135e-05 6.5247789e-08 9.9995303e-01 2.2727445e-08\n",
      " 2.1858398e-08 3.7143188e-08 2.7701683e-08 3.0844967e-07 9.5964303e-08], Действие: агент\n",
      "loss =  tensor(0.0663, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0649, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0670, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0642, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0659, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0645, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0637, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0651, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0634, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0619, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0621, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0618, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0617, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0599, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0605, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0622, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4444\n",
      "Reward: 7.5988\n",
      "Episode: 3, Step: 32, State: [0.0, 0.836309552192688, 0.9584569931030273, 0.0, 0.9879153966903687, 0.9681591987609863, 0.6081218123435974, 0.16818642616271973, 0.5915343761444092, 0.4678714871406555]\n",
      "weights [0.9999990000010001, 6.109054647602246, 10, 0.9999990000010001, 10, 10, 2.551806861651439, 1.2021910068091932, 2.448180442653596, 1.8792417556895133]\n",
      "Episode: 3, Step: 32, Epsilon: 0.3301\n",
      "Episode: 3, Step: 32, Action: [1.5908631e-08 3.2326796e-05 5.0648062e-08 9.9996734e-01 1.6903799e-08\n",
      " 1.6681104e-08 2.7970890e-08 2.0443419e-08 2.4590557e-07 7.4925552e-08], Действие: агент\n",
      "loss =  tensor(0.0605, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0597, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0611, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0618, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0613, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0593, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0601, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0612, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0593, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0590, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0577, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0580, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0567, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0562, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0566, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0560, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4431\n",
      "Reward: 7.6907\n",
      "Episode: 3, Step: 33, State: [0.0, 0.8621031641960144, 0.9564787149429321, 0.0, 0.9879153966903687, 0.9731343388557434, 0.6538071036338806, 0.1762917935848236, 0.561904788017273, 0.42670682072639465]\n",
      "weights [0.9999990000010001, 7.2517454256602445, 10, 0.9999990000010001, 10, 10, 2.888554681340899, 1.2140206667739577, 2.282603621415077, 1.7443051685385222]\n",
      "Episode: 3, Step: 33, Epsilon: 0.3287\n",
      "Episode: 3, Step: 33, Action: [0.03902612 0.12462016 0.14169074 0.14310683 0.12905457 0.16849485\n",
      " 0.07318899 0.03063148 0.05515994 0.09502633], Действие: случайное\n",
      "loss =  tensor(1.4394, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5246, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3405, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4577, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1933, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2336, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2947, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2847, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0839, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0421, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0635, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9493, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9921, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9123, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8572, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9441, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2986\n",
      "Reward: 5.9872\n",
      "Episode: 3, Step: 34, State: [1.0, 1.0, 0.97230464220047, 0.0, 0.982880175113678, 0.9611940383911133, 0.3187817335128784, 0.9381965398788452, 0.8275132179260254, 0.017068272456526756]\n",
      "weights [10, 10, 10, 0.9999990000010001, 10, 10, 1.4679561327687507, 10, 5.797512078688166, 1.0173636221261866]\n",
      "Episode: 3, Step: 34, Epsilon: 0.3273\n",
      "Episode: 3, Step: 34, Action: [1.3290237e-10 7.8670826e-07 4.7853410e-10 9.9999917e-01 1.4006853e-10\n",
      " 1.2311686e-10 2.1030545e-10 1.6930005e-10 3.9410644e-09 8.2669088e-10], Действие: агент\n",
      "loss =  tensor(0.0800, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0883, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0829, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0795, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0827, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0826, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0846, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0839, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0807, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0747, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0739, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0720, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0734, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0699, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0729, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0693, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3479\n",
      "Reward: 15.0854\n",
      "Episode: 3, Step: 35, State: [0.0, 0.97817462682724, 1.0, 0.0019455252913758159, 1.0, 0.9990049600601196, 0.9807106852531433, 0.9057750701904297, 0.6719576716423035, 0.0301204826682806]\n",
      "weights [0.9999990000010001, 10, 10, 1.0019483138369072, 10, 10, 10, 10, 3.048377801208034, 1.0310548383332243]\n",
      "Episode: 3, Step: 35, Epsilon: 0.3260\n",
      "Episode: 3, Step: 35, Action: [3.5533043e-10 2.4310560e-07 1.2511449e-09 9.9999976e-01 3.5950662e-10\n",
      " 3.7926517e-10 5.8494087e-10 4.1973061e-10 8.8214138e-09 1.9575557e-09], Действие: агент\n",
      "loss =  tensor(0.0772, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0752, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0742, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0723, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0711, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0724, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0683, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0740, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0680, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0657, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0666, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0662, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0634, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0633, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0645, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0607, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4955\n",
      "Reward: 19.8895\n",
      "Episode: 3, Step: 36, State: [0.028790786862373352, 0.2876984179019928, 0.9841740727424622, 0.0, 0.9879153966903687, 0.9412935376167297, 0.7045685052871704, 0.545086145401001, 0.5142857432365417, 0.08534136414527893]\n",
      "weights [1.0296432085175093, 1.4038977607726935, 10, 0.9999990000010001, 10, 10, 3.384868008416048, 2.198213555548732, 2.0588194133811135, 1.093302864584738]\n",
      "Episode: 3, Step: 36, Epsilon: 0.3246\n",
      "Episode: 3, Step: 36, Action: [2.6483370e-08 2.6353280e-05 6.9343066e-08 9.9997318e-01 3.0030201e-08\n",
      " 2.8498969e-08 4.0928295e-08 3.4094750e-08 2.9013222e-07 1.0593641e-07], Действие: агент\n",
      "loss =  tensor(0.0638, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0634, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0649, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0638, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0636, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0640, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0621, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0650, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0599, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0583, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0584, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0596, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0580, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0588, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0585, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0562, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.5526\n",
      "Reward: 11.0281\n",
      "Episode: 3, Step: 37, State: [0.126679465174675, 0.0902777761220932, 0.888229489326477, 0.0, 0.9617321491241455, 0.8587064743041992, 0.4680202901363373, 0.435663640499115, 0.5365079641342163, 0.1375502049922943]\n",
      "weights [1.145053637318141, 1.0992354309009145, 8.946823693927987, 0.9999990000010001, 10, 7.0774150313009585, 1.8797674078375555, 1.771989720624604, 2.1575297202298755, 1.159486437705777]\n",
      "Episode: 3, Step: 37, Epsilon: 0.3232\n",
      "Episode: 3, Step: 37, Action: [1.6744912e-07 2.7372231e-04 3.9319914e-07 9.9972290e-01 1.9599723e-07\n",
      " 1.7183643e-07 2.5236147e-07 2.2481548e-07 1.3699832e-06 5.9495147e-07], Действие: агент\n",
      "loss =  tensor(0.0588, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0594, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0573, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0590, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0587, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0578, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0575, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0585, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0553, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0558, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0544, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0552, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0542, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0546, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0533, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0535, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.5482\n",
      "Reward: 9.1284\n",
      "Episode: 3, Step: 38, State: [0.042226485908031464, 0.1765872985124588, 0.8872403502464294, 0.0, 0.9667673707008362, 0.8825870752334595, 0.4822334945201874, 0.43161094188690186, 0.5534391403198242, 0.12851405143737793]\n",
      "weights [1.0440870844721357, 1.2144563518841696, 8.868341945398688, 0.9999990000010001, 10, 8.516877380501041, 1.931368788918696, 1.7593551923123543, 2.239331412486038, 1.1474641148089935]\n",
      "Episode: 3, Step: 38, Epsilon: 0.3218\n",
      "Episode: 3, Step: 38, Action: [1.5315274e-07 2.1480881e-04 3.6564802e-07 9.9978215e-01 1.7465507e-07\n",
      " 1.5698859e-07 2.3214997e-07 2.0110171e-07 1.2733435e-06 5.4459576e-07], Действие: агент\n",
      "loss =  tensor(0.0531, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0538, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0537, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0536, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0525, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0522, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0534, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0533, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0509, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0522, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0512, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0489, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0485, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0504, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0492, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0499, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.5431\n",
      "Reward: 8.9471\n",
      "Episode: 3, Step: 39, State: [0.051823414862155914, 0.1597222238779068, 0.919881284236908, 0.0, 0.9677743911743164, 0.8885571956634521, 0.46700507402420044, 0.43971630930900574, 0.5809524059295654, 0.12751004099845886]\n",
      "weights [1.0546547563182713, 1.1900812306780186, 10, 0.9999990000010001, 10, 8.973132297064371, 1.8761869486510945, 1.7848069322877778, 2.3863580838835077, 1.1461436817000112]\n",
      "Episode: 3, Step: 39, Epsilon: 0.3205\n",
      "Episode: 3, Step: 39, Action: [0.08852964 0.00375358 0.01792894 0.12048237 0.38458663 0.08519369\n",
      " 0.0557962  0.00338008 0.01227293 0.22807594], Действие: случайное\n",
      "loss =  tensor(1.7284, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3838, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4209, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3782, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3741, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2946, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4519, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3159, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9972, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0331, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0180, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1392, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0435, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7831, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9440, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7935, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2564\n",
      "Reward: 4.6015\n",
      "Episode: 3, Step: 40, State: [1.0, 1.0, 1.0, 0.8132295608520508, 0.9969788789749146, 0.9402984976768494, 0.09137056022882462, 0.7456940412521362, 0.7291005253791809, 0.08935742825269699]\n",
      "weights [10, 10, 10, 5.354137680589694, 10, 10, 1.100557450234481, 3.9322557468490835, 3.6913925728616963, 1.098124481438159]\n",
      "Episode: 3, Step: 40, Epsilon: 0.3191\n",
      "Episode: 3, Step: 40, Action: [0.08022733 0.14237895 0.13037386 0.00881074 0.08288467 0.02371534\n",
      " 0.14915869 0.05928131 0.00781278 0.31535632], Действие: случайное\n",
      "loss =  tensor(1.1293, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1191, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1239, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1395, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1349, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0556, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0161, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1119, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8540, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8821, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8322, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8624, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8029, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8238, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7617, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3033\n",
      "Reward: 16.2928\n",
      "accuracy =  0.2727\n",
      "--------------------------------------\n",
      "Episode: 3, Step: 40, Test Accuracy: 0.2727\n",
      "--------------------------------------\n",
      "Episode: 3, Step: 41, State: [0.0, 1.0, 1.0, 0.04182879254221916, 1.0, 1.0, 1.0, 0.9979736804962158, 0.9820106029510498, 0.009036144241690636]\n",
      "weights [0.9999990000010001, 10, 10, 1.0436537317787546, 10, 10, 10, 10, 10, 1.0091175223714435]\n",
      "Episode: 3, Step: 41, Epsilon: 0.3178\n",
      "Episode: 3, Step: 41, Action: [1.10513577e-01 1.34916269e-02 1.93693986e-02 9.94736354e-02\n",
      " 1.50594780e-01 1.01212182e-04 3.02511975e-01 1.35687794e-01\n",
      " 3.53330555e-02 1.32922944e-01], Действие: случайное\n",
      "loss =  tensor(1.2617, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1154, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2828, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1452, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2860, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1086, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1346, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1649, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9577, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8688, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8677, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7546, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8296, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8652, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7430, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4636\n",
      "Reward: 26.2407\n",
      "Episode: 3, Step: 42, State: [0.003838771488517523, 0.4126984179019928, 0.4243323504924774, 0.561284065246582, 0.6455186009407043, 0.9741293787956238, 0.641624391078949, 0.7730496525764465, 0.7269841432571411, 0.23694778978824615]\n",
      "weights [1.0038525567208587, 1.7026998185972952, 1.7371104034508178, 2.279374058268466, 2.8210145345826496, 10, 2.790360685120206, 4.406230724569022, 3.662777500005616, 1.3105245959485463]\n",
      "Episode: 3, Step: 42, Epsilon: 0.3165\n",
      "Episode: 3, Step: 42, Action: [1.4306037e-08 4.1978292e-05 3.9627466e-08 9.9995780e-01 1.5574738e-08\n",
      " 1.3849130e-08 1.9822682e-08 1.8211491e-08 1.6464351e-07 5.5018546e-08], Действие: агент\n",
      "loss =  tensor(0.1478, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1536, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1377, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1383, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1277, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1287, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1291, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1235, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1008, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0988, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0925, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0930, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0893, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0893, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0877, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0852, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1842\n",
      "Reward: 2.3782\n",
      "Episode: 3, Step: 43, State: [0.0, 1.0, 1.0, 0.9961089491844177, 1.0, 1.0, 0.9979695677757263, 0.9777102470397949, 0.8984127044677734, 0.3212851285934448]\n",
      "weights [0.9999990000010001, 10, 10, 10, 10, 10, 10, 10, 9.843653688261487, 1.4733705842588047]\n",
      "Episode: 3, Step: 43, Epsilon: 0.3151\n",
      "Episode: 3, Step: 43, Action: [0.02316834 0.11676183 0.1269136  0.22875822 0.08997574 0.01174983\n",
      " 0.07443332 0.18009058 0.14258398 0.00556458], Действие: случайное\n",
      "loss =  tensor(1.2035, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0769, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3402, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1180, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1920, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9896, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0590, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1039, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7479, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7837, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7590, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7140, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6785, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6556, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6694, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7090, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.5058\n",
      "Reward: 38.2151\n",
      "Episode: 3, Step: 44, State: [0.007677542977035046, 0.7807539701461792, 0.61622154712677, 0.002918287878856063, 0.6545820832252502, 0.9184079766273499, 0.4974619150161743, 0.24113474786281586, 0.6126984357833862, 0.6435742974281311]\n",
      "weights [1.0077359281620382, 4.561065208804575, 2.6056632071189076, 1.0029258233478444, 2.8950354234713425, 10, 1.9898949750986734, 1.3177552660745082, 2.5819607004737306, 2.8056259331422084]\n",
      "Episode: 3, Step: 44, Epsilon: 0.3138\n",
      "Episode: 3, Step: 44, Action: [1.0043544e-07 3.6017725e-04 2.7969037e-07 9.9963748e-01 1.0490810e-07\n",
      " 9.1970350e-08 1.6278885e-07 1.2477884e-07 1.0345511e-06 3.9205878e-07], Действие: агент\n",
      "loss =  tensor(0.1095, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1054, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1102, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1033, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1083, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1084, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1080, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1005, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0953, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0932, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0919, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0860, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0872, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0862, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0862, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0850, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4654\n",
      "Reward: 9.4146\n",
      "Episode: 3, Step: 45, State: [0.06909789144992828, 0.190476194024086, 0.9841740727424622, 0.0, 0.9778448939323425, 0.9791044592857361, 0.7543147206306458, 0.09827760607004166, 0.5206349492073059, 0.8032128810882568]\n",
      "weights [1.0742256533631627, 1.23529259711129, 10, 0.9999990000010001, 10, 10, 4.070231364026001, 1.1089875306902321, 2.086088487798354, 5.081607596688734]\n",
      "Episode: 3, Step: 45, Epsilon: 0.3125\n",
      "Episode: 3, Step: 45, Action: [0.11570199 0.10184373 0.06618687 0.05414069 0.16634575 0.11648267\n",
      " 0.25264823 0.04360806 0.00395665 0.07908537], Действие: случайное\n",
      "loss =  tensor(1.3290, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3216, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3789, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3081, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1486, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1860, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3324, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0873, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0084, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8848, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8422, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9086, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8369, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8572, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8930, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7971, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1882\n",
      "Reward: 8.4025\n",
      "Episode: 3, Step: 46, State: [1.0, 1.0, 1.0, 0.938715934753418, 0.9667673707008362, 0.9681591987609863, 0.013197969645261765, 0.9321175217628479, 0.9820106029510498, 0.2991967797279358]\n",
      "weights [10, 10, 10, 10, 10, 10, 1.0133734587747645, 10, 10, 1.4269320461737272]\n",
      "Episode: 3, Step: 46, Epsilon: 0.3112\n",
      "Episode: 3, Step: 46, Action: [5.6932870e-12 1.0543388e-07 2.7240429e-11 9.9999988e-01 6.2781997e-12\n",
      " 5.6287509e-12 9.1438445e-12 8.1401526e-12 2.4529789e-10 4.6083075e-11], Действие: агент\n",
      "loss =  tensor(0.1262, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1312, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1263, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1217, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1239, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1266, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1162, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1217, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1080, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0997, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0978, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0913, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0949, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0928, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0923, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0896, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.233\n",
      "Reward: 14.8773\n",
      "Episode: 3, Step: 47, State: [0.0, 1.0, 1.0, 0.9542801380157471, 1.0, 1.0, 0.9675126671791077, 0.8804457783699036, 0.811640202999115, 0.0833333358168602]\n",
      "weights [0.9999990000010001, 10, 10, 10, 10, 10, 10, 8.36433562972262, 5.308960335283045, 1.0909079037833402]\n",
      "Episode: 3, Step: 47, Epsilon: 0.3099\n",
      "Episode: 3, Step: 47, Action: [1.4234979e-11 2.5810005e-08 6.3172426e-11 1.0000000e+00 1.4703943e-11\n",
      " 1.6531646e-11 2.2393483e-11 1.7910702e-11 4.7930182e-10 9.1757164e-11], Действие: агент\n",
      "loss =  tensor(0.1011, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0989, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0987, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0982, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0940, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0931, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0934, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0903, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0891, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0868, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0790, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0821, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0792, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0779, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0766, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0768, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3326\n",
      "Reward: 13.5985\n",
      "Episode: 3, Step: 48, State: [0.0, 0.9960317611694336, 1.0, 0.25486379861831665, 1.0, 1.0, 0.9390863180160522, 0.7345491647720337, 0.7724867463111877, 0.019076304510235786]\n",
      "weights [0.9999990000010001, 10, 10, 1.342034726149403, 10, 10, 10, 3.767161749479766, 4.395329012518805, 1.0194462476048802]\n",
      "Episode: 3, Step: 48, Epsilon: 0.3086\n",
      "Episode: 3, Step: 48, Action: [2.3663790e-10 1.8696826e-07 8.2454965e-10 9.9999976e-01 2.3461194e-10\n",
      " 2.4921873e-10 3.7174938e-10 2.7672478e-10 5.0512008e-09 1.2318793e-09], Действие: агент\n",
      "loss =  tensor(0.0856, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0866, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0822, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0796, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0832, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0782, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0813, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0811, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0761, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0771, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0737, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0736, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0706, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0707, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0696, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0697, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3919\n",
      "Reward: 8.3884\n",
      "Episode: 3, Step: 49, State: [0.0, 0.9265872836112976, 1.0, 0.0, 0.9989929795265198, 1.0, 0.8263959288597107, 0.5937183499336243, 0.7650793790817261, 0.01606425642967224]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 5.760200398707855, 2.461340645082006, 4.256738890576132, 1.0163254970755384]\n",
      "Episode: 3, Step: 49, Epsilon: 0.3073\n",
      "Episode: 3, Step: 49, Action: [1.3828629e-09 8.9138490e-07 4.2520503e-09 9.9999905e-01 1.3587647e-09\n",
      " 1.3934378e-09 2.1691267e-09 1.5996180e-09 2.1918186e-08 6.3122085e-09], Действие: агент\n",
      "loss =  tensor(0.0759, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0749, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0731, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0710, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0738, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0711, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0712, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0681, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0676, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0680, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0671, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0634, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0631, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0631, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0649, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0648, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4298\n",
      "Reward: 9.4198\n",
      "Episode: 3, Step: 50, State: [0.0, 0.8373016119003296, 0.9871414303779602, 0.0, 0.9919435977935791, 0.9840795993804932, 0.5796954035758972, 0.5552178025245667, 0.7841269969940186, 0.02610441856086254]\n",
      "weights [0.9999990000010001, 6.146304615401474, 10, 0.9999990000010001, 10, 10, 2.3792212345204313, 2.248286368900509, 4.632331758689313, 1.0268030703242528]\n",
      "Episode: 3, Step: 50, Epsilon: 0.3060\n",
      "Episode: 3, Step: 50, Action: [4.3696611e-09 3.1091972e-06 1.2702143e-08 9.9999678e-01 4.2993156e-09\n",
      " 4.2731956e-09 6.7946115e-09 5.1342841e-09 5.7035958e-08 1.8769473e-08], Действие: агент\n",
      "loss =  tensor(0.0669, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0639, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0661, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0623, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0646, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0634, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0624, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0610, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0600, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0606, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0603, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0598, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0577, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0581, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0578, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0585, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4649\n",
      "Reward: 9.4481\n",
      "accuracy =  0.3366\n",
      "--------------------------------------\n",
      "Episode: 3, Step: 50, Test Accuracy: 0.3366\n",
      "--------------------------------------\n",
      "Episode: 3, Step: 51, State: [0.0, 0.620039701461792, 0.97230464220047, 0.0, 0.9748237729072571, 0.9592039585113525, 0.4548223316669464, 0.5724417567253113, 0.7978835701942444, 0.04417670518159866]\n",
      "weights [0.9999990000010001, 2.6318469903308914, 10, 0.9999990000010001, 10, 10, 1.8342610562104618, 2.3388571659472754, 4.947618822191867, 1.046217391021633]\n",
      "Episode: 3, Step: 51, Epsilon: 0.3047\n",
      "Episode: 3, Step: 51, Action: [1.04091606e-08 7.99420195e-06 2.80539094e-08 9.99991775e-01\n",
      " 1.05937925e-08 1.00696411e-08 1.58707127e-08 1.25760016e-08\n",
      " 1.13143109e-07 4.16423234e-08], Действие: агент\n",
      "loss =  tensor(0.0613, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0622, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0579, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0598, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0571, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0586, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0579, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0564, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0562, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0560, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0550, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0526, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0557, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0553, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0530, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0558, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4886\n",
      "Reward: 8.6188\n",
      "Episode: 3, Step: 52, State: [0.003838771488517523, 0.4722222089767456, 0.9713155031204224, 0.0, 0.9697884917259216, 0.9502487778663635, 0.3746192753314972, 0.564336359500885, 0.800000011920929, 0.05220883712172508]\n",
      "weights [1.0038525567208587, 1.8947332045329177, 10, 0.9999990000010001, 10, 10, 1.599023381327735, 2.2953434982796854, 4.9999752981452605, 1.0550836345419645]\n",
      "Episode: 3, Step: 52, Epsilon: 0.3035\n",
      "Episode: 3, Step: 52, Action: [1.8968112e-08 1.5371581e-05 4.8559521e-08 9.9998426e-01 1.9764913e-08\n",
      " 1.8285904e-08 2.8556636e-08 2.3373401e-08 1.8111456e-07 7.2161491e-08], Действие: агент\n",
      "loss =  tensor(0.0528, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0548, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0538, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0544, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0541, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0530, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0509, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0531, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0513, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0503, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0504, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0510, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0501, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0490, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0493, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0492, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4929\n",
      "Reward: 8.2739\n",
      "Episode: 3, Step: 53, State: [0.003838771488517523, 0.4404761791229248, 0.9663699269294739, 0.0, 0.964753270149231, 0.9452736377716064, 0.3583756387233734, 0.5825734734535217, 0.8010581731796265, 0.05321285128593445]\n",
      "weights [1.0038525567208587, 1.7872308120888438, 10, 0.9999990000010001, 10, 10, 1.5585418849565484, 2.39562543532609, 5.026569773751657, 1.0562024898159184]\n",
      "Episode: 3, Step: 53, Epsilon: 0.3022\n",
      "Episode: 3, Step: 53, Action: [2.0504384e-08 1.6656846e-05 5.1909723e-08 9.9998295e-01 2.1467724e-08\n",
      " 1.9703798e-08 3.0731570e-08 2.5341084e-08 1.9044970e-07 7.7240593e-08], Действие: агент\n",
      "loss =  tensor(0.0507, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0513, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0508, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0506, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0490, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0506, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0497, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0505, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0478, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0499, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0479, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0465, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0462, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0459, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0471, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0476, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4935\n",
      "Reward: 8.2609\n",
      "Episode: 3, Step: 54, State: [0.004798464477062225, 0.4553571343421936, 0.9693372845649719, 0.0, 0.9597180485725403, 0.9512437582015991, 0.3492385745048523, 0.5734549164772034, 0.7894179821014404, 0.05622490122914314]\n",
      "weights [1.0048205910915826, 1.8360621739349372, 10, 0.9999990000010001, 10, 10, 1.53665909527448, 2.3444125702458956, 4.748721003142392, 1.059573347219078]\n",
      "Episode: 3, Step: 54, Epsilon: 0.3009\n",
      "Episode: 3, Step: 54, Action: [2.1257904e-08 1.7484201e-05 5.3845699e-08 9.9998212e-01 2.2197504e-08\n",
      " 2.0396945e-08 3.1821088e-08 2.6167926e-08 1.9518431e-07 8.0069341e-08], Действие: агент\n",
      "loss =  tensor(0.0462, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0469, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0466, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0477, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0467, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0465, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0447, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0455, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0443, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0450, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0454, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0441, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0438, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0443, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0437, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0429, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4892\n",
      "Reward: 7.9706\n",
      "Episode: 3, Step: 55, State: [0.003838771488517523, 0.4702380895614624, 0.9742828607559204, 0.0, 0.9718025922775269, 0.9532338380813599, 0.3664974570274353, 0.5694022178649902, 0.7883597612380981, 0.05421686917543411]\n",
      "weights [1.0038525567208587, 1.8876368660316372, 10, 0.9999990000010001, 10, 10, 1.5785231370731374, 2.3223474879370665, 4.724977068977602, 1.057323724736391]\n",
      "Episode: 3, Step: 55, Epsilon: 0.2997\n",
      "Episode: 3, Step: 55, Action: [0.05297128 0.01360273 0.04551892 0.05070483 0.39985618 0.00883654\n",
      " 0.0038313  0.09520246 0.10523373 0.22424203], Действие: случайное\n",
      "loss =  tensor(1.5405, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5283, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7354, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8890, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2838, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3303, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2894, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5383, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0691, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0271, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2966, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9435, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9625, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8601, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8942, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2497\n",
      "Reward: 3.9565\n",
      "Episode: 3, Step: 56, State: [1.0, 1.0, 1.0, 0.07392995804548264, 0.9949647784233093, 1.0, 0.913705587387085, 0.7963525652885437, 0.720634937286377, 0.0060240961611270905]\n",
      "weights [10, 10, 10, 1.079830763187943, 10, 10, 10, 4.910423207607128, 3.579532854801679, 1.0060595936765382]\n",
      "Episode: 3, Step: 56, Epsilon: 0.2984\n",
      "Episode: 3, Step: 56, Action: [2.1218551e-11 7.7659372e-08 7.7134896e-11 9.9999988e-01 2.2897781e-11\n",
      " 2.0842704e-11 3.2606941e-11 2.6798829e-11 6.2097161e-10 1.2970795e-10], Действие: агент\n",
      "loss =  tensor(0.0906, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0885, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0822, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0885, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0860, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0861, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0864, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0818, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0750, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0710, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0651, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0664, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0699, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0661, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0628, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0631, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3169\n",
      "Reward: 12.4992\n",
      "Episode: 3, Step: 57, State: [0.0, 0.9990079402923584, 1.0, 0.0, 1.0, 1.0, 1.0, 0.9878419637680054, 0.9037036895751953, 0.001004016026854515]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 10, 1.0010040230780932]\n",
      "Episode: 3, Step: 57, Epsilon: 0.2972\n",
      "Episode: 3, Step: 57, Action: [7.3912140e-11 3.1502914e-08 2.5253674e-10 1.0000000e+00 7.1822798e-11\n",
      " 7.3584111e-11 1.1869662e-10 8.6164346e-11 1.5955091e-09 3.7354414e-10], Действие: агент\n",
      "loss =  tensor(0.0724, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0677, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0685, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0662, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0714, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0671, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0670, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0635, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0629, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0591, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0584, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0588, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0583, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0567, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0549, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0572, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3207\n",
      "Reward: 5.2146\n",
      "Episode: 3, Step: 58, State: [0.0, 1.0, 1.0, 0.06809338182210922, 1.0, 1.0, 0.9949238300323486, 0.9209726452827454, 0.8550264835357666, 0.009036144241690636]\n",
      "weights [0.9999990000010001, 10, 10, 1.0730677381468847, 10, 10, 10, 10, 6.897763995968972, 1.0091175223714435]\n",
      "Episode: 3, Step: 58, Epsilon: 0.2960\n",
      "Episode: 3, Step: 58, Action: [9.4030818e-11 4.5320522e-08 3.2083075e-10 1.0000000e+00 9.1805834e-11\n",
      " 9.4747710e-11 1.4943483e-10 1.0927340e-10 1.9564850e-09 4.7425480e-10], Действие: агент\n",
      "loss =  tensor(0.0606, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0599, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0609, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0560, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0581, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0572, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0567, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0566, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0540, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0528, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0535, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0522, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0512, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0514, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0511, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0529, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4151\n",
      "Reward: 13.5113\n",
      "Episode: 3, Step: 59, State: [0.0, 0.9226190447807312, 0.7863501310348511, 0.0, 0.8982880115509033, 0.9900497794151306, 0.772588849067688, 0.7274569272994995, 0.7957671880722046, 0.0060240961611270905]\n",
      "weights [0.9999990000010001, 10, 4.680533268334713, 0.9999990000010001, 9.831586066320924, 10, 4.3973024128233344, 3.6691313448555647, 4.896348898161578, 1.0060595936765382]\n",
      "Episode: 3, Step: 59, Epsilon: 0.2947\n",
      "Episode: 3, Step: 59, Action: [2.3756612e-09 1.5719612e-06 6.8500290e-09 9.9999833e-01 2.2805020e-09\n",
      " 2.2257376e-09 3.5649297e-09 2.7115228e-09 3.0879637e-08 9.7157091e-09], Действие: агент\n",
      "loss =  tensor(0.0528, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0551, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0530, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0544, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0518, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0509, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0522, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0507, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0493, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0486, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0490, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0470, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0479, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0494, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0472, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0457, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4466\n",
      "Reward: 11.0007\n",
      "Episode: 3, Step: 60, State: [0.0, 0.817460298538208, 0.7814045548439026, 0.0, 0.8811681866645813, 0.9781094789505005, 0.6263959407806396, 0.695035457611084, 0.7947089672088623, 0.00803212821483612]\n",
      "weights [0.9999990000010001, 5.478230290515851, 4.574639808464911, 0.9999990000010001, 8.415184088736416, 10, 2.676623282590119, 3.279058978816438, 4.871109640272262, 1.0080961494289464]\n",
      "Episode: 3, Step: 60, Epsilon: 0.2935\n",
      "Episode: 3, Step: 60, Action: [6.0387517e-09 4.3530508e-06 1.6417284e-08 9.9999559e-01 5.8603318e-09\n",
      " 5.5694227e-09 8.8885805e-09 6.9389308e-09 6.6388559e-08 2.3348846e-08], Действие: агент\n",
      "loss =  tensor(0.0475, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0473, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0465, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0474, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0473, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0474, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0450, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0464, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0455, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0444, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0432, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0447, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0434, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0439, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0438, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0424, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4263\n",
      "Reward: 8.1280\n",
      "accuracy =  0.3174\n",
      "--------------------------------------\n",
      "Episode: 3, Step: 60, Test Accuracy: 0.3174\n",
      "--------------------------------------\n",
      "Episode: 3, Step: 61, State: [0.0, 0.7569444179534912, 0.9149357080459595, 0.0, 0.9436052441596985, 0.9830845594406128, 0.641624391078949, 0.7254306077957153, 0.8148148059844971, 0.0060240961611270905]\n",
      "weights [0.9999990000010001, 4.114268338590602, 10, 0.9999990000010001, 10, 10, 2.790360685120206, 3.6420532890377504, 5.399970582668191, 1.0060595936765382]\n",
      "Episode: 3, Step: 61, Epsilon: 0.2923\n",
      "Episode: 3, Step: 61, Action: [2.5248252e-09 1.4599927e-06 7.0740414e-09 9.9999845e-01 2.4946869e-09\n",
      " 2.4008471e-09 3.8037400e-09 2.9609886e-09 2.9954133e-08 1.0241108e-08], Действие: агент\n",
      "loss =  tensor(0.0450, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0452, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0440, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0429, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0419, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0437, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0428, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0439, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0414, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0430, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0412, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0408, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0407, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0405, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0413, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0405, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4239\n",
      "Reward: 8.2120\n",
      "Episode: 3, Step: 62, State: [0.0, 0.721230149269104, 0.9525222778320312, 0.0, 0.9546827673912048, 0.9830845594406128, 0.6477157473564148, 0.7345491647720337, 0.811640202999115, 0.005020080134272575]\n",
      "weights [0.9999990000010001, 3.587175622480427, 10, 0.9999990000010001, 10, 10, 2.8386087481547864, 3.767161749479766, 5.308960335283045, 1.0050443983739406]\n",
      "Episode: 3, Step: 62, Epsilon: 0.2911\n",
      "Episode: 3, Step: 62, Action: [0.09342996 0.10419721 0.02342508 0.21186351 0.12913144 0.02678295\n",
      " 0.08171899 0.05316211 0.05842809 0.21786066], Действие: случайное\n",
      "loss =  tensor(0.9278, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8970, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8133, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9122, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8600, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9482, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8653, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8717, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6294, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7188, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6682, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6535, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6259, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5318, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5801, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5603, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3417\n",
      "Reward: 11.4836\n",
      "Episode: 3, Step: 63, State: [1.0, 1.0, 1.0, 0.4221789836883545, 0.5377643704414368, 0.9711442589759827, 0.08121827244758606, 0.6079027652740479, 0.803174614906311, 0.13955822587013245]\n",
      "weights [10, 10, 10, 1.7306367216382679, 2.163394106077231, 10, 1.0883966034754966, 2.5503812856972603, 5.080619651293205, 1.1621923387191684]\n",
      "Episode: 3, Step: 63, Epsilon: 0.2899\n",
      "Episode: 3, Step: 63, Action: [4.7816218e-10 3.9178799e-06 1.4917944e-09 9.9999607e-01 4.8791871e-10\n",
      " 4.0744902e-10 6.3148115e-10 5.6142818e-10 6.8489423e-09 2.4621298e-09], Действие: агент\n",
      "loss =  tensor(0.0487, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0527, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0507, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0514, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0542, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0550, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0527, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0524, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0501, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0519, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0505, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0500, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0483, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0497, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0466, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0464, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.43\n",
      "Reward: 16.9993\n",
      "Episode: 3, Step: 64, State: [0.0, 0.9583333134651184, 0.9416419267654419, 0.0, 0.861027181148529, 0.9741293787956238, 0.5837563276290894, 0.655521810054779, 0.7587301731109619, 0.009036144241690636]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 7.195599921369043, 10, 2.4024331514059885, 2.902932975890416, 4.144719910376509, 1.0091175223714435]\n",
      "Episode: 3, Step: 64, Epsilon: 0.2887\n",
      "Episode: 3, Step: 64, Action: [3.5986418e-09 2.1842786e-06 1.0123720e-08 9.9999774e-01 3.4060859e-09\n",
      " 3.3310701e-09 5.3098628e-09 3.9847015e-09 3.9838977e-08 1.4677090e-08], Действие: агент\n",
      "loss =  tensor(0.0491, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0484, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0493, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0492, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0485, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0483, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0474, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0502, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0442, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0459, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0446, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0432, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0441, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0424, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0436, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0420, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3604\n",
      "Reward: 5.0196\n",
      "Episode: 3, Step: 65, State: [0.0, 0.9771825671195984, 0.9980217814445496, 0.0, 0.9899294972419739, 0.998009979724884, 0.8649746179580688, 0.802431583404541, 0.8126984238624573, 0.00401606410741806]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 7.405960115923565, 5.061512137010503, 5.338954864484435, 1.0040312498339343]\n",
      "Episode: 3, Step: 65, Epsilon: 0.2875\n",
      "Episode: 3, Step: 65, Action: [3.1547256e-10 1.4173831e-07 9.8823949e-10 9.9999988e-01 3.0455002e-10\n",
      " 3.0776051e-10 4.8958926e-10 3.5997322e-10 4.9533040e-09 1.4432571e-09], Действие: агент\n",
      "loss =  tensor(0.0455, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0458, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0440, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0465, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0451, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0427, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0433, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0463, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0421, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0398, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0425, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0413, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0405, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0395, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0416, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0396, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3892\n",
      "Reward: 9.2325\n",
      "Episode: 3, Step: 66, State: [0.0, 0.788690447807312, 0.9812067151069641, 0.0, 0.9536757469177246, 0.9880596995353699, 0.7837563157081604, 0.8145896792411804, 0.8486772775650024, 0.0030120480805635452]\n",
      "weights [0.9999990000010001, 4.732371335096077, 10, 0.9999990000010001, 10, 10, 4.6243911302366145, 5.393413929135351, 6.608349199376581, 1.0030201418729532]\n",
      "Episode: 3, Step: 66, Epsilon: 0.2863\n",
      "Episode: 3, Step: 66, Action: [6.0985933e-10 2.6758633e-07 1.7766895e-09 9.9999976e-01 6.0195920e-10\n",
      " 5.8674660e-10 9.2542668e-10 7.1172607e-10 8.0341644e-09 2.5754219e-09], Действие: агент\n",
      "loss =  tensor(0.0416, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0406, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0421, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0399, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0391, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0390, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0387, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0402, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0382, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0380, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0364, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0369, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0366, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0374, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0366, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0373, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3816\n",
      "Reward: 7.1433\n",
      "Episode: 3, Step: 67, State: [0.0, 0.7232142686843872, 0.9881305694580078, 0.0, 0.9738166928291321, 0.993034839630127, 0.8335025310516357, 0.8449848294258118, 0.882539689540863, 0.00200803205370903]\n",
      "weights [0.9999990000010001, 3.61288995049306, 10, 0.9999990000010001, 10, 10, 6.006061234774041, 6.450939900630664, 8.513441541654561, 1.0020110683323142]\n",
      "Episode: 3, Step: 67, Epsilon: 0.2852\n",
      "Episode: 3, Step: 67, Action: [0.05758402 0.01977345 0.23209036 0.04739349 0.19160972 0.11192256\n",
      " 0.03945673 0.23060623 0.06196381 0.00759962], Действие: случайное\n",
      "loss =  tensor(1.8040, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6183, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6220, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6997, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4902, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5454, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4845, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3017, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1890, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0532, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0398, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9798, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9768, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9245, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8616, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9539, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2258\n",
      "Reward: 8.1211\n",
      "Episode: 3, Step: 68, State: [1.0, 1.0, 1.0, 0.34143969416618347, 1.0, 1.0, 0.9908629655838013, 0.06889564543962479, 0.9015873074531555, 0.43775099515914917]\n",
      "weights [10, 10, 10, 1.518461517768466, 10, 10, 10, 1.0739923200980341, 10, 1.778568237243604]\n",
      "Episode: 3, Step: 68, Epsilon: 0.2840\n",
      "Episode: 3, Step: 68, Action: [1.67817340e-11 1.09958904e-07 6.15395443e-11 9.99999881e-01\n",
      " 1.87850829e-11 1.67873684e-11 2.67238454e-11 2.28557191e-11\n",
      " 4.39722120e-10 9.79268125e-11], Действие: агент\n",
      "loss =  tensor(0.1016, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0953, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0867, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0895, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0874, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0782, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0805, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0758, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0664, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0638, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0602, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0604, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0557, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0556, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0555, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0529, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3435\n",
      "Reward: 18.6191\n",
      "Episode: 3, Step: 69, State: [0.0, 0.5089285969734192, 0.9881305694580078, 0.08365758508443832, 0.9234642386436462, 0.993034839630127, 0.9756345152854919, 0.17426544427871704, 0.9767195582389832, 1.0]\n",
      "weights [0.9999990000010001, 2.036359595523579, 10, 1.0912939229144207, 10, 10, 10, 1.211041468508034, 10, 10]\n",
      "Episode: 3, Step: 69, Epsilon: 0.2828\n",
      "Episode: 3, Step: 69, Action: [1.9192307e-10 3.1831678e-07 6.2630873e-10 9.9999964e-01 2.2345956e-10\n",
      " 1.9715574e-10 3.5423009e-10 2.7360461e-10 3.2042839e-09 8.9961155e-10], Действие: агент\n",
      "loss =  tensor(0.0595, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0596, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0583, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0596, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0585, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0551, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0581, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0588, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0523, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0515, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0484, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0492, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0486, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0495, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0479, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0488, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3493\n",
      "Reward: 8.7265\n",
      "Episode: 3, Step: 70, State: [0.0, 0.966269850730896, 0.9040554165840149, 0.015564202331006527, 0.9536757469177246, 0.9920397996902466, 0.8771573901176453, 0.12664639949798584, 0.8550264835357666, 0.8654618263244629]\n",
      "weights [0.9999990000010001, 10, 10, 1.0158092448066325, 10, 10, 8.140431569519027, 1.1450102849692307, 6.897763995968972, 7.432779410490963]\n",
      "Episode: 3, Step: 70, Epsilon: 0.2817\n",
      "Episode: 3, Step: 70, Action: [0.1332831  0.17932025 0.15917428 0.22377353 0.04080825 0.06902151\n",
      " 0.00834177 0.12420482 0.02894475 0.03312775], Действие: случайное\n",
      "loss =  tensor(1.2051, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3417, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1556, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1460, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1062, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2517, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8852, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9540, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9075, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7551, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7230, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8062, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6630, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7812, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6822, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6670, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1904\n",
      "Reward: 8.9538\n",
      "accuracy =  0.1221\n",
      "--------------------------------------\n",
      "Episode: 3, Step: 70, Test Accuracy: 0.1221\n",
      "--------------------------------------\n",
      "Episode: 3, Step: 71, State: [1.0, 1.0, 0.6726014018058777, 0.0, 0.7764350175857544, 0.9870646595954895, 0.992893397808075, 0.996960461139679, 0.9925925731658936, 0.7058233022689819]\n",
      "weights [10, 10, 3.054371494393461, 0.9999990000010001, 4.472952410743327, 10, 10, 10, 10, 3.3993059559339946]\n",
      "Episode: 3, Step: 71, Epsilon: 0.2805\n",
      "Episode: 3, Step: 71, Action: [2.1596965e-12 1.7051434e-08 8.6253261e-12 1.0000000e+00 2.4206466e-12\n",
      " 1.8962295e-12 3.7078105e-12 2.9785709e-12 7.7674665e-11 1.3563281e-11], Действие: агент\n",
      "loss =  tensor(0.0626, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0693, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0671, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0693, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0704, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0720, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0726, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0684, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0639, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0651, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0604, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0614, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0600, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0612, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0586, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0568, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.39\n",
      "Reward: 22.8956\n",
      "Episode: 3, Step: 72, State: [0.0, 0.9523809552192688, 0.7121661901473999, 0.008754863403737545, 0.9053373336791992, 0.972139298915863, 0.8903553485870361, 0.5481256246566772, 0.7904762029647827, 0.37148594856262207]\n",
      "weights [0.9999990000010001, 10, 3.4742149516665446, 1.0088311702619053, 10, 10, 9.12028874025884, 2.2129995449303403, 4.7727047783843854, 1.5910517937685935]\n",
      "Episode: 3, Step: 72, Epsilon: 0.2793\n",
      "Episode: 3, Step: 72, Action: [1.1954789e-09 1.2189431e-06 3.6325609e-09 9.9999881e-01 1.1900757e-09\n",
      " 1.1182499e-09 1.9223918e-09 1.4325459e-09 1.6567636e-08 5.0518896e-09], Действие: агент\n",
      "loss =  tensor(0.0605, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0665, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0587, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0587, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0588, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0567, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0617, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0560, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0544, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0526, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0536, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0513, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0498, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0492, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0504, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0502, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4499\n",
      "Reward: 12.4689\n",
      "Episode: 3, Step: 73, State: [0.0009596928721293807, 0.733134925365448, 0.9960435032844543, 0.0, 0.9808660745620728, 0.937313437461853, 0.7319796681404114, 0.14792299270629883, 0.6687830686569214, 0.34036144614219666]\n",
      "weights [1.000959612846125, 3.747197920790067, 10, 0.9999990000010001, 10, 10, 3.7310463053884138, 1.1736014677530713, 3.019160212567691, 1.5159794377878788]\n",
      "Episode: 3, Step: 73, Epsilon: 0.2782\n",
      "Episode: 3, Step: 73, Action: [8.5729095e-09 8.8334391e-06 2.3401483e-08 9.9999106e-01 8.8659702e-09\n",
      " 8.4762002e-09 1.3672895e-08 1.0438738e-08 8.2552845e-08 3.2821408e-08], Действие: агент\n",
      "loss =  tensor(0.0533, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0564, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0496, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0512, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0504, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0495, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0468, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0484, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0469, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0466, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0464, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0459, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0438, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0430, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0440, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0445, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.5013\n",
      "Reward: 10.7702\n",
      "Episode: 3, Step: 74, State: [0.0019193857442587614, 0.4593254029750824, 0.9564787149429321, 0.0, 0.9284995198249817, 0.8716418147087097, 0.6527918577194214, 0.157041534781456, 0.6634920835494995, 0.3333333432674408]\n",
      "weights [1.001922073021743, 1.8495378846438189, 10, 0.9999990000010001, 10, 7.790638416180834, 2.8801084943549764, 1.1862966622490465, 2.9716894593700824, 1.49999777235505]\n",
      "Episode: 3, Step: 74, Epsilon: 0.2771\n",
      "Episode: 3, Step: 74, Action: [3.3793050e-08 3.7774073e-05 8.2796255e-08 9.9996173e-01 3.6281488e-08\n",
      " 3.2993430e-08 5.2283227e-08 4.2527859e-08 2.4978925e-07 1.1456194e-07], Действие: агент\n",
      "loss =  tensor(0.0463, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0461, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0467, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0442, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0441, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0440, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0436, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0434, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0437, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0422, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0391, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0409, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0422, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0393, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0399, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0400, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.495\n",
      "Reward: 9.3759\n",
      "Episode: 3, Step: 75, State: [0.0009596928721293807, 0.6220238208770752, 0.937685489654541, 0.0, 0.9063444137573242, 0.874626874923706, 0.6497461795806885, 0.16514691710472107, 0.6380952596664429, 0.2901606559753418]\n",
      "weights [1.000959612846125, 2.6456623712586165, 10, 0.9999990000010001, 10, 7.976127445686817, 2.8550642038354783, 1.197814109660929, 2.7631504244125322, 1.4087674903488752]\n",
      "Episode: 3, Step: 75, Epsilon: 0.2759\n",
      "Episode: 3, Step: 75, Action: [3.3219703e-08 3.7072037e-05 8.3113711e-08 9.9996245e-01 3.4443616e-08\n",
      " 3.1946101e-08 5.0866703e-08 4.0262059e-08 2.5224219e-07 1.1463361e-07], Действие: агент\n",
      "loss =  tensor(0.0420, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0402, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0420, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0402, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0412, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0402, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0419, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0380, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0385, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0381, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0383, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0382, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0382, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0377, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0380, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0378, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4773\n",
      "Reward: 8.5161\n",
      "Episode: 3, Step: 76, State: [0.0, 0.6934523582458496, 0.9554896354675293, 0.0, 0.9446122646331787, 0.8995025157928467, 0.686294436454773, 0.18743667006492615, 0.6465608477592468, 0.24899598956108093]\n",
      "weights [0.9999990000010001, 3.262125039203378, 10, 0.9999990000010001, 10, 9.950398833267394, 3.1876923093317115, 1.2306717919551093, 2.829333321808975, 1.3315490390877123]\n",
      "Episode: 3, Step: 76, Epsilon: 0.2748\n",
      "Episode: 3, Step: 76, Action: [1.9183366e-08 1.8784711e-05 4.9273186e-08 9.9998093e-01 1.9628475e-08\n",
      " 1.8557373e-08 2.9435386e-08 2.2948889e-08 1.5710218e-07 6.8329243e-08], Действие: агент\n",
      "loss =  tensor(0.0382, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0372, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0384, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0379, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0365, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0372, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0355, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0363, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0355, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0347, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0354, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0344, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0344, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0362, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0339, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0347, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4955\n",
      "Reward: 10.0262\n",
      "Episode: 3, Step: 77, State: [0.0, 0.5952380895614624, 0.9327398538589478, 0.0, 0.9244713187217712, 0.8786069750785828, 0.641624391078949, 0.17831814289093018, 0.6708994507789612, 0.26004016399383545]\n",
      "weights [0.9999990000010001, 2.4705820968540744, 10, 0.9999990000010001, 10, 8.237637730912509, 2.790360685120206, 1.217014559021353, 3.0385757902596713, 1.3514228744826018]\n",
      "Episode: 3, Step: 77, Epsilon: 0.2737\n",
      "Episode: 3, Step: 77, Action: [0.32031849 0.12346963 0.12769074 0.08523849 0.10668587 0.16361907\n",
      " 0.0284063  0.02076793 0.00041792 0.02338558], Действие: случайное\n",
      "loss =  tensor(2.0027, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9101, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8410, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4433, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5736, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4947, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6833, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5741, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2364, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1512, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0166, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9773, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8279, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8127, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0260, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9625, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1444\n",
      "Reward: 12.4659\n",
      "Episode: 3, Step: 78, State: [1.0, 1.0, 1.0, 0.8511673212051392, 0.06747230887413025, 0.6368159055709839, 1.0, 1.0, 1.0, 1.0]\n",
      "weights [10, 10, 10, 6.718909376541793, 1.0723530648613826, 2.7534169637995656, 10, 10, 10, 10]\n",
      "Episode: 3, Step: 78, Epsilon: 0.2726\n",
      "Episode: 3, Step: 78, Action: [5.2179290e-13 1.1013560e-08 2.1935476e-12 1.0000000e+00 5.9955448e-13\n",
      " 4.6145835e-13 7.5391700e-13 6.6722550e-13 1.5505064e-11 3.5699315e-12], Действие: агент\n",
      "loss =  tensor(0.0770, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0764, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0754, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0785, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0826, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0834, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0902, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0954, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0795, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0755, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0744, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0708, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0683, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0672, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0643, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0663, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4718\n",
      "Reward: 33.6835\n",
      "Episode: 3, Step: 79, State: [0.005758157465606928, 0.2777777910232544, 0.727992057800293, 0.021400777623057365, 0.42396777868270874, 0.387064665555954, 0.8994923830032349, 0.7031408548355103, 0.9788359999656677, 0.926706850528717]\n",
      "weights [1.0057904942528242, 1.3846134928519007, 3.6763497255388287, 1.0218677424485751, 1.7360109851184762, 1.6314908152851368, 9.949395682483472, 3.368589607897354, 10, 10]\n",
      "Episode: 3, Step: 79, Epsilon: 0.2715\n",
      "Episode: 3, Step: 79, Action: [6.0930754e-09 1.3249431e-05 1.5144584e-08 9.9998665e-01 6.9654420e-09\n",
      " 5.2032907e-09 9.7218606e-09 8.1997396e-09 5.0863765e-08 2.0786681e-08], Действие: агент\n",
      "loss =  tensor(0.0809, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0705, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0854, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0779, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0701, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0690, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0682, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0763, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0631, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0605, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0590, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0559, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0563, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0551, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0548, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0527, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4282\n",
      "Reward: 17.2184\n",
      "Episode: 3, Step: 80, State: [0.0, 0.9970238208770752, 0.9980217814445496, 0.0, 0.9798589944839478, 0.7940298318862915, 0.7573603987693787, 0.20162107050418854, 0.7333333492279053, 0.2961847484111786]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 4.855048447596023, 4.121321802403281, 1.2525364967923411, 3.7499861610684895, 1.4208253897839986]\n",
      "Episode: 3, Step: 80, Epsilon: 0.2704\n",
      "Episode: 3, Step: 80, Action: [5.0863589e-09 4.8194788e-06 1.4425712e-08 9.9999511e-01 4.9594342e-09\n",
      " 4.8231685e-09 8.1363227e-09 5.9362999e-09 5.2010748e-08 1.9926835e-08], Действие: агент\n",
      "loss =  tensor(0.0638, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0586, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0614, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0576, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0578, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0582, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0559, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0547, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0530, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0493, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0506, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0504, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0477, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0476, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0451, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0476, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4493\n",
      "Reward: 8.7541\n",
      "accuracy =  0.2981\n",
      "--------------------------------------\n",
      "Episode: 3, Step: 80, Test Accuracy: 0.2981\n",
      "--------------------------------------\n",
      "Episode: 3, Step: 81, State: [0.0, 0.983134925365448, 0.9821958541870117, 0.0, 0.9546827673912048, 0.6517412662506104, 0.6436548233032227, 0.29685917496681213, 0.7661375403404236, 0.2700803279876709]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 2.8714201014108847, 2.806259938775551, 1.422188190771898, 4.2759993436155055, 1.370011890803264]\n",
      "Episode: 3, Step: 81, Epsilon: 0.2693\n",
      "Episode: 3, Step: 81, Action: [9.4738217e-09 9.5290370e-06 2.6261642e-08 9.9999034e-01 9.1501393e-09\n",
      " 8.6933190e-09 1.5118637e-08 1.1124737e-08 8.9408061e-08 3.5987682e-08], Действие: агент\n",
      "loss =  tensor(0.0506, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0542, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0505, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0498, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0497, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0496, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0485, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0475, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0489, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0421, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0445, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0419, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0451, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0435, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0436, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0420, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4415\n",
      "Reward: 7.7778\n",
      "Episode: 3, Step: 82, State: [0.0, 1.0, 0.9762611389160156, 0.0, 0.9264854192733765, 0.7164179086685181, 0.6538071036338806, 0.34954407811164856, 0.7492063641548157, 0.25401607155799866]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 3.526303332489927, 2.888554681340899, 1.5373808262304054, 3.987326110983094, 1.3405096562587562]\n",
      "Episode: 3, Step: 82, Epsilon: 0.2682\n",
      "Episode: 3, Step: 82, Action: [6.8465091e-09 6.3564025e-06 1.9075463e-08 9.9999356e-01 6.5848642e-09\n",
      " 6.2761587e-09 1.0769941e-08 7.9122886e-09 6.5728713e-08 2.6385841e-08], Действие: агент\n",
      "loss =  tensor(0.0445, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0458, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0455, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0438, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0442, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0441, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0427, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0436, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0425, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0426, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0396, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0412, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0390, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0400, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0383, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0383, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4362\n",
      "Reward: 7.7317\n",
      "Episode: 3, Step: 83, State: [0.0, 1.0, 0.9831849932670593, 0.0, 0.9284995198249817, 0.7671641707420349, 0.6720812320709229, 0.3465045690536499, 0.732275128364563, 0.24799196422100067]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 4.294853194775634, 3.0495264323811098, 1.5302302394396652, 3.735163859552963, 1.329771255958526]\n",
      "Episode: 3, Step: 83, Epsilon: 0.2671\n",
      "Episode: 3, Step: 83, Action: [5.6130580e-09 4.9554983e-06 1.5681048e-08 9.9999499e-01 5.4063922e-09\n",
      " 5.1822080e-09 8.7833438e-09 6.4488943e-09 5.4369522e-08 2.1790962e-08], Действие: агент\n",
      "loss =  tensor(0.0415, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0390, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0410, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0391, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0388, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0383, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0383, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0371, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0374, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0363, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0362, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0367, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0360, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0351, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0358, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0358, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4519\n",
      "Reward: 8.7293\n",
      "Episode: 3, Step: 84, State: [0.0, 1.0, 0.9663699269294739, 0.0, 0.9093655347824097, 0.6865671873092651, 0.6253806948661804, 0.3546099364757538, 0.7291005253791809, 0.24899598956108093]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 3.1904662468139646, 2.6693694556753567, 1.5494481664176802, 3.6913925728616963, 1.3315490390877123]\n",
      "Episode: 3, Step: 84, Epsilon: 0.2660\n",
      "Episode: 3, Step: 84, Action: [9.6943813e-09 9.4674142e-06 2.6637782e-08 9.9999034e-01 9.2991979e-09\n",
      " 8.8117620e-09 1.5160392e-08 1.1164508e-08 8.8206789e-08 3.6673683e-08], Действие: агент\n",
      "loss =  tensor(0.0362, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0367, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0356, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0344, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0359, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0352, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0359, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0361, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0332, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0346, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0342, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0329, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0345, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0336, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0324, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0321, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4553\n",
      "Reward: 8.4898\n",
      "Episode: 3, Step: 85, State: [0.0, 1.0, 0.9594460725784302, 0.0, 0.8972809910774231, 0.6796019673347473, 0.6203045845031738, 0.35764944553375244, 0.7216930985450745, 0.25]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 9.735201646582112, 3.1211080498010824, 2.6336830140772265, 1.5567799175498767, 3.5931426839563128, 1.333331555557926]\n",
      "Episode: 3, Step: 85, Epsilon: 0.2649\n",
      "Episode: 3, Step: 85, Action: [0.08955542 0.02644352 0.14734278 0.11641611 0.15315348 0.03960929\n",
      " 0.32755441 0.01544896 0.01504434 0.06943171], Действие: случайное\n",
      "loss =  tensor(1.7714, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6971, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5355, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3751, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2241, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4119, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1979, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0023, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9933, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8606, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8583, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8788, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8133, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9728, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8714, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8310, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2313\n",
      "Reward: 3.2884\n",
      "Episode: 3, Step: 86, State: [1.0, 1.0, 1.0, 0.10992217808961868, 1.0, 1.0, 0.6944162249565125, 0.9402229189872742, 0.9523809552192688, 0.0030120480805635452]\n",
      "weights [10, 10, 10, 1.123496004380482, 10, 10, 3.272414340202946, 10, 10, 1.0030201418729532]\n",
      "Episode: 3, Step: 86, Epsilon: 0.2638\n",
      "Episode: 3, Step: 86, Action: [6.2271100e-12 1.7175994e-08 2.1151154e-11 1.0000000e+00 6.4130754e-12\n",
      " 5.5449963e-12 9.1828203e-12 7.6727383e-12 1.3513708e-10 3.3317033e-11], Действие: агент\n",
      "loss =  tensor(0.1246, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1062, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0939, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0980, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0694, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0740, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0782, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0703, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0593, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0591, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0560, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0561, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0547, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0530, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0499, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0523, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2445\n",
      "Reward: 13.1285\n",
      "Episode: 3, Step: 87, State: [0.0, 1.0, 1.0, 0.7130350470542908, 1.0, 1.0, 0.9461929202079773, 0.9939209818840027, 0.8328042030334473, 0.10542168468236923]\n",
      "weights [0.9999990000010001, 10, 10, 3.484733954446467, 10, 10, 10, 10, 5.980975820966518, 1.1178438656889114]\n",
      "Episode: 3, Step: 87, Epsilon: 0.2628\n",
      "Episode: 3, Step: 87, Action: [8.0679526e-12 6.5363297e-09 3.1018601e-11 1.0000000e+00 8.0817063e-12\n",
      " 8.4416380e-12 1.2152227e-11 9.6261931e-12 1.7325158e-10 4.4452272e-11], Действие: агент\n",
      "loss =  tensor(0.0578, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0592, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0604, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0515, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0536, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0524, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0494, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0516, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0452, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0451, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0453, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0440, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0425, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0431, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0409, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0414, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2948\n",
      "Reward: 8.6086\n",
      "Episode: 3, Step: 88, State: [0.0, 1.0, 1.0, 0.6877431869506836, 1.0, 1.0, 0.8081218004226685, 0.826747715473175, 0.6962962746620178, 0.05823293328285217]\n",
      "weights [0.9999990000010001, 10, 10, 3.202481917856977, 10, 10, 5.2116123175559625, 5.7718963466182895, 3.292671850551998, 1.0618325629640846]\n",
      "Episode: 3, Step: 88, Epsilon: 0.2617\n",
      "Episode: 3, Step: 88, Action: [5.3328380e-11 5.3587652e-08 1.9382763e-10 1.0000000e+00 5.3010554e-11\n",
      " 5.5776592e-11 7.9168748e-11 6.2751394e-11 9.2134789e-10 2.7336686e-10], Действие: агент\n",
      "loss =  tensor(0.0455, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0435, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0452, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0425, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0423, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0447, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0425, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0421, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0387, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0379, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0404, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0400, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0378, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0373, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0379, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0357, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4314\n",
      "Reward: 12.8297\n",
      "Episode: 3, Step: 89, State: [0.0, 0.9990079402923584, 0.9159248471260071, 0.0, 0.9305136203765869, 0.9472636580467224, 0.43350252509117126, 0.6818642616271973, 0.770370364189148, 0.04919678717851639]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 1.7652298184226147, 3.143302484066359, 4.354819627916308, 1.0517412381172873]\n",
      "Episode: 3, Step: 89, Epsilon: 0.2607\n",
      "Episode: 3, Step: 89, Action: [3.1845928e-09 1.9040164e-06 8.7839078e-09 9.9999809e-01 2.9739260e-09\n",
      " 2.8241871e-09 4.7115618e-09 3.5345360e-09 3.0277690e-08 1.2518118e-08], Действие: агент\n",
      "loss =  tensor(0.0393, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0381, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0399, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0381, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0375, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0373, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0382, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0360, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0354, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0361, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0361, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0337, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0332, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0330, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0347, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0322, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4471\n",
      "Reward: 9.4921\n",
      "Episode: 3, Step: 90, State: [0.0, 0.995039701461792, 0.8090999126434326, 0.0, 0.9164149165153503, 0.9184079766273499, 0.3888324797153473, 0.6869301199913025, 0.8126984238624573, 0.046184737235307693]\n",
      "weights [0.9999990000010001, 10, 5.238314845908592, 0.9999990000010001, 10, 10, 1.6362099270660215, 3.1941648484592973, 5.338954864484435, 1.0484199515548638]\n",
      "Episode: 3, Step: 90, Epsilon: 0.2596\n",
      "Episode: 3, Step: 90, Action: [5.6636305e-09 3.8737567e-06 1.5169849e-08 9.9999607e-01 5.2472617e-09\n",
      " 4.8815170e-09 8.2884064e-09 6.3052585e-09 5.0732766e-08 2.1232834e-08], Действие: агент\n",
      "loss =  tensor(0.0356, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0343, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0337, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0330, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0348, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0342, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0325, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0336, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0331, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0317, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0324, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0311, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0308, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0314, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0310, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0321, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4497\n",
      "Reward: 8.8578\n",
      "accuracy =  0.3222\n",
      "--------------------------------------\n",
      "Episode: 3, Step: 90, Test Accuracy: 0.3222\n",
      "--------------------------------------\n",
      "Episode: 3, Step: 91, State: [0.0, 0.9900793433189392, 0.8199802041053772, 0.0, 0.9204431176185608, 0.8995025157928467, 0.3573603928089142, 0.6778115630149841, 0.8222222328186035, 0.0602409653365612]\n",
      "weights [0.9999990000010001, 10, 5.554913781102052, 0.9999990000010001, 10, 9.950398833267394, 1.556079694949397, 3.10376407543897, 5.624968694825353, 1.064101433466614]\n",
      "Episode: 3, Step: 91, Epsilon: 0.2586\n",
      "Episode: 3, Step: 91, Action: [0.02649843 0.06406774 0.17389643 0.10821886 0.09483983 0.00600549\n",
      " 0.30343221 0.00179414 0.08399283 0.13725404], Действие: случайное\n",
      "loss =  tensor(1.5301, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3072, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1578, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1695, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0195, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2014, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1698, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0464, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8614, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8115, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6799, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7395, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7969, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7612, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7445, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6821, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3107\n",
      "Reward: 5.4064\n",
      "Episode: 3, Step: 92, State: [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2954314649105072, 0.8885511755943298, 0.652910053730011, 0.04919678717851639]\n",
      "weights [10, 10, 10, 0.9999990000010001, 10, 10, 1.4193063284704501, 8.972647604719992, 2.881089267082575, 1.0517412381172873]\n",
      "Episode: 3, Step: 92, Epsilon: 0.2575\n",
      "Episode: 3, Step: 92, Action: [1.00925525e-10 4.20810096e-07 3.25399707e-10 9.99999523e-01\n",
      " 1.04861703e-10 8.83414869e-11 1.49581333e-10 1.22205635e-10\n",
      " 1.69153014e-09 5.37455136e-10], Действие: агент\n",
      "loss =  tensor(0.0623, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0626, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0566, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0646, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0611, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0614, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0624, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0579, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0532, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0490, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0497, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0468, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0446, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0460, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0448, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0461, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3757\n",
      "Reward: 13.7178\n",
      "Episode: 3, Step: 93, State: [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6649746298789978, 0.9959473013877869, 0.5873016119003296, 0.03313253074884415]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 2.9848396699006945, 10, 2.4230711962153224, 1.0342668437357407]\n",
      "Episode: 3, Step: 93, Epsilon: 0.2565\n",
      "Episode: 3, Step: 93, Action: [3.8218220e-10 1.7779422e-07 1.1854009e-09 9.9999976e-01 3.6969738e-10\n",
      " 3.6229794e-10 5.8536725e-10 4.2701098e-10 4.9161062e-09 1.7616935e-09], Действие: агент\n",
      "loss =  tensor(0.0492, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0496, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0476, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0439, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0451, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0472, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0466, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0417, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0418, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0388, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0401, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0376, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0402, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0370, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0379, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0362, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3717\n",
      "Reward: 5.0168\n",
      "Episode: 3, Step: 94, State: [0.0, 1.0, 1.0, 0.01653696410357952, 1.0, 1.0, 0.6974619030952454, 0.9888551235198975, 0.5756613612174988, 0.04216867312788963]\n",
      "weights [0.9999990000010001, 10, 10, 1.0168139998007217, 10, 10, 3.3053579197891905, 10, 2.356602844997373, 1.044024065533048]\n",
      "Episode: 3, Step: 94, Epsilon: 0.2555\n",
      "Episode: 3, Step: 94, Action: [3.3745998e-10 1.5803835e-07 1.0521440e-09 9.9999988e-01 3.2737327e-10\n",
      " 3.2169348e-10 5.1699883e-10 3.7748624e-10 4.3783932e-09 1.5608455e-09], Действие: агент\n",
      "loss =  tensor(0.0384, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0394, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0392, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0377, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0382, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0378, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0372, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0371, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0360, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0354, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0339, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0349, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0341, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0342, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0338, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0317, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4233\n",
      "Reward: 9.1611\n",
      "Episode: 3, Step: 95, State: [0.0, 0.942460298538208, 0.8001978397369385, 0.0, 0.964753270149231, 0.9880596995353699, 0.4324873089790344, 0.9483282566070557, 0.7068783044815063, 0.027108434587717056]\n",
      "weights [0.9999990000010001, 10, 5.0049258414301185, 0.9999990000010001, 10, 10, 1.7620720271981194, 10, 3.4115406800252637, 1.0278627214878857]\n",
      "Episode: 3, Step: 95, Epsilon: 0.2544\n",
      "Episode: 3, Step: 95, Action: [1.9939976e-09 1.2596086e-06 5.6501150e-09 9.9999869e-01 1.8981912e-09\n",
      " 1.7652906e-09 2.9560914e-09 2.2493991e-09 2.0695230e-08 8.1062703e-09], Действие: агент\n",
      "loss =  tensor(0.0357, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0347, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0349, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0343, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0339, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0342, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0340, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0351, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0339, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0320, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0317, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0317, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0316, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0316, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0300, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0311, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4865\n",
      "Reward: 12.3628\n",
      "Episode: 3, Step: 96, State: [0.0, 0.6805555820465088, 0.578635036945343, 0.0, 0.903323233127594, 0.9562188982963562, 0.3299492299556732, 0.9300912022590637, 0.770370364189148, 0.03514056280255318]\n",
      "weights [0.9999990000010001, 3.130425242617167, 2.373233928888286, 0.9999990000010001, 10, 10, 1.4924219958912215, 10, 4.354819627916308, 1.036419321849925]\n",
      "Episode: 3, Step: 96, Epsilon: 0.2534\n",
      "Episode: 3, Step: 96, Action: [0.05344861 0.003865   0.31029704 0.09091179 0.02223432 0.04948734\n",
      " 0.00721017 0.05421746 0.18262105 0.22570722], Действие: случайное\n",
      "loss =  tensor(1.1586, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0876, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1809, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1155, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0529, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9833, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0002, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0482, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7914, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7803, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7426, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7203, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7680, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5879, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6398, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6705, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2763\n",
      "Reward: 6.7898\n",
      "Episode: 3, Step: 97, State: [1.0, 1.0, 0.9980217814445496, 0.0, 0.9848942756652832, 0.9810945391654968, 0.9015228152275085, 0.7527862191200256, 0.5809524059295654, 0.03413654491305351]\n",
      "weights [10, 10, 10, 0.9999990000010001, 10, 10, 10, 4.0450655759354115, 2.3863580838835077, 1.0353419620457827]\n",
      "Episode: 3, Step: 97, Epsilon: 0.2524\n",
      "Episode: 3, Step: 97, Action: [3.1030553e-11 8.1890519e-08 9.9629374e-11 9.9999988e-01 3.3042815e-11\n",
      " 2.8778268e-11 4.5220459e-11 3.7480571e-11 5.5945493e-10 1.6235853e-10], Действие: агент\n",
      "loss =  tensor(0.0531, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0512, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0484, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0570, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0516, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0518, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0505, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0505, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0458, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0421, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0436, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0416, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0396, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0393, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0400, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0392, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.352\n",
      "Reward: 13.8643\n",
      "Episode: 3, Step: 98, State: [0.0, 1.0, 0.9386745691299438, 0.0019455252913758159, 0.9989929795265198, 1.0, 0.9918781518936157, 0.935157060623169, 0.6222222447395325, 0.03614457696676254]\n",
      "weights [0.9999990000010001, 10, 10, 1.0019483138369072, 10, 10, 10, 10, 2.6470519744037193, 1.037498922145499]\n",
      "Episode: 3, Step: 98, Epsilon: 0.2514\n",
      "Episode: 3, Step: 98, Action: [1.6983934e-10 6.6968653e-08 5.1766591e-10 9.9999988e-01 1.6487191e-10\n",
      " 1.6277650e-10 2.5629740e-10 1.8853974e-10 2.2311051e-09 7.4547868e-10], Действие: агент\n",
      "loss =  tensor(0.0411, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0416, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0418, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0405, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0413, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0393, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0406, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0380, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0377, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0358, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0358, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0350, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0374, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0344, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0352, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0345, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3786\n",
      "Reward: 7.5788\n",
      "Episode: 3, Step: 99, State: [0.0, 1.0, 0.9406528472900391, 0.019455252215266228, 0.9909365773200989, 0.9870646595954895, 0.8781725764274597, 0.8733536005020142, 0.5005291104316711, 0.05923694744706154]\n",
      "weights [0.9999990000010001, 10, 10, 1.0198402290349202, 10, 10, 8.208265121353804, 7.895937887109191, 2.002114675290846, 1.0629657854021035]\n",
      "Episode: 3, Step: 99, Epsilon: 0.2504\n",
      "Episode: 3, Step: 99, Action: [4.7902388e-10 2.3918895e-07 1.4442786e-09 9.9999976e-01 4.6814869e-10\n",
      " 4.6194945e-10 7.2149048e-10 5.2907945e-10 5.8044232e-09 2.1100683e-09], Действие: агент\n",
      "loss =  tensor(0.0360, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0354, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0354, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0338, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0366, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0347, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0344, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0341, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0334, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0328, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0320, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0331, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0314, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0320, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0317, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0304, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4895\n",
      "Reward: 17.2748\n",
      "Episode: 3, Step: 100, State: [0.0, 0.9930555820465088, 0.345202773809433, 0.0, 0.86908358335495, 0.8616915345191956, 0.6791878342628479, 0.8338398933410645, 0.49841269850730896, 0.0632530152797699]\n",
      "weights [0.9999990000010001, 10, 1.527188009988543, 0.9999990000010001, 7.638403091249889, 7.230163145549767, 3.1170790565974396, 6.018255535891519, 1.9936669117363208, 1.0675229798318282]\n",
      "Episode: 3, Step: 100, Epsilon: 0.2494\n",
      "Episode: 3, Step: 100, Action: [0.02950468 0.03983143 0.04431756 0.09402511 0.09956031 0.13087362\n",
      " 0.02590404 0.13391063 0.2943579  0.10771472], Действие: случайное\n",
      "loss =  tensor(1.8173, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8118, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7819, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5663, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5307, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6346, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6882, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5246, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1021, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0460, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9868, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9791, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9226, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9366, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8597, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9088, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3469\n",
      "Reward: 4.4439\n",
      "accuracy =  0.3064\n",
      "--------------------------------------\n",
      "Episode: 3, Step: 100, Test Accuracy: 0.3064\n",
      "--------------------------------------\n",
      "Восстанавливаем лучшее состояние модели...\n",
      "Episode: 4, Step: 1, State: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "weights [np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815)]\n",
      "Episode: 4, Step: 1, Epsilon: 0.3771\n",
      "Episode: 4, Step: 1, Action: [1.0636068e-04 9.9580353e-01 1.3849602e-04 3.2208140e-03 1.1201202e-04\n",
      " 7.8675883e-05 1.1481340e-04 1.1626898e-04 1.3840769e-04 1.7056029e-04], Действие: агент\n",
      "loss =  tensor(3.8831, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.9152, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.8304, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.8482, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.7253, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.7812, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.7203, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.6462, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.0818, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.1370, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.1908, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.1402, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.0676, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(3.0485, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.9464, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.8557, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3666\n",
      "Reward: 4.0179\n",
      "Episode: 4, Step: 2, State: [0.03358925133943558, 0.9474206566810608, 1.0, 0.0009727626456879079, 1.0, 0.9970149397850037, 0.9705584049224854, 0.45187437534332275, 0.852910041809082, 0.1295180767774582]\n",
      "weights [1.0347556322509412, 10, 10, 1.0009727078868775, 10, 10, 10, 1.8243959607442104, 6.798514417874968, 1.1487876135444264]\n",
      "Episode: 4, Step: 2, Epsilon: 0.3755\n",
      "Episode: 4, Step: 2, Action: [1.2430139e-09 8.9765331e-07 4.1670094e-09 9.9999905e-01 1.2676776e-09\n",
      " 1.3309801e-09 2.0722521e-09 1.5060564e-09 3.0934252e-08 6.3395973e-09], Действие: агент\n",
      "loss =  tensor(0.1746, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1831, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1819, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1902, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1864, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1884, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1839, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1897, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1793, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1807, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1838, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1918, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1750, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1772, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1790, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1768, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3797\n",
      "Reward: 6.7289\n",
      "Episode: 4, Step: 3, State: [0.06621880829334259, 0.846230149269104, 1.0, 0.0038910505827516317, 1.0, 0.9990049600601196, 0.9807106852531433, 0.2998986840248108, 0.882539689540863, 0.17369477450847626]\n",
      "weights [1.0709135480216403, 6.50318311465957, 10, 1.00390524217234, 10, 10, 10, 1.4283626509749165, 8.513441541654561, 1.2102050900138812]\n",
      "Episode: 4, Step: 3, Epsilon: 0.3738\n",
      "Episode: 4, Step: 3, Action: [0.27965682 0.0064854  0.03726115 0.06065996 0.17956869 0.07276336\n",
      " 0.0461821  0.06241482 0.20516782 0.04983988], Действие: случайное\n",
      "loss =  tensor(1.3166, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3142, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1843, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1492, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1180, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1948, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1201, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9860, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8855, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8307, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8016, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7487, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8203, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7409, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7583, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6973, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2187\n",
      "Reward: 8.3497\n",
      "Episode: 4, Step: 4, State: [1.0, 1.0, 1.0, 0.0009727626456879079, 0.9798589944839478, 0.9582089781761169, 0.9949238300323486, 0.7527862191200256, 0.28148147463798523, 0.8293172717094421]\n",
      "weights [10, 10, 10, 1.0009727078868775, 10, 10, 10, 4.0450655759354115, 1.391750627091401, 5.858789294183231]\n",
      "Episode: 4, Step: 4, Epsilon: 0.3722\n",
      "Episode: 4, Step: 4, Action: [2.3925551e-11 3.4820144e-07 1.2021102e-10 9.9999964e-01 3.0915111e-11\n",
      " 2.7452972e-11 4.8216493e-11 3.5244398e-11 1.7279354e-09 2.3363664e-10], Действие: агент\n",
      "loss =  tensor(0.2358, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2284, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2343, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2210, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2220, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2195, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2131, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2121, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1912, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1954, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1825, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1837, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1774, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1797, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1693, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1693, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.339\n",
      "Reward: 16.0816\n",
      "Episode: 4, Step: 5, State: [0.0, 0.7867063283920288, 1.0, 0.07003890722990036, 0.9848942756652832, 0.998009979724884, 0.9939086437225342, 0.9908814430236816, 0.04338624328374863, 0.7580321431159973]\n",
      "weights [0.9999990000010001, 4.688349654781663, 10, 1.0753126474448833, 10, 10, 10, 10, 1.0453528894250765, 4.132763252584152]\n",
      "Episode: 4, Step: 5, Epsilon: 0.3706\n",
      "Episode: 4, Step: 5, Action: [4.9499699e-10 1.4706945e-06 2.2986208e-09 9.9999845e-01 6.1370692e-10\n",
      " 6.2144823e-10 1.0141619e-09 6.8651468e-10 2.1521640e-08 3.9508752e-09], Действие: агент\n",
      "loss =  tensor(0.1872, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1917, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1779, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1782, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1793, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1763, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1697, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1650, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1577, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1572, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1529, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1498, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1457, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1433, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1419, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1359, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3624\n",
      "Reward: 7.3017\n",
      "Episode: 4, Step: 6, State: [0.0, 0.983134925365448, 0.9980217814445496, 0.011673151515424252, 0.9859012961387634, 0.9840795993804932, 0.9604060649871826, 0.8530901670455933, 0.1111111119389534, 0.5050200819969177]\n",
      "weights [0.9999990000010001, 10, 10, 1.0118099996203904, 10, 10, 10, 6.806849977566641, 1.1249987354241593, 2.020279900959279]\n",
      "Episode: 4, Step: 6, Epsilon: 0.3690\n",
      "Episode: 4, Step: 6, Action: [1.3412271e-09 2.8022696e-06 5.6946270e-09 9.9999714e-01 1.5281548e-09\n",
      " 1.6020486e-09 2.5612679e-09 1.7076177e-09 4.6710525e-08 9.5045278e-09], Действие: агент\n",
      "loss =  tensor(0.1450, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1465, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1440, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1430, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1437, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1401, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1380, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1538, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1318, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1377, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1247, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1237, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1238, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1277, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1197, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1193, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.403\n",
      "Reward: 9.1853\n",
      "Episode: 4, Step: 7, State: [0.0, 0.9454365372657776, 0.9782393574714661, 0.0, 0.9718025922775269, 0.9562188982963562, 0.896446704864502, 0.6129685640335083, 0.15238095819950104, 0.4718875586986542]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 9.65676989729423, 2.5837627730162067, 1.1797738971294476, 1.8935325666695004]\n",
      "Episode: 4, Step: 7, Epsilon: 0.3674\n",
      "Episode: 4, Step: 7, Action: [0.10694821 0.09520243 0.0138244  0.0574264  0.03998762 0.02560027\n",
      " 0.21648447 0.12377844 0.14008929 0.18065847], Действие: случайное\n",
      "loss =  tensor(1.4822, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5673, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7236, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4060, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5307, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4196, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1550, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1732, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0286, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1514, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0125, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8816, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8715, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8900, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8659, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8032, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3945\n",
      "Reward: 6.2849\n",
      "Episode: 4, Step: 8, State: [0.0, 1.0, 1.0, 0.0077821011655032635, 0.9989929795265198, 1.0, 0.938071072101593, 0.41033434867858887, 0.6846560835838318, 0.05522088333964348]\n",
      "weights [0.9999990000010001, 10, 10, 1.0078421215062958, 10, 10, 10, 1.6958734189207647, 3.171130872711695, 1.0584473385562312]\n",
      "Episode: 4, Step: 8, Epsilon: 0.3658\n",
      "Episode: 4, Step: 8, Action: [3.2999317e-09 2.2958818e-06 1.0587270e-08 9.9999762e-01 3.3102194e-09\n",
      " 3.5398235e-09 5.3124150e-09 3.8243093e-09 6.7117732e-08 1.6123593e-08], Действие: агент\n",
      "loss =  tensor(0.1682, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1628, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1673, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1597, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1617, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1574, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1498, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1407, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1339, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1388, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1327, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1276, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1277, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1278, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1209, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1231, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.353\n",
      "Reward: 9.8460\n",
      "Episode: 4, Step: 9, State: [0.0, 0.9990079402923584, 1.0, 0.7052529454231262, 0.964753270149231, 0.9442785978317261, 0.5208121538162231, 0.6271529793739319, 0.5968254208564758, 0.12449799478054047]\n",
      "weights [0.9999990000010001, 10, 10, 3.3927280756290394, 10, 10, 2.0868599258182305, 2.6820579557344817, 2.4803089565204437, 1.1422005339083139]\n",
      "Episode: 4, Step: 9, Epsilon: 0.3643\n",
      "Episode: 4, Step: 9, Action: [0.12540801 0.11897049 0.00972166 0.0682067  0.02750531 0.35327356\n",
      " 0.08332416 0.01922342 0.14419341 0.05017329], Действие: случайное\n",
      "loss =  tensor(1.2987, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2071, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3913, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1692, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2849, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2703, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4298, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3634, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1156, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9571, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9605, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8711, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9583, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8624, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9498, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8391, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4806\n",
      "Reward: 17.4454\n",
      "Episode: 4, Step: 10, State: [0.0191938579082489, 0.8720238208770752, 0.9663699269294739, 0.005836575757712126, 0.8912386894226074, 0.34825870394706726, 0.6781725883483887, 0.8409321308135986, 0.13333334028720856, 0.45481929183006287]\n",
      "weights [1.0195684320439558, 7.813893124175512, 10, 1.0058698295929869, 9.19436149058662, 1.5343487848742943, 3.1072458608239018, 6.286585207493817, 1.1538448317448398, 1.8342508286948846]\n",
      "Episode: 4, Step: 10, Epsilon: 0.3627\n",
      "Episode: 4, Step: 10, Action: [0.25404055 0.00034249 0.01685605 0.04118148 0.17732678 0.04089576\n",
      " 0.11335529 0.17075858 0.1778457  0.00739732], Действие: случайное\n",
      "loss =  tensor(1.1488, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1365, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1365, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2228, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1847, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0289, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0669, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0048, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8957, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8296, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8596, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7711, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7522, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7209, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7379, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7177, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4946\n",
      "Reward: 17.6167\n",
      "accuracy =  0.3152\n",
      "--------------------------------------\n",
      "Episode: 4, Step: 10, Test Accuracy: 0.3152\n",
      "--------------------------------------\n",
      "Episode: 4, Step: 11, State: [0.37523990869522095, 0.1894841343164444, 0.9020771384239197, 0.011673151515424252, 0.6404833793640137, 0.40597015619277954, 0.8852791786193848, 0.5268490314483643, 0.3153439164161682, 0.8172690868377686]\n",
      "weights [1.600611840138052, 1.233780618687857, 10, 1.0118099996203904, 2.7815048348144966, 1.6834142712032774, 8.71673747823683, 2.1134858702186055, 1.4605851950957818, 5.472497839565598]\n",
      "Episode: 4, Step: 11, Epsilon: 0.3611\n",
      "Episode: 4, Step: 11, Action: [0.0719531  0.00854641 0.23444433 0.24040854 0.22164449 0.05104546\n",
      " 0.02994716 0.0167848  0.11159224 0.01363348], Действие: случайное\n",
      "loss =  tensor(1.3168, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2886, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4252, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2821, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4131, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1035, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1176, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2261, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8315, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8453, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7635, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7839, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7653, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6500, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7677, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7747, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2668\n",
      "Reward: 5.4786\n",
      "Episode: 4, Step: 12, State: [0.0, 0.533730149269104, 1.0, 0.7392995953559875, 0.5226585865020752, 0.9681591987609863, 0.9563452005386353, 0.9280648231506348, 0.9068782925605774, 0.8192771077156067]\n",
      "weights [0.9999990000010001, 2.1446762079003325, 10, 3.83580595342591, 2.0949322157905153, 10, 10, 10, 10, 5.533302693737725]\n",
      "Episode: 4, Step: 12, Epsilon: 0.3596\n",
      "Episode: 4, Step: 12, Action: [2.2274804e-11 5.0169170e-08 9.3937962e-11 1.0000000e+00 2.6639827e-11\n",
      " 2.5151943e-11 3.7638753e-11 3.1089086e-11 7.9590451e-10 1.4563917e-10], Действие: агент\n",
      "loss =  tensor(0.2514, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2305, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2551, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2280, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2220, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2059, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1977, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2024, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1713, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1704, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1623, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1658, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1630, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1611, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1523, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1532, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3095\n",
      "Reward: 15.3026\n",
      "Episode: 4, Step: 13, State: [0.008637236431241035, 0.9990079402923584, 1.0, 0.002918287878856063, 1.0, 1.0, 1.0, 0.9979736804962158, 0.0063492064364254475, 0.904618501663208]\n",
      "weights [1.008711470752322, 10, 10, 1.0029258233478444, 10, 10, 10, 10, 1.0063887636268019, 10]\n",
      "Episode: 4, Step: 13, Epsilon: 0.3580\n",
      "Episode: 4, Step: 13, Action: [0.10480472 0.07378242 0.28209505 0.03371735 0.06230653 0.13100047\n",
      " 0.07546705 0.0081118  0.0578615  0.17085311], Действие: случайное\n",
      "loss =  tensor(1.4510, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2283, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3780, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2616, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1560, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1155, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1625, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1303, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0032, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8850, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7983, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9001, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8584, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8693, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7951, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7289, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3339\n",
      "Reward: 19.3118\n",
      "Episode: 4, Step: 14, State: [0.6545105576515198, 0.9970238208770752, 0.9554896354675293, 0.10894941538572311, 0.8972809910774231, 0.739303469657898, 0.7238578796386719, 0.8834853172302246, 0.6867724657058716, 0.02811245061457157]\n",
      "weights [2.8944360752861185, 10, 10, 1.1222694816629335, 9.735201646582112, 3.8358629584551243, 3.621310567837137, 8.582535640081266, 3.1925571603926044, 1.0289245620110945]\n",
      "Episode: 4, Step: 14, Epsilon: 0.3565\n",
      "Episode: 4, Step: 14, Action: [0.07384988 0.36791669 0.01691666 0.12588808 0.03158599 0.02551769\n",
      " 0.11028628 0.01675537 0.14308916 0.08819421], Действие: случайное\n",
      "loss =  tensor(1.1950, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1093, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0686, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1368, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0502, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0132, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9482, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9427, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8103, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8822, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7292, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7053, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6897, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7509, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7160, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6951, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4958\n",
      "Reward: 20.7179\n",
      "Episode: 4, Step: 15, State: [0.023992322385311127, 0.807539701461792, 0.1928783357143402, 0.04085602983832359, 0.9375629425048828, 0.8169154524803162, 0.5035532712936401, 0.935157060623169, 0.1100529134273529, 0.6937751173973083]\n",
      "weights [1.024581054385648, 5.195849802507058, 1.2389690492523158, 1.0425952604760436, 10, 5.461927571822611, 2.0143107565539546, 10, 1.123661048422704, 3.2655632877950937]\n",
      "Episode: 4, Step: 15, Epsilon: 0.3550\n",
      "Episode: 4, Step: 15, Action: [1.3218290e-07 1.1794865e-03 4.6191840e-07 9.9881589e-01 1.5262697e-07\n",
      " 1.3196953e-07 2.4234467e-07 1.8114154e-07 2.6304751e-06 7.1513028e-07], Действие: агент\n",
      "loss =  tensor(0.2454, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2388, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2362, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2197, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2098, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2213, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2103, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1987, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1774, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1736, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1709, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1626, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1652, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1586, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1563, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1546, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4975\n",
      "Reward: 10.9438\n",
      "Episode: 4, Step: 16, State: [0.0, 0.7976190447807312, 0.5479723215103149, 0.014591439627110958, 0.8922457098960876, 0.7562189102172852, 0.3035533130168915, 0.8622087240219116, 0.2571428716182709, 0.6154618263244629]\n",
      "weights [0.9999990000010001, 4.941151986186513, 2.212249017786201, 1.0148064725712522, 9.28028683358064, 4.102024069493001, 1.4358580245012051, 7.257300838539159, 1.346152060257372, 2.600515288056896]\n",
      "Episode: 4, Step: 16, Epsilon: 0.3535\n",
      "Episode: 4, Step: 16, Action: [9.9088922e-08 5.2051235e-04 3.3545402e-07 9.9947625e-01 1.1099677e-07\n",
      " 9.7919745e-08 1.7898714e-07 1.3186273e-07 1.7132473e-06 5.2424491e-07], Действие: агент\n",
      "loss =  tensor(0.1717, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1650, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1636, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1650, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1655, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1618, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1665, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1620, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1467, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1412, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1389, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1312, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1370, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1332, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1290, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1311, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.5041\n",
      "Reward: 10.9438\n",
      "Episode: 4, Step: 17, State: [0.01343570090830326, 0.4186508059501648, 0.8773491382598877, 0.0, 0.9506545662879944, 0.8467661738395691, 0.5147207975387573, 0.8368794322013855, 0.18835978209972382, 0.3313252925872803]\n",
      "weights [1.013617649962625, 1.7201335962988888, 8.153157936720973, 0.9999990000010001, 10, 6.525931637453217, 2.0606651475337405, 6.1303971847216, 1.2320714842292138, 1.4954932397189367]\n",
      "Episode: 4, Step: 17, Epsilon: 0.3519\n",
      "Episode: 4, Step: 17, Action: [5.3716075e-08 1.1110298e-04 1.6239501e-07 9.9988735e-01 6.3448439e-08\n",
      " 5.8583367e-08 9.0355577e-08 7.1022569e-08 7.6036724e-07 2.6151611e-07], Действие: агент\n",
      "loss =  tensor(0.1398, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1376, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1360, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1329, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1302, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1343, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1276, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1274, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1218, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1211, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1161, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1166, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1160, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1136, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1093, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1102, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.527\n",
      "Reward: 10.2861\n",
      "Episode: 4, Step: 18, State: [0.09213051944971085, 0.1884920597076416, 0.888229489326477, 0.0, 0.9446122646331787, 0.8388059735298157, 0.5421319603919983, 0.7629179358482361, 0.24656084179878235, 0.24598392844200134]\n",
      "weights [1.1014787036515035, 1.2322723143872387, 8.946823693927987, 0.9999990000010001, 10, 6.2036653481053055, 2.184030614640676, 4.217930975279914, 1.3272454210397089, 1.3262299193488225]\n",
      "Episode: 4, Step: 18, Epsilon: 0.3504\n",
      "Episode: 4, Step: 18, Action: [0.04571165 0.16976463 0.07663508 0.06094773 0.01195494 0.05775856\n",
      " 0.00563043 0.00491172 0.44203185 0.1246534 ], Действие: случайное\n",
      "loss =  tensor(1.3011, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2038, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3329, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0939, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2052, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0643, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9391, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9956, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7893, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8985, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8222, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7607, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7865, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7025, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7858, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7364, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1888\n",
      "Reward: 2.3960\n",
      "Episode: 4, Step: 19, State: [1.0, 1.0, 1.0, 0.2937743067741394, 0.9989929795265198, 0.9960198998451233, 0.9979695677757263, 0.9848024249076843, 0.0063492064364254475, 0.7981927990913391]\n",
      "weights [10, 10, 10, 1.4159759317964307, 10, 10, 10, 10, 1.0063887636268019, 4.955200014159006]\n",
      "Episode: 4, Step: 19, Epsilon: 0.3489\n",
      "Episode: 4, Step: 19, Action: [8.2435083e-12 1.5791616e-07 4.5977368e-11 9.9999988e-01 1.1084667e-11\n",
      " 1.0155405e-11 1.6331754e-11 1.2498176e-11 6.4447175e-10 9.2649652e-11], Действие: агент\n",
      "loss =  tensor(0.1692, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1663, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1535, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1627, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1523, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1435, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1489, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1444, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1224, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1268, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1222, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1178, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1177, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1114, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1105, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1118, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3346\n",
      "Reward: 16.7400\n",
      "Episode: 4, Step: 20, State: [0.0009596928721293807, 0.5952380895614624, 1.0, 0.17120622098445892, 1.0, 0.9990049600601196, 1.0, 1.0, 0.005291005130857229, 0.8955823183059692]\n",
      "weights [1.000959612846125, 2.4705820968540744, 10, 1.2065713072997635, 10, 10, 10, 10, 1.005318138108739, 9.576830350436865]\n",
      "Episode: 4, Step: 20, Epsilon: 0.3474\n",
      "Episode: 4, Step: 20, Action: [2.9173300e-10 1.0761098e-06 1.3361561e-09 9.9999893e-01 3.8156567e-10\n",
      " 3.7412987e-10 6.0165795e-10 4.2860668e-10 1.1222333e-08 2.2833848e-09], Действие: агент\n",
      "loss =  tensor(0.1220, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1158, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1149, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1175, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1159, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1140, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1132, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1110, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1037, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1045, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0995, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0996, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0976, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0961, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0973, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0965, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3935\n",
      "Reward: 7.3925\n",
      "accuracy =  0.3238\n",
      "--------------------------------------\n",
      "Episode: 4, Step: 20, Test Accuracy: 0.3238\n",
      "--------------------------------------\n",
      "Episode: 4, Step: 21, State: [0.06717850267887115, 0.2251984179019928, 0.9940652847290039, 0.022373540326952934, 0.9989929795265198, 0.9900497794151306, 0.992893397808075, 1.0, 0.014814814552664757, 0.7771084308624268]\n",
      "weights [1.0720153114572075, 1.2906513518478528, 10, 1.0228845252919094, 10, 10, 10, 10, 1.015036563414598, 4.486466300196765]\n",
      "Episode: 4, Step: 21, Epsilon: 0.3460\n",
      "Episode: 4, Step: 21, Action: [1.0068367e-09 2.5832421e-06 3.8278989e-09 9.9999738e-01 1.3758624e-09\n",
      " 1.2685850e-09 1.9584885e-09 1.5095222e-09 2.7021663e-08 6.6099557e-09], Действие: агент\n",
      "loss =  tensor(0.1027, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0987, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0994, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0984, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0974, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0972, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0966, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0934, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0916, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0896, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0885, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0878, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0895, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0853, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0854, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0862, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4195\n",
      "Reward: 7.2110\n",
      "Episode: 4, Step: 22, State: [0.14395393431186676, 0.1170634925365448, 0.9000989198684692, 0.0, 0.9909365773200989, 0.9492537379264832, 0.9746192693710327, 0.9949341416358948, 0.02857142873108387, 0.7228915691375732]\n",
      "weights [1.1681600697925998, 1.1325829875240518, 10, 0.9999990000010001, 10, 10, 10, 10, 1.0294107051875765, 3.6086826669441585]\n",
      "Episode: 4, Step: 22, Epsilon: 0.3445\n",
      "Episode: 4, Step: 22, Action: [0.12995013 0.04192677 0.08562263 0.02761369 0.0449458  0.40054438\n",
      " 0.18603917 0.0056454  0.05216262 0.02554942], Действие: случайное\n",
      "loss =  tensor(1.6325, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7384, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8178, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4785, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4894, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4457, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5686, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3393, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2354, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2198, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0816, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0950, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9775, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0488, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0022, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0872, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1482\n",
      "Reward: 14.5580\n",
      "Episode: 4, Step: 23, State: [1.0, 1.0, 1.0, 0.9883268475532532, 0.9879153966903687, 0.03980099409818649, 0.5380710363388062, 0.9888551235198975, 0.9978836178779602, 0.9748995900154114]\n",
      "weights [10, 10, 10, 10, 10, 1.0414496915783775, 2.164830339374689, 10, 10, 10]\n",
      "Episode: 4, Step: 23, Epsilon: 0.3430\n",
      "Episode: 4, Step: 23, Action: [2.8151635e-12 1.7174823e-07 1.5875903e-11 9.9999988e-01 3.4755866e-12\n",
      " 2.8990469e-12 5.6702368e-12 4.6865753e-12 1.9618497e-10 2.5900108e-11], Действие: агент\n",
      "loss =  tensor(0.1346, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1357, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1303, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1310, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1300, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1324, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1262, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1238, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1103, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1096, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1095, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1096, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1035, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0991, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0978, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1033, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4179\n",
      "Reward: 29.7149\n",
      "Episode: 4, Step: 24, State: [0.6967370510101318, 0.0019841270986944437, 0.9940652847290039, 0.18579766154289246, 0.7432023882865906, 0.12835821509361267, 0.4883248805999756, 0.9706180095672607, 0.7862433791160583, 0.8514056205749512]\n",
      "weights [3.2974575558053205, 1.0019870677065101, 10, 1.2281944236374318, 3.8941020487914986, 1.147258965847343, 1.954361288489619, 10, 4.678195780177323, 6.729684354044116]\n",
      "Episode: 4, Step: 24, Epsilon: 0.3416\n",
      "Episode: 4, Step: 24, Action: [1.9719599e-09 2.3606161e-05 5.8831104e-09 9.9997640e-01 2.6461076e-09\n",
      " 1.8809936e-09 3.4318695e-09 3.0999034e-09 3.3098544e-08 9.6505230e-09], Действие: агент\n",
      "loss =  tensor(0.1045, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1068, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1079, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1012, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1072, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1056, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1026, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1000, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0942, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0958, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0903, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0890, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0882, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0903, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0869, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0857, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4326\n",
      "Reward: 14.1616\n",
      "Episode: 4, Step: 25, State: [0.0, 0.6597222089767456, 0.9990108609199524, 0.0, 0.9979858994483948, 0.8796020150184631, 0.6751269102096558, 0.9696048498153687, 0.10793650895357132, 0.4016064405441284]\n",
      "weights [0.9999990000010001, 2.9387667594353855, 10, 0.9999990000010001, 10, 8.305717860938358, 3.078115588243263, 10, 1.1209951859275986, 1.67113818833733]\n",
      "Episode: 4, Step: 25, Epsilon: 0.3401\n",
      "Episode: 4, Step: 25, Action: [5.4304352e-09 9.7354186e-06 1.9124284e-08 9.9999011e-01 6.3095160e-09\n",
      " 6.1239835e-09 9.6590886e-09 7.0533286e-09 1.0683203e-07 3.1516667e-08], Действие: агент\n",
      "loss =  tensor(0.0911, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0927, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0885, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0869, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0889, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0882, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0856, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0879, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0805, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0795, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0802, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0805, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0811, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0786, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0772, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0761, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4039\n",
      "Reward: 6.3481\n",
      "Episode: 4, Step: 26, State: [0.0, 0.8978174328804016, 1.0, 0.0, 0.9989929795265198, 0.9104477763175964, 0.7746192812919617, 0.954407274723053, 0.16931216418743134, 0.27409639954566956]\n",
      "weights [0.9999990000010001, 9.786309366451977, 10, 0.9999990000010001, 10, 10, 4.436917092177337, 10, 1.2038201994394369, 1.3775914898102564]\n",
      "Episode: 4, Step: 26, Epsilon: 0.3387\n",
      "Episode: 4, Step: 26, Action: [0.13252033 0.15694536 0.06920055 0.01791012 0.01252172 0.0812784\n",
      " 0.05534504 0.23849297 0.10069499 0.13509052], Действие: случайное\n",
      "loss =  tensor(1.3956, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3351, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3260, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3899, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3433, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2301, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1220, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0884, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0359, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0167, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9572, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8641, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7979, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7929, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3077\n",
      "Reward: 9.9306\n",
      "Episode: 4, Step: 27, State: [1.0, 1.0, 1.0, 0.15466925501823425, 0.9758307933807373, 0.9631840586662292, 0.8700507879257202, 0.39918947219848633, 0.20952381193637848, 0.3182730972766876]\n",
      "weights [10, 10, 10, 1.1829675224388627, 10, 10, 7.695254852130584, 1.6644154676245888, 1.2650586444494778, 1.4668608927480884]\n",
      "Episode: 4, Step: 27, Epsilon: 0.3372\n",
      "Episode: 4, Step: 27, Action: [0.52242939 0.20510244 0.0212021  0.01600537 0.0738628  0.02486907\n",
      " 0.02657571 0.0237157  0.067284   0.0189534 ], Действие: случайное\n",
      "loss =  tensor(1.6964, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7479, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7487, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0953, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1164, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3058, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5996, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3345, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2684, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3164, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9975, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8909, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8732, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9272, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8244, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7782, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1673\n",
      "Reward: 11.5884\n",
      "Episode: 4, Step: 28, State: [1.0, 0.7817460298538208, 0.9634025692939758, 0.4309338629245758, 0.17925478518009186, 0.9840795993804932, 1.0, 1.0, 1.0, 1.0]\n",
      "weights [10, 4.581797149133587, 10, 1.7572619025924525, 1.218403425984029, 10, 10, 10, 10, 10]\n",
      "Episode: 4, Step: 28, Epsilon: 0.3358\n",
      "Episode: 4, Step: 28, Action: [9.5039016e-13 1.1061221e-08 3.8647310e-12 1.0000000e+00 1.1485320e-12\n",
      " 8.8337904e-13 1.4698776e-12 1.2762458e-12 3.7278451e-11 6.6235676e-12], Действие: агент\n",
      "loss =  tensor(0.1957, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2277, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1958, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1927, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1788, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1739, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1709, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1544, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1394, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1373, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1286, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1270, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1363, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1209, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1222, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1186, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4293\n",
      "Reward: 29.3071\n",
      "Episode: 4, Step: 29, State: [0.0009596928721293807, 0.2678571343421936, 0.9950544238090515, 0.0, 0.8771399855613708, 0.8845770955085754, 0.8730964660644531, 0.9827761054039001, 0.3047619163990021, 0.5542168617248535]\n",
      "weights [1.000959612846125, 1.365851777097844, 10, 0.9999990000010001, 8.13927839167822, 8.663716622706133, 7.879939108463112, 10, 1.4383541195936365, 2.243238182204637]\n",
      "Episode: 4, Step: 29, Epsilon: 0.3344\n",
      "Episode: 4, Step: 29, Action: [2.0053306e-09 2.5012441e-06 6.3437002e-09 9.9999750e-01 2.4815767e-09\n",
      " 2.2308742e-09 3.4586807e-09 2.7417462e-09 3.3603744e-08 1.0289656e-08], Действие: агент\n",
      "loss =  tensor(0.1294, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1281, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1262, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1234, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1234, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1251, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1117, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1180, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1019, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1021, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0985, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0923, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0971, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0979, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0925, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0930, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3722\n",
      "Reward: 6.7787\n",
      "Episode: 4, Step: 30, State: [0.0, 1.0, 1.0, 0.0009727626456879079, 0.9929506778717041, 0.9412935376167297, 0.834517776966095, 0.9625126719474792, 0.1449735462665558, 0.4186747074127197]\n",
      "weights [0.9999990000010001, 10, 10, 1.0009727078868775, 10, 10, 6.042908650595444, 10, 1.1695530893581707, 1.7202043202782886]\n",
      "Episode: 4, Step: 30, Epsilon: 0.3329\n",
      "Episode: 4, Step: 30, Action: [0.02562798 0.0845238  0.16584294 0.04399355 0.04204882 0.16052473\n",
      " 0.16255252 0.02426703 0.18653416 0.10408447], Действие: случайное\n",
      "loss =  tensor(1.8193, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8033, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0834, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6464, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8218, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4904, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2770, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2882, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1707, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0446, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9845, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0359, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0461, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9045, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9022, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9264, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3507\n",
      "Reward: 4.2210\n",
      "accuracy =  0.2989\n",
      "--------------------------------------\n",
      "Episode: 4, Step: 30, Test Accuracy: 0.2989\n",
      "--------------------------------------\n",
      "Episode: 4, Step: 31, State: [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.43386244773864746, 0.09437751024961472]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 1.7663520634757255, 1.1042116412811105]\n",
      "Episode: 4, Step: 31, Epsilon: 0.3315\n",
      "Episode: 4, Step: 31, Action: [0.09169026 0.17305797 0.05083118 0.00851206 0.21840809 0.02472748\n",
      " 0.08243784 0.05468934 0.02614993 0.26949586], Действие: случайное\n",
      "loss =  tensor(1.3261, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3126, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3028, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2134, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1919, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1875, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0886, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1321, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9759, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9948, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8692, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8457, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8782, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9705, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8553, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8447, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3059\n",
      "Reward: 3.3684\n",
      "Episode: 4, Step: 32, State: [0.0, 1.0, 1.0, 0.04085602983832359, 1.0, 0.9970149397850037, 0.9746192693710327, 0.9989868402481079, 0.9936507940292358, 0.0]\n",
      "weights [0.9999990000010001, 10, 10, 1.0425952604760436, 10, 10, 10, 10, 10, 0.9999990000010001]\n",
      "Episode: 4, Step: 32, Epsilon: 0.3301\n",
      "Episode: 4, Step: 32, Action: [5.2547886e-11 1.8314116e-08 1.7670168e-10 1.0000000e+00 5.0881639e-11\n",
      " 5.2042183e-11 8.3372337e-11 6.1683152e-11 1.1777118e-09 2.5941457e-10], Действие: агент\n",
      "loss =  tensor(0.1883, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1833, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1859, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1749, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1795, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1654, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1541, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1499, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1305, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1152, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1186, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1224, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1197, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1157, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1104, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1089, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2139\n",
      "Reward: 2.8736\n",
      "Episode: 4, Step: 33, State: [0.0, 1.0, 1.0, 0.9630350470542908, 1.0, 1.0, 0.9979695677757263, 0.9929078221321106, 0.9238095283508301, 0.01807228848338127]\n",
      "weights [0.9999990000010001, 10, 10, 10, 10, 10, 10, 10, 10, 1.0184038701297058]\n",
      "Episode: 4, Step: 33, Epsilon: 0.3287\n",
      "Episode: 4, Step: 33, Action: [5.1782641e-12 4.7247006e-09 2.1748103e-11 1.0000000e+00 5.2685451e-12\n",
      " 5.8555218e-12 7.7673441e-12 6.3903275e-12 1.6605445e-10 3.1875187e-11], Действие: агент\n",
      "loss =  tensor(0.1221, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1141, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1197, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1201, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1133, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1114, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1072, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1031, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0992, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0994, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0968, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0957, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0947, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0981, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0932, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0892, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3113\n",
      "Reward: 12.5231\n",
      "Episode: 4, Step: 34, State: [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.9979695677757263, 0.996960461139679, 0.9544973373413086, 0.001004016026854515]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 10, 1.0010040230780932]\n",
      "Episode: 4, Step: 34, Epsilon: 0.3273\n",
      "Episode: 4, Step: 34, Action: [0.06236149 0.00131086 0.14571869 0.15638575 0.18408616 0.09425586\n",
      " 0.15070636 0.08117512 0.03410328 0.08989644], Действие: случайное\n",
      "loss =  tensor(1.2428, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1801, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6022, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2527, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2217, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2862, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0642, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1668, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0509, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8249, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8761, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8030, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7353, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6614, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7416, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3778\n",
      "Reward: 30.3883\n",
      "Episode: 4, Step: 35, State: [1.0, 0.403769850730896, 0.9901087880134583, 0.3025291860103607, 0.1510574072599411, 0.5980099439620972, 0.5583756566047668, 0.4488348662853241, 0.8931217193603516, 0.8765060305595398]\n",
      "weights [10, 1.6772018725050848, 10, 1.4337496941702288, 1.1779345630872717, 2.4876175352162866, 2.2643628019894884, 1.814334986912809, 9.356350398461002, 8.097495829432333]\n",
      "Episode: 4, Step: 35, Epsilon: 0.3260\n",
      "Episode: 4, Step: 35, Action: [7.6279133e-10 1.0400908e-05 2.0507718e-09 9.9998963e-01 9.2203101e-10\n",
      " 6.4514888e-10 1.0646573e-09 1.0131010e-09 8.9101011e-09 3.3197913e-09], Действие: агент\n",
      "loss =  tensor(0.1455, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1340, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1427, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1418, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1419, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1410, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1328, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1305, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1173, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1135, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1110, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1090, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1062, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1042, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0992, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0998, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4563\n",
      "Reward: 25.2759\n",
      "Episode: 4, Step: 36, State: [0.0, 1.0, 0.9980217814445496, 0.06614785641431808, 0.9013091921806335, 0.8338308334350586, 0.5918781757354736, 0.3860182464122772, 0.46560847759246826, 0.2158634513616562]\n",
      "weights [0.9999990000010001, 10, 10, 1.070832182628134, 10, 6.017927409425731, 2.4502427714061055, 1.6287102433360532, 1.8712836689683177, 1.2752864618414226]\n",
      "Episode: 4, Step: 36, Epsilon: 0.3246\n",
      "Episode: 4, Step: 36, Action: [1.7106130e-08 2.0492453e-05 5.0527756e-08 9.9997914e-01 1.6967604e-08\n",
      " 1.6911867e-08 2.6966543e-08 1.9745070e-08 1.9345141e-07 7.3104957e-08], Действие: агент\n",
      "loss =  tensor(0.1203, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1091, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1114, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1041, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1056, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1045, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1040, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1005, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0934, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0916, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0916, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0887, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0886, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0862, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0860, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0851, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3748\n",
      "Reward: 4.7807\n",
      "Episode: 4, Step: 37, State: [0.0, 1.0, 0.9990108609199524, 0.0, 1.0, 0.9900497794151306, 0.9065989851951599, 0.8409321308135986, 0.4910053014755249, 0.05923694744706154]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 10, 6.286585207493817, 1.964653145201216, 1.0629657854021035]\n",
      "Episode: 4, Step: 37, Epsilon: 0.3232\n",
      "Episode: 4, Step: 37, Action: [0.01222682 0.02643726 0.33930046 0.07311868 0.20166791 0.03391808\n",
      " 0.0156372  0.03794991 0.10870872 0.15103495], Действие: случайное\n",
      "loss =  tensor(1.2387, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3031, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1707, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1480, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1975, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0769, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9542, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0946, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8561, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8898, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7989, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7616, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8090, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6472, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7969, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7231, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3466\n",
      "Reward: 11.2468\n",
      "Episode: 4, Step: 38, State: [1.0, 1.0, 1.0, 0.01653696410357952, 0.8418932557106018, 0.8905472755432129, 0.8010152578353882, 0.4751773178577423, 0.24126984179019928, 0.23995983600616455]\n",
      "weights [10, 10, 10, 1.0168139998007217, 6.324800878631309, 9.136281154094533, 5.025485691194627, 1.9054018216520607, 1.3179898956034237, 1.3157182102417162]\n",
      "Episode: 4, Step: 38, Epsilon: 0.3218\n",
      "Episode: 4, Step: 38, Action: [7.3862821e-10 4.0952687e-06 2.4221134e-09 9.9999583e-01 8.3529927e-10\n",
      " 7.3402173e-10 1.1168120e-09 9.1624092e-10 1.4393455e-08 4.2879940e-09], Действие: агент\n",
      "loss =  tensor(0.1435, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1448, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1431, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1399, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1280, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1271, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1243, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1132, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1050, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1045, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0999, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0973, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0986, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0956, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0930, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0949, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3413\n",
      "Reward: 12.8697\n",
      "Episode: 4, Step: 39, State: [0.0, 1.0, 1.0, 0.08171205967664719, 1.0, 1.0, 1.0, 0.9949341416358948, 0.31216931343078613, 0.22489960491657257]\n",
      "weights [0.9999990000010001, 10, 10, 1.0889818619048974, 10, 10, 10, 10, 1.453844042846918, 1.2901537867731043]\n",
      "Episode: 4, Step: 39, Epsilon: 0.3205\n",
      "Episode: 4, Step: 39, Action: [2.3533619e-10 1.8700588e-07 8.5197077e-10 9.9999976e-01 2.4780336e-10\n",
      " 2.5550959e-10 3.8838657e-10 2.7553712e-10 5.1498446e-09 1.3569320e-09], Действие: агент\n",
      "loss =  tensor(0.1007, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1027, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0980, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0964, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0999, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0957, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0927, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0939, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0900, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0845, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0846, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0823, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0840, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0797, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0773, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0797, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3552\n",
      "Reward: 4.3656\n",
      "Episode: 4, Step: 40, State: [0.0, 1.0, 1.0, 0.0, 1.0, 0.998009979724884, 1.0, 0.9797365665435791, 0.29100528359413147, 0.206827312707901]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 1.4104457570905047, 1.2607579096755057]\n",
      "Episode: 4, Step: 40, Epsilon: 0.3191\n",
      "Episode: 4, Step: 40, Action: [3.4796890e-10 2.5040194e-07 1.2186937e-09 9.9999976e-01 3.6421369e-10\n",
      " 3.7326631e-10 5.7191851e-10 4.0249473e-10 7.0634130e-09 1.9421997e-09], Действие: агент\n",
      "loss =  tensor(0.0811, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0823, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0834, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0844, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0812, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0828, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0791, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0798, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0775, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0737, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0732, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0742, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0712, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0705, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0703, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0718, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3668\n",
      "Reward: 5.4575\n",
      "accuracy =  0.2978\n",
      "--------------------------------------\n",
      "Episode: 4, Step: 40, Test Accuracy: 0.2978\n",
      "--------------------------------------\n",
      "Episode: 4, Step: 41, State: [0.0, 0.9960317611694336, 0.9762611389160156, 0.0, 0.9949647784233093, 0.9850746393203735, 0.9593908786773682, 0.9422492384910583, 0.26243385672569275, 0.2409638613462448]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 1.3558087682169049, 1.3174585920441544]\n",
      "Episode: 4, Step: 41, Epsilon: 0.3178\n",
      "Episode: 4, Step: 41, Action: [5.3768584e-10 4.4022406e-07 1.8680442e-09 9.9999952e-01 5.6412869e-10\n",
      " 5.7319277e-10 8.8764796e-10 6.2510569e-10 1.0378216e-08 2.9563645e-09], Действие: агент\n",
      "loss =  tensor(0.0706, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0755, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0761, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0759, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0746, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0714, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0708, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0714, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0700, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0670, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0666, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0661, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0654, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0661, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0642, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0639, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3971\n",
      "Reward: 8.4382\n",
      "Episode: 4, Step: 42, State: [0.0, 0.9910714030265808, 0.8486647009849548, 0.0, 0.9889224767684937, 0.939303457736969, 0.8812182545661926, 0.9078013896942139, 0.26137566566467285, 0.2359437793493271]\n",
      "weights [0.9999990000010001, 10, 6.607800022257612, 0.9999990000010001, 10, 10, 8.418731157862132, 10, 1.3538663697473607, 1.3088024993054808]\n",
      "Episode: 4, Step: 42, Epsilon: 0.3165\n",
      "Episode: 4, Step: 42, Action: [1.6326450e-09 1.6276075e-06 5.4411902e-09 9.9999833e-01 1.6961385e-09\n",
      " 1.6861134e-09 2.6703297e-09 1.9082167e-09 2.7851920e-08 8.3905745e-09], Действие: агент\n",
      "loss =  tensor(0.0657, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0654, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0677, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0662, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0655, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0638, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0659, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0646, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0623, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0623, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0602, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0588, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0596, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0606, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0587, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0586, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4576\n",
      "Reward: 12.8779\n",
      "Episode: 4, Step: 43, State: [0.0019193857442587614, 0.9464285969734192, 0.6844708323478699, 0.0, 0.9264854192733765, 0.8477612137794495, 0.7360405921936035, 0.8247213959693909, 0.2232804298400879, 0.2550200819969177]\n",
      "weights [1.001922073021743, 10, 3.169269066856686, 0.9999990000010001, 10, 6.5685851565194335, 3.7884469428970453, 5.705170350712167, 1.2874642933611489, 1.3423162605030141]\n",
      "Episode: 4, Step: 43, Epsilon: 0.3151\n",
      "Episode: 4, Step: 43, Action: [1.4423472e-08 2.2476099e-05 4.4146475e-08 9.9997723e-01 1.4920431e-08\n",
      " 1.4203216e-08 2.2971619e-08 1.6871564e-08 1.9040156e-07 6.5924134e-08], Действие: агент\n",
      "loss =  tensor(0.0610, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0595, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0594, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0601, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0596, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0588, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0570, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0605, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0561, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0560, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0549, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0569, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0550, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0549, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0525, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0539, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4498\n",
      "Reward: 8.8717\n",
      "Episode: 4, Step: 44, State: [0.0019193857442587614, 0.9523809552192688, 0.7012858390808105, 0.0, 0.9305136203765869, 0.8587064743041992, 0.7614213228225708, 0.8378925919532776, 0.23386242985725403, 0.2469879537820816]\n",
      "weights [1.001922073021743, 10, 3.347670727266927, 0.9999990000010001, 10, 7.0774150313009585, 4.191471846348046, 6.168711494050222, 1.3052469082892946, 1.3279982399011514]\n",
      "Episode: 4, Step: 44, Epsilon: 0.3138\n",
      "Episode: 4, Step: 44, Action: [1.0535584e-08 1.5026680e-05 3.2381642e-08 9.9998474e-01 1.0874685e-08\n",
      " 1.0390342e-08 1.6750869e-08 1.2281359e-08 1.4115126e-07 4.8402807e-08], Действие: агент\n",
      "loss =  tensor(0.0543, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0541, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0529, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0545, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0544, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0531, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0519, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0542, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0524, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0500, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0502, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0516, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0492, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0493, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0499, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0497, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4369\n",
      "Reward: 8.5994\n",
      "Episode: 4, Step: 45, State: [0.0019193857442587614, 0.9503968358039856, 0.7893174886703491, 0.0, 0.939577043056488, 0.8835821151733398, 0.7644670009613037, 0.8399189710617065, 0.2507936656475067, 0.23393574357032776]\n",
      "weights [1.001922073021743, 10, 4.746455921912782, 0.9999990000010001, 10, 8.589671697069873, 4.245671555195343, 6.246797386516561, 1.3347440076307524, 1.3053718225789344]\n",
      "Episode: 4, Step: 45, Epsilon: 0.3125\n",
      "Episode: 4, Step: 45, Action: [6.0835199e-09 7.2227231e-06 1.8884519e-08 9.9999261e-01 6.2700027e-09\n",
      " 6.0563821e-09 9.6815596e-09 7.0621633e-09 8.2760131e-08 2.8428403e-08], Действие: агент\n",
      "loss =  tensor(0.0510, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0528, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0512, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0494, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0512, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0512, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0496, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0501, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0502, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0477, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0487, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0468, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0474, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0485, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0477, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0464, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4389\n",
      "Reward: 9.0364\n",
      "Episode: 4, Step: 46, State: [0.0, 0.9652777910232544, 0.7675568461418152, 0.0, 0.9466263651847839, 0.8895522356033325, 0.7512690424919128, 0.8338398933410645, 0.2402116358280182, 0.23895582556724548]\n",
      "weights [0.9999990000010001, 10, 4.302108628682072, 0.9999990000010001, 10, 9.053971816367124, 4.020392112129325, 6.018255535891519, 1.3161542490000497, 1.313982446239608]\n",
      "Episode: 4, Step: 46, Epsilon: 0.3112\n",
      "Episode: 4, Step: 46, Action: [0.15290507 0.31755853 0.1147078  0.07555397 0.14194795 0.01645736\n",
      " 0.06874699 0.03582444 0.06872819 0.00756971], Действие: случайное\n",
      "loss =  tensor(1.7283, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5732, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7257, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5540, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4593, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5459, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5037, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4637, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1378, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0582, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1420, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9549, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0598, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9943, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0176, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0983, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2395\n",
      "Reward: 4.1363\n",
      "Episode: 4, Step: 47, State: [0.8483685255050659, 1.0, 0.9990108609199524, 0.0, 0.9144008159637451, 1.0, 0.913705587387085, 0.9240121841430664, 0.2846560776233673, 0.7118473649024963]\n",
      "weights [6.594893365229684, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 1.3979270261367633, 3.4703709348022844]\n",
      "Episode: 4, Step: 47, Epsilon: 0.3099\n",
      "Episode: 4, Step: 47, Action: [1.2511700e-11 7.5789522e-08 5.2125523e-11 9.9999988e-01 1.4944129e-11\n",
      " 1.2809115e-11 2.2186985e-11 1.6710888e-11 4.2668538e-10 9.2893845e-11], Действие: агент\n",
      "loss =  tensor(0.0830, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0816, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0860, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0888, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0942, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0984, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0878, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0955, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0863, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0814, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0819, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0790, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0787, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0777, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0785, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0699, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3595\n",
      "Reward: 23.9049\n",
      "Episode: 4, Step: 48, State: [0.9644913673400879, 0.983134925365448, 0.3125618100166321, 0.10700388997793198, 0.251762330532074, 0.8915423154830933, 0.5532994866371155, 0.8176291584968567, 0.6243386268615723, 0.8985943794250488]\n",
      "weights [10, 10, 1.454674121829153, 1.1198244527076775, 1.3364719584876599, 9.220100764214212, 2.2386313233455186, 5.483302640132437, 2.661964762788501, 9.861289078861324]\n",
      "Episode: 4, Step: 48, Epsilon: 0.3086\n",
      "Episode: 4, Step: 48, Action: [0.04860624 0.04387656 0.0402954  0.0263763  0.1612714  0.19333951\n",
      " 0.02039549 0.00610916 0.08788638 0.37184357], Действие: случайное\n",
      "loss =  tensor(2.1528, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0960, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.0417, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6518, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6039, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3755, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4774, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5452, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1036, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3320, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0153, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0015, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0879, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1159, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9442, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1536\n",
      "Reward: 11.0745\n",
      "Episode: 4, Step: 49, State: [1.0, 1.0, 1.0, 0.9951362013816833, 0.9979858994483948, 0.998009979724884, 0.965482234954834, 0.9685916900634766, 0.45079365372657776, 0.05321285128593445]\n",
      "weights [10, 10, 10, 10, 10, 10, 10, 10, 1.8208059429382635, 1.0562024898159184]\n",
      "Episode: 4, Step: 49, Epsilon: 0.3073\n",
      "Episode: 4, Step: 49, Action: [0.23852222 0.17939115 0.02408918 0.01969418 0.14685954 0.00222271\n",
      " 0.03406871 0.16763427 0.00749752 0.18002054], Действие: случайное\n",
      "loss =  tensor(1.2063, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1041, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2969, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1155, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0399, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0332, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9844, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0807, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8835, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8043, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8185, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8366, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7340, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7663, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7729, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7169, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4221\n",
      "Reward: 37.5377\n",
      "Episode: 4, Step: 50, State: [0.07773512601852417, 0.1130952388048172, 0.575667679309845, 0.09727626293897629, 0.6998993158340454, 0.9731343388557434, 0.9949238300323486, 0.7689969539642334, 0.9185185432434082, 0.6244980096817017]\n",
      "weights [1.0842860266345338, 1.1275155081329191, 2.3566379335319567, 1.1077573915340713, 3.3322038920881414, 10, 10, 4.328928506495375, 10, 2.663094637814579]\n",
      "Episode: 4, Step: 50, Epsilon: 0.3060\n",
      "Episode: 4, Step: 50, Action: [9.0893487e-10 1.0023045e-06 2.2974691e-09 9.9999893e-01 1.0695846e-09\n",
      " 8.4546581e-10 1.3843461e-09 1.2676075e-09 9.4075308e-09 3.1465275e-09], Действие: агент\n",
      "loss =  tensor(0.1353, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1389, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1452, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1480, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1457, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1450, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1390, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1347, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1131, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1115, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1038, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1028, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1008, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0912, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0975, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0923, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1995\n",
      "Reward: 3.9952\n",
      "accuracy =  0.1721\n",
      "--------------------------------------\n",
      "Episode: 4, Step: 50, Test Accuracy: 0.1721\n",
      "--------------------------------------\n",
      "Episode: 4, Step: 51, State: [0.0, 0.9970238208770752, 1.0, 0.9863813519477844, 1.0, 1.0, 0.9989847540855408, 0.9422492384910583, 0.961904764175415, 0.15461847186088562]\n",
      "weights [0.9999990000010001, 10, 10, 10, 10, 10, 10, 10, 10, 1.1828964601400445]\n",
      "Episode: 4, Step: 51, Epsilon: 0.3047\n",
      "Episode: 4, Step: 51, Action: [2.1581153e-12 1.8416391e-09 8.7335928e-12 1.0000000e+00 2.1883407e-12\n",
      " 2.3326779e-12 3.2060040e-12 2.6622545e-12 5.6217055e-11 1.2335994e-11], Действие: агент\n",
      "loss =  tensor(0.1158, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1156, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1035, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1079, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1026, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1025, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1027, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0998, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0919, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0889, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0918, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0839, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0819, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0791, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0791, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0789, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.326\n",
      "Reward: 14.1302\n",
      "Episode: 4, Step: 52, State: [0.0, 0.8829365372657776, 1.0, 0.0, 1.0, 0.9990049600601196, 0.9979695677757263, 0.9412360787391663, 0.9841269850730896, 0.0]\n",
      "weights [0.9999990000010001, 8.542302050028217, 10, 0.9999990000010001, 10, 10, 10, 10, 10, 0.9999990000010001]\n",
      "Episode: 4, Step: 52, Epsilon: 0.3035\n",
      "Episode: 4, Step: 52, Action: [5.1709331e-11 1.2466081e-08 1.5122978e-10 1.0000000e+00 4.9843470e-11\n",
      " 4.8595697e-11 7.7392211e-11 5.9432563e-11 7.4253842e-10 2.1230871e-10], Действие: агент\n",
      "loss =  tensor(0.0837, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0850, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0835, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0850, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0837, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0815, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0825, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0789, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0757, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0763, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0735, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0712, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0718, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0697, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0701, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0691, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3519\n",
      "Reward: 7.3547\n",
      "Episode: 4, Step: 53, State: [0.0, 0.8373016119003296, 0.997032642364502, 0.0, 0.9848942756652832, 0.9810945391654968, 0.9644669890403748, 0.8297872543334961, 0.9460317492485046, 0.00200803205370903]\n",
      "weights [0.9999990000010001, 6.146304615401474, 10, 0.9999990000010001, 10, 10, 10, 5.874966184924209, 10, 1.0020110683323142]\n",
      "Episode: 4, Step: 53, Epsilon: 0.3022\n",
      "Episode: 4, Step: 53, Action: [1.2572110e-10 3.1874869e-08 3.5085068e-10 1.0000000e+00 1.2185516e-10\n",
      " 1.1791362e-10 1.8536694e-10 1.4442396e-10 1.5727035e-09 4.9155990e-10], Действие: агент\n",
      "loss =  tensor(0.0719, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0710, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0713, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0754, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0693, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0689, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0726, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0680, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0678, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0667, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0635, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0629, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0611, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0631, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0606, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0613, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3898\n",
      "Reward: 9.5847\n",
      "Episode: 4, Step: 54, State: [0.0, 0.8273809552192688, 0.9525222778320312, 0.0, 0.9365558624267578, 0.939303457736969, 0.896446704864502, 0.698074996471405, 0.8994709253311157, 0.009036144241690636]\n",
      "weights [0.9999990000010001, 5.793069983675648, 10, 0.9999990000010001, 10, 10, 9.65676989729423, 3.312069806220886, 9.947272030720141, 1.0091175223714435]\n",
      "Episode: 4, Step: 54, Epsilon: 0.3009\n",
      "Episode: 4, Step: 54, Action: [5.0565102e-10 1.5361796e-07 1.3252992e-09 9.9999988e-01 4.8701682e-10\n",
      " 4.6530274e-10 7.2750994e-10 5.7243915e-10 5.2286593e-09 1.8386205e-09], Действие: агент\n",
      "loss =  tensor(0.0653, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0663, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0623, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0626, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0646, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0613, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0633, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0603, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0592, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0579, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0581, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0562, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0561, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0578, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0565, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0553, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4027\n",
      "Reward: 9.7844\n",
      "Episode: 4, Step: 55, State: [0.0, 0.824404776096344, 0.9327398538589478, 0.0, 0.9274924397468567, 0.9273631572723389, 0.8487309813499451, 0.6646403074264526, 0.8920634984970093, 0.011044176295399666]\n",
      "weights [0.9999990000010001, 5.694883282619265, 10, 0.9999990000010001, 10, 10, 6.610695291268392, 2.981864070967983, 9.264620600582385, 1.0111664898109831]\n",
      "Episode: 4, Step: 55, Epsilon: 0.2997\n",
      "Episode: 4, Step: 55, Action: [7.9884266e-10 2.5788162e-07 2.0521269e-09 9.9999976e-01 7.6668927e-10\n",
      " 7.2768197e-10 1.1421263e-09 9.0247659e-10 7.7332949e-09 2.8341858e-09], Действие: агент\n",
      "loss =  tensor(0.0562, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0562, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0566, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0551, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0568, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0560, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0587, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0536, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0532, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0549, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0525, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0522, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0517, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0514, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0505, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0515, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4045\n",
      "Reward: 9.2540\n",
      "Episode: 4, Step: 56, State: [0.0, 0.8015872836112976, 0.9327398538589478, 0.0, 0.9305136203765869, 0.932338297367096, 0.8497461676597595, 0.6717325448989868, 0.8804233074188232, 0.011044176295399666]\n",
      "weights [0.9999990000010001, 5.0399741419134045, 10, 0.9999990000010001, 10, 10, 6.6553599935846135, 3.0462872215129075, 8.362763809990211, 1.0111664898109831]\n",
      "Episode: 4, Step: 56, Epsilon: 0.2984\n",
      "Episode: 4, Step: 56, Action: [8.0985635e-10 2.5934662e-07 2.0684507e-09 9.9999976e-01 7.8094647e-10\n",
      " 7.3929640e-10 1.1558229e-09 9.1735664e-10 7.7187652e-09 2.8585618e-09], Действие: агент\n",
      "loss =  tensor(0.0523, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0524, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0529, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0521, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0509, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0523, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0518, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0504, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0490, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0495, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0481, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0487, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0490, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0471, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0470, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0475, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4196\n",
      "Reward: 10.0817\n",
      "Episode: 4, Step: 57, State: [0.0, 0.7430555820465088, 0.912957489490509, 0.0, 0.9164149165153503, 0.911442756652832, 0.8263959288597107, 0.655521810054779, 0.8814814686775208, 0.012048192322254181]\n",
      "weights [0.9999990000010001, 3.891877146379028, 10, 0.9999990000010001, 10, 10, 5.760200398707855, 2.902932975890416, 8.437427897677933, 1.0121940969534486]\n",
      "Episode: 4, Step: 57, Epsilon: 0.2972\n",
      "Episode: 4, Step: 57, Action: [1.2592078e-09 4.1774405e-07 3.1138359e-09 9.9999952e-01 1.2221596e-09\n",
      " 1.1415988e-09 1.7802644e-09 1.4347427e-09 1.1067041e-08 4.2824597e-09], Действие: агент\n",
      "loss =  tensor(0.0500, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0478, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0469, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0492, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0471, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0470, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0461, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0456, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0442, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0457, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0447, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0436, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0456, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0440, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0437, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0439, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4108\n",
      "Reward: 8.7508\n",
      "Episode: 4, Step: 58, State: [0.0, 0.704365074634552, 0.9465875625610352, 0.0, 0.9295065402984619, 0.93034827709198, 0.8558375835418701, 0.6798378825187683, 0.8931217193603516, 0.009036144241690636]\n",
      "weights [0.9999990000010001, 3.382538839837743, 10, 0.9999990000010001, 10, 10, 6.936572568606094, 3.1234078674243957, 9.356350398461002, 1.0091175223714435]\n",
      "Episode: 4, Step: 58, Epsilon: 0.2960\n",
      "Episode: 4, Step: 58, Action: [8.3144319e-10 2.4981543e-07 2.0611768e-09 9.9999976e-01 8.1397095e-10\n",
      " 7.6098555e-10 1.1768649e-09 9.5335984e-10 7.4344135e-09 2.8449312e-09], Действие: агент\n",
      "loss =  tensor(0.0456, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0447, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0447, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0444, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0437, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0436, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0446, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0432, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0422, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0424, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0415, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0418, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0403, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0414, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0425, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0414, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3945\n",
      "Reward: 8.0691\n",
      "Episode: 4, Step: 59, State: [0.0, 0.7996031641960144, 0.9604352116584778, 0.0, 0.9466263651847839, 0.9472636580467224, 0.8842639327049255, 0.6849037408828735, 0.8772487044334412, 0.01004016026854515]\n",
      "weights [0.9999990000010001, 4.9900738497901065, 10, 0.9999990000010001, 10, 10, 8.640274229953276, 3.17362328952625, 8.146487162496927, 1.0101409670621602]\n",
      "Episode: 4, Step: 59, Epsilon: 0.2947\n",
      "Episode: 4, Step: 59, Action: [5.3436433e-10 1.5685799e-07 1.3710745e-09 9.9999988e-01 5.1657106e-10\n",
      " 4.9094706e-10 7.6304363e-10 6.0500960e-10 5.1531170e-09 1.8984070e-09], Действие: агент\n",
      "loss =  tensor(0.0421, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0414, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0417, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0425, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0413, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0415, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0404, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0424, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0401, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0398, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0392, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0405, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0401, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0389, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0383, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0375, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3886\n",
      "Reward: 8.1081\n",
      "Episode: 4, Step: 60, State: [0.0, 0.8353174328804016, 0.9693372845649719, 0.0, 0.9506545662879944, 0.9502487778663635, 0.8812182545661926, 0.6940222978591919, 0.8783068656921387, 0.01004016026854515]\n",
      "weights [0.9999990000010001, 6.072251272488946, 10, 0.9999990000010001, 10, 10, 8.418731157862132, 3.268201325789698, 8.217322927580092, 1.0101409670621602]\n",
      "Episode: 4, Step: 60, Epsilon: 0.2935\n",
      "Episode: 4, Step: 60, Action: [0.00066567 0.00898611 0.13498772 0.00943737 0.25951274 0.07040165\n",
      " 0.20600373 0.04229195 0.06260576 0.20510729], Действие: случайное\n",
      "loss =  tensor(2.1221, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.2022, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.3277, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.1062, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7968, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9977, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5549, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4322, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3126, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4961, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2715, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3037, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1120, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0415, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1884, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0516, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3473\n",
      "Reward: 14.1064\n",
      "accuracy =  0.2232\n",
      "--------------------------------------\n",
      "Episode: 4, Step: 60, Test Accuracy: 0.2232\n",
      "--------------------------------------\n",
      "Episode: 4, Step: 61, State: [1.0, 1.0, 1.0, 0.006809338461607695, 0.7361530661582947, 0.9552238583564758, 0.49238577485084534, 0.6109422445297241, 0.5587301850318909, 0.1526104360818863]\n",
      "weights [10, 10, 10, 1.0068550096877193, 3.7900618945151443, 10, 1.9699960727264747, 2.570305862391523, 2.266182049842273, 1.180093386190495]\n",
      "Episode: 4, Step: 61, Epsilon: 0.2923\n",
      "Episode: 4, Step: 61, Action: [5.00246996e-02 2.13599430e-04 2.04418200e-01 1.59265351e-02\n",
      " 3.05143736e-01 2.45164108e-02 2.57212343e-01 5.45970611e-02\n",
      " 3.50887829e-02 5.28586329e-02], Действие: случайное\n",
      "loss =  tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5107, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5734, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4559, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4467, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2174, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2413, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2123, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0508, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9314, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9821, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0822, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9464, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9104, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8137, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7832, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2335\n",
      "Reward: 4.3787\n",
      "Episode: 4, Step: 62, State: [1.0, 1.0, 1.0, 0.9970816969871521, 1.0, 1.0, 0.046700507402420044, 0.8844984769821167, 0.4021163880825043, 0.28313252329826355]\n",
      "weights [10, 10, 10, 10, 10, 10, 1.0489871848016903, 8.657819533908965, 1.6725635349484351, 1.3949560240128462]\n",
      "Episode: 4, Step: 62, Epsilon: 0.2911\n",
      "Episode: 4, Step: 62, Action: [1.8872742e-11 2.9197639e-07 8.4419631e-11 9.9999976e-01 2.1572886e-11\n",
      " 1.9389960e-11 2.8794517e-11 2.6618589e-11 5.2443866e-10 1.4134258e-10], Действие: агент\n",
      "loss =  tensor(0.1070, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1145, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1213, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1282, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1188, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1270, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1303, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1241, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0990, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0975, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0961, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0893, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0898, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0873, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0843, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0866, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1728\n",
      "Reward: 13.4013\n",
      "Episode: 4, Step: 63, State: [0.0, 1.0, 1.0, 0.7247081995010376, 0.9989929795265198, 1.0, 0.9664974808692932, 0.9949341416358948, 0.8582010865211487, 0.7690762877464294]\n",
      "weights [0.9999990000010001, 10, 10, 3.632496012200541, 10, 10, 10, 10, 7.052190480702547, 4.3304157023347685]\n",
      "Episode: 4, Step: 63, Epsilon: 0.2899\n",
      "Episode: 4, Step: 63, Action: [0.06782884 0.09569696 0.0372879  0.16273214 0.16775181 0.15189206\n",
      " 0.09878139 0.17870419 0.02441693 0.01490778], Действие: случайное\n",
      "loss =  tensor(1.3081, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3470, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3168, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1906, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2560, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1804, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2533, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2908, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9653, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9274, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9085, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7444, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7407, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8222, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7920, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7799, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3973\n",
      "Reward: 17.8160\n",
      "Episode: 4, Step: 64, State: [0.0, 0.9980158805847168, 0.9772502183914185, 0.0, 0.9959717988967896, 0.993034839630127, 0.9756345152854919, 0.5542046427726746, 0.31216931343078613, 0.2439759075641632]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 10, 2.2431766966863504, 1.453844042846918, 1.3227074206996232]\n",
      "Episode: 4, Step: 64, Epsilon: 0.2887\n",
      "Episode: 4, Step: 64, Action: [1.2079366e-09 7.9317874e-07 3.5671366e-09 9.9999917e-01 1.2214553e-09\n",
      " 1.2172249e-09 1.8612683e-09 1.3486230e-09 1.4116724e-08 5.2294533e-09], Действие: агент\n",
      "loss =  tensor(0.1059, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1105, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1145, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1053, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1071, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1107, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1140, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1117, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0972, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0912, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0944, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0917, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0883, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0843, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0878, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0888, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3199\n",
      "Reward: 10.1144\n",
      "Episode: 4, Step: 65, State: [0.0, 0.988095223903656, 0.5934718251228333, 0.37062257528305054, 0.8912386894226074, 0.9014925360679626, 0.9258882999420166, 0.5896656513214111, 0.8359788656234741, 0.7520080208778381]\n",
      "weights [0.9999990000010001, 10, 2.4598480546990293, 1.5888692092515408, 9.19436149058662, 10, 10, 2.4370310849901675, 6.096738125016836, 4.032372220938552]\n",
      "Episode: 4, Step: 65, Epsilon: 0.2875\n",
      "Episode: 4, Step: 65, Action: [1.2467967e-10 2.2968906e-07 4.2428638e-10 9.9999976e-01 1.2934871e-10\n",
      " 1.1648120e-10 2.0734742e-10 1.6082485e-10 2.1065778e-09 5.7277877e-10], Действие: агент\n",
      "loss =  tensor(0.1075, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0943, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0956, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0916, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0988, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0913, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0890, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0903, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0804, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0807, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0802, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0747, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0772, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0759, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0712, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0712, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4593\n",
      "Reward: 16.7403\n",
      "Episode: 4, Step: 66, State: [0.0, 0.550595223903656, 1.0, 0.0, 1.0, 0.9820895791053772, 0.7939086556434631, 0.3333333432674408, 0.5724867582321167, 0.2098393589258194]\n",
      "weights [0.9999990000010001, 2.2251605412958004, 10, 0.9999990000010001, 10, 10, 4.852193821765713, 1.49999777235505, 2.3391033614803995, 1.2655638391159507]\n",
      "Episode: 4, Step: 66, Epsilon: 0.2863\n",
      "Episode: 4, Step: 66, Action: [5.3785296e-09 2.8866850e-06 1.2990800e-08 9.9999702e-01 5.6494591e-09\n",
      " 5.2595310e-09 7.8958982e-09 6.3946834e-09 4.0223615e-08 1.8332479e-08], Действие: агент\n",
      "loss =  tensor(0.0782, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0756, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0749, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0752, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0738, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0743, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0718, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0702, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0664, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0678, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0658, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0668, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0636, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0638, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0625, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0631, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4773\n",
      "Reward: 7.8860\n",
      "Episode: 4, Step: 67, State: [0.00671785045415163, 0.4335317313671112, 0.9990108609199524, 0.0, 0.9969788789749146, 0.9691542387008667, 0.7299492359161377, 0.2917933166027069, 0.5925925970077515, 0.24297188222408295]\n",
      "weights [1.0067622716213627, 1.7653208309311992, 10, 0.9999990000010001, 10, 10, 3.702993770073868, 1.4120151806359549, 2.454539456367144, 1.320953152948607]\n",
      "Episode: 4, Step: 67, Epsilon: 0.2852\n",
      "Episode: 4, Step: 67, Action: [8.8073655e-09 5.1604998e-06 2.0546596e-08 9.9999475e-01 9.4316732e-09\n",
      " 8.5831333e-09 1.2940990e-08 1.0739840e-08 6.0036875e-08 2.8826729e-08], Действие: агент\n",
      "loss =  tensor(0.0673, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0671, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0633, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0636, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0666, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0635, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0617, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0651, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0608, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0587, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0575, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0596, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0578, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0569, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0588, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0563, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.5126\n",
      "Reward: 9.7785\n",
      "Episode: 4, Step: 68, State: [0.04030710086226463, 0.2876984179019928, 0.9821958541870117, 0.0, 0.9133937358856201, 0.8905472755432129, 0.5472081303596497, 0.21479229629039764, 0.6857143044471741, 0.34939759969711304]\n",
      "weights [1.0419989132977492, 1.4038977607726935, 10, 0.9999990000010001, 10, 9.136281154094533, 2.208515343437921, 1.2735467593209906, 3.1818082475333993, 1.5370346966131012]\n",
      "Episode: 4, Step: 68, Epsilon: 0.2840\n",
      "Episode: 4, Step: 68, Action: [2.5527765e-08 2.0303647e-05 5.5895978e-08 9.9997938e-01 2.7855483e-08\n",
      " 2.3916069e-08 3.7478358e-08 3.2349739e-08 1.4424997e-07 7.7280106e-08], Действие: агент\n",
      "loss =  tensor(0.0576, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0581, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0583, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0555, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0569, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0583, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0552, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0554, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0542, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0543, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0536, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0532, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0513, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0506, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0525, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0496, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4946\n",
      "Reward: 8.6580\n",
      "Episode: 4, Step: 69, State: [0.04606525972485542, 0.4285714328289032, 0.9861523509025574, 0.0, 0.9164149165153503, 0.8945273756980896, 0.5583756566047668, 0.19452887773513794, 0.7037037014961243, 0.3624497950077057]\n",
      "weights [1.048288640188247, 1.7499969505438298, 10, 0.9999990000010001, 10, 9.48104330934504, 2.2643628019894884, 1.2415078962486694, 3.374988584267904, 1.5685014665011674]\n",
      "Episode: 4, Step: 69, Epsilon: 0.2828\n",
      "Episode: 4, Step: 69, Action: [1.6602415e-08 1.3448708e-05 3.7660197e-08 9.9998629e-01 1.7685826e-08\n",
      " 1.5401184e-08 2.4572749e-08 2.0651797e-08 1.0100252e-07 5.1991247e-08], Действие: агент\n",
      "loss =  tensor(0.0540, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0530, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0507, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0524, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0501, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0505, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0513, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0507, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0488, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0494, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0473, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0480, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0470, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0488, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0457, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0471, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.5057\n",
      "Reward: 9.4329\n",
      "Episode: 4, Step: 70, State: [0.03262955695390701, 0.3819444477558136, 0.9693372845649719, 0.0, 0.9083585143089294, 0.8895522356033325, 0.5644670128822327, 0.20060789585113525, 0.6835978627204895, 0.34939759969711304]\n",
      "weights [1.0337290884369763, 1.6179749189114858, 10, 0.9999990000010001, 10, 9.053971816367124, 2.296032065413996, 1.2509489946935766, 3.1605249195636143, 1.5370346966131012]\n",
      "Episode: 4, Step: 70, Epsilon: 0.2817\n",
      "Episode: 4, Step: 70, Action: [2.2718121e-08 1.8454022e-05 5.0441493e-08 9.9998128e-01 2.4331229e-08\n",
      " 2.1093342e-08 3.3339916e-08 2.8282164e-08 1.3094713e-07 6.9278457e-08], Действие: агент\n",
      "loss =  tensor(0.0472, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0475, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0491, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0478, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0478, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0479, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0469, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0475, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0462, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0467, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0447, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0449, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0449, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0435, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0432, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0422, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.51\n",
      "Reward: 9.8139\n",
      "accuracy =  0.3384\n",
      "--------------------------------------\n",
      "Episode: 4, Step: 70, Test Accuracy: 0.3384\n",
      "--------------------------------------\n",
      "Episode: 4, Step: 71, State: [0.03934741020202637, 0.4216269850730896, 0.9554896354675293, 0.0, 0.8851963877677917, 0.8636816143989563, 0.5015228390693665, 0.19250252842903137, 0.7015873193740845, 0.3755020201206207]\n",
      "weights [1.040957958852057, 1.728985006572902, 10, 0.9999990000010001, 8.710451440551546, 7.335713813489662, 2.006105940795983, 1.2383924368977743, 3.3510527999337167, 1.601283640516351]\n",
      "Episode: 4, Step: 71, Epsilon: 0.2805\n",
      "Episode: 4, Step: 71, Action: [0.13065442 0.1819444  0.01081168 0.02740115 0.15823684 0.2482161\n",
      " 0.0414494  0.00503201 0.10787993 0.08837407], Действие: случайное\n",
      "loss =  tensor(1.3932, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4500, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2463, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2336, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2616, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2027, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1668, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2106, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9786, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9496, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7784, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8405, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8264, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7946, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6807, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3329\n",
      "Reward: 16.0964\n",
      "Episode: 4, Step: 72, State: [1.0, 1.0, 0.997032642364502, 0.7626459002494812, 0.22356495261192322, 0.23084576427936554, 0.796954333782196, 0.9918946027755737, 0.5259259343147278, 0.11445783078670502]\n",
      "weights [10, 10, 10, 4.213096752718136, 1.2879360809740739, 1.3001276641679274, 4.924976206835726, 10, 2.1093705878720006, 1.1292504247854873]\n",
      "Episode: 4, Step: 72, Epsilon: 0.2793\n",
      "Episode: 4, Step: 72, Action: [2.5519437e-10 2.6448472e-06 7.5610795e-10 9.9999738e-01 2.6847277e-10\n",
      " 2.1791739e-10 3.0427985e-10 2.9042785e-10 2.9235876e-09 1.1722450e-09], Действие: агент\n",
      "loss =  tensor(0.0657, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0691, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0702, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0688, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0711, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0738, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0747, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0712, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0658, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0662, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0633, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0638, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0617, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0630, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0608, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0583, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.5072\n",
      "Reward: 23.7018\n",
      "Episode: 4, Step: 73, State: [0.0, 0.7470238208770752, 0.7843719124794006, 0.0009727626456879079, 0.5639476180076599, 0.49253731966018677, 0.8558375835418701, 0.935157060623169, 0.3629629611968994, 0.21787148714065552]\n",
      "weights [0.9999990000010001, 3.9529257281902392, 4.637593246340054, 1.0009727078868775, 2.2932972000606258, 1.9705843762658428, 6.936572568606094, 10, 1.5697649733426449, 1.2785606265440037]\n",
      "Episode: 4, Step: 73, Epsilon: 0.2782\n",
      "Episode: 4, Step: 73, Action: [2.6110552e-08 2.8491861e-05 6.1619616e-08 9.9997115e-01 2.6415664e-08\n",
      " 2.2755184e-08 3.5692093e-08 2.8302706e-08 1.7270081e-07 8.7277300e-08], Действие: агент\n",
      "loss =  tensor(0.0717, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0659, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0663, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0642, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0624, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0643, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0610, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0605, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0576, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0556, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0554, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0561, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0526, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0539, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0547, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0503, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4401\n",
      "Reward: 8.6319\n",
      "Episode: 4, Step: 74, State: [0.0, 0.7876983880996704, 0.9910979270935059, 0.0, 0.9466263651847839, 0.8318408131599426, 0.7878172397613525, 0.8368794322013855, 0.305820107460022, 0.13654617965221405]\n",
      "weights [0.9999990000010001, 4.710257641434357, 10, 0.9999990000010001, 10, 5.9467108046872745, 4.712896024065552, 6.1303971847216, 1.4405467087131179, 1.1581381867753264]\n",
      "Episode: 4, Step: 74, Epsilon: 0.2771\n",
      "Episode: 4, Step: 74, Action: [2.7725227e-09 1.7215864e-06 7.5056841e-09 9.9999821e-01 2.8390614e-09\n",
      " 2.6744784e-09 4.1062540e-09 3.1296343e-09 2.5309204e-08 1.1014885e-08], Действие: агент\n",
      "loss =  tensor(0.0572, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0527, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0570, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0547, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0535, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0549, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0532, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0504, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0487, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0487, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0492, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0501, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0474, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0471, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0461, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0472, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4731\n",
      "Reward: 10.1689\n",
      "Episode: 4, Step: 75, State: [0.0009596928721293807, 0.5089285969734192, 0.9910979270935059, 0.0, 0.9566968679428101, 0.8407959938049316, 0.7746192812919617, 0.7841945290565491, 0.31111112236976624, 0.12751004099845886]\n",
      "weights [1.000959612846125, 2.036359595523579, 10, 0.9999990000010001, 10, 6.281209516582253, 4.436917092177337, 4.633781348762411, 1.451610819772789, 1.1461436817000112]\n",
      "Episode: 4, Step: 75, Epsilon: 0.2759\n",
      "Episode: 4, Step: 75, Action: [0.05683997 0.05521517 0.05616477 0.02789232 0.04166976 0.14234431\n",
      " 0.10195342 0.09944544 0.2541286  0.16434624], Действие: случайное\n",
      "loss =  tensor(1.7345, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6381, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6004, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5402, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7057, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5004, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5063, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5129, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1247, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0318, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1409, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8991, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9972, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9343, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8521, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8692, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3491\n",
      "Reward: 3.8601\n",
      "Episode: 4, Step: 76, State: [0.002879078732803464, 0.9990079402923584, 1.0, 0.0, 1.0, 1.0, 0.9989847540855408, 0.9868287444114685, 0.5248677134513855, 0.03614457696676254]\n",
      "weights [1.002886385978904, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 2.104672579907075, 1.037498922145499]\n",
      "Episode: 4, Step: 76, Epsilon: 0.2748\n",
      "Episode: 4, Step: 76, Action: [1.12368136e-10 3.63468118e-08 3.27278399e-10 1.00000000e+00\n",
      " 1.09088058e-10 1.06786885e-10 1.64360137e-10 1.22037283e-10\n",
      " 1.35432332e-09 4.75091355e-10], Действие: агент\n",
      "loss =  tensor(0.1047, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0841, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0901, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0969, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0854, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0840, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0858, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0805, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0753, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0659, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0701, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0641, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0637, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0629, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0612, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0589, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.417\n",
      "Reward: 16.8406\n",
      "Episode: 4, Step: 77, State: [0.5978886485099792, 0.2757936418056488, 1.0, 0.09241244941949844, 0.9476334452629089, 0.9104477763175964, 0.7228426337242126, 0.847011148929596, 0.12380952388048172, 0.30321285128593445]\n",
      "weights [2.4868671561430937, 1.3808199940045844, 10, 1.1018208629454296, 10, 10, 3.6080455136069998, 6.536381289369399, 1.141303045344387, 1.4351564415174354]\n",
      "Episode: 4, Step: 77, Epsilon: 0.2737\n",
      "Episode: 4, Step: 77, Action: [1.2197554e-09 3.0741671e-06 3.3700245e-09 9.9999690e-01 1.5171648e-09\n",
      " 1.2451682e-09 1.8033075e-09 1.6292706e-09 1.3342949e-08 5.5831078e-09], Действие: агент\n",
      "loss =  tensor(0.0642, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0642, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0668, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0636, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0619, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0625, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0627, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0617, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0578, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0544, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0548, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0518, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0520, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0509, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0510, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0497, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4866\n",
      "Reward: 10.3243\n",
      "Episode: 4, Step: 78, State: [0.24280230700969696, 0.0912698432803154, 0.9980217814445496, 0.0, 0.921450138092041, 0.869651734828949, 0.7888324856758118, 0.8186423778533936, 0.16825397312641144, 0.24799196422100067]\n",
      "weights [1.3206573245006992, 1.1004354726977508, 10, 0.9999990000010001, 10, 7.671696489333856, 4.735554460854845, 5.513936906686583, 1.2022886378792947, 1.329771255958526]\n",
      "Episode: 4, Step: 78, Epsilon: 0.2726\n",
      "Episode: 4, Step: 78, Action: [7.2359061e-09 8.4403682e-06 1.7252349e-08 9.9999142e-01 8.8092849e-09\n",
      " 7.3670061e-09 1.0427617e-08 9.2939763e-09 5.3823509e-08 2.6807845e-08], Действие: агент\n",
      "loss =  tensor(0.0534, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0540, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0534, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0524, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0521, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0538, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0521, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0524, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0509, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0487, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0484, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0476, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0459, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0456, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0462, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0447, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.504\n",
      "Reward: 9.7691\n",
      "Episode: 4, Step: 79, State: [0.03550863638520241, 0.2003968209028244, 0.9594460725784302, 0.0, 0.8932527899742126, 0.8328357934951782, 0.8121827244758606, 0.8226950168609619, 0.2518518567085266, 0.17771084606647491]\n",
      "weights [1.0368148444971863, 1.2506187763164134, 10, 0.9999990000010001, 9.367838577887426, 5.982106090786037, 5.324295504307698, 5.639967598926595, 1.3366318854560357, 1.2161157411606818]\n",
      "Episode: 4, Step: 79, Epsilon: 0.2715\n",
      "Episode: 4, Step: 79, Action: [1.2210566e-08 9.1718575e-06 2.7994760e-08 9.9999070e-01 1.3990995e-08\n",
      " 1.2104178e-08 1.7241941e-08 1.4847728e-08 7.9531674e-08 4.1360636e-08], Действие: агент\n",
      "loss =  tensor(0.0492, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0473, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0478, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0468, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0461, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0470, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0469, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0446, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0443, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0450, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0434, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0438, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0438, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0418, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0428, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0414, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.5032\n",
      "Reward: 9.3580\n",
      "Episode: 4, Step: 80, State: [0.03742802143096924, 0.1835317462682724, 0.937685489654541, 0.0, 0.903323233127594, 0.8358209133148193, 0.8335025310516357, 0.8308004140853882, 0.30158731341362, 0.13353413343429565]\n",
      "weights [1.0388822689440218, 1.224785863557547, 10, 0.9999990000010001, 10, 6.09087265203803, 6.006061234774041, 5.910145018674205, 1.4318161559629168, 1.1541122212365287]\n",
      "Episode: 4, Step: 80, Epsilon: 0.2704\n",
      "Episode: 4, Step: 80, Action: [1.1094183e-08 7.4083750e-06 2.4867491e-08 9.9999249e-01 1.2632216e-08\n",
      " 1.0899564e-08 1.5432157e-08 1.3440667e-08 7.0372906e-08 3.6543540e-08], Действие: агент\n",
      "loss =  tensor(0.0408, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0425, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0422, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0423, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0428, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0410, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0420, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0421, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0399, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0394, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0407, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0402, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0384, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0381, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0383, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0391, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4851\n",
      "Reward: 8.7996\n",
      "accuracy =  0.3518\n",
      "--------------------------------------\n",
      "Episode: 4, Step: 80, Test Accuracy: 0.3518\n",
      "--------------------------------------\n",
      "Episode: 4, Step: 81, State: [0.012476007454097271, 0.3144841194152832, 0.9545004963874817, 0.0, 0.9335347414016724, 0.8487561941146851, 0.8477157354354858, 0.8358662724494934, 0.2899470925331116, 0.1405622512102127]\n",
      "weights [1.012632599223576, 1.4587532828470138, 10, 0.9999990000010001, 10, 6.611797305345311, 6.56662351974547, 6.0925558833506805, 1.4083437743022806, 1.1635500510166001]\n",
      "Episode: 4, Step: 81, Epsilon: 0.2693\n",
      "Episode: 4, Step: 81, Action: [0.18975416 0.12314511 0.01932125 0.16981951 0.15171937 0.13530811\n",
      " 0.0322896  0.10537054 0.04324997 0.03002236], Действие: случайное\n",
      "loss =  tensor(1.1290, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0307, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1789, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2092, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1049, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1932, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9905, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1648, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6507, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8001, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7235, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7088, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7393, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6457, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6367, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5932, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2519\n",
      "Reward: 13.1248\n",
      "Episode: 4, Step: 82, State: [1.0, 0.64682537317276, 0.9980217814445496, 0.20525291562080383, 0.1419939547777176, 0.5552238821983337, 0.9969543218612671, 0.9584599733352661, 1.0, 0.9989959597587585]\n",
      "weights [10, 2.8314524673843415, 10, 1.2582603464607691, 1.1654915953993497, 2.2483171008044467, 10, 10, 10, 10]\n",
      "Episode: 4, Step: 82, Epsilon: 0.2682\n",
      "Episode: 4, Step: 82, Action: [4.8981765e-12 4.7571749e-08 1.3717089e-11 1.0000000e+00 5.6796763e-12\n",
      " 3.8324326e-12 6.7593353e-12 6.0589827e-12 6.3550207e-11 2.1641178e-11], Действие: агент\n",
      "loss =  tensor(0.0558, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0515, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0552, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0578, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0585, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0646, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0669, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0638, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0574, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0559, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0579, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0572, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0564, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0533, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0517, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0543, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4963\n",
      "Reward: 27.1357\n",
      "Episode: 4, Step: 83, State: [0.008637236431241035, 0.2311507910490036, 0.9020771384239197, 0.0, 0.5176233649253845, 0.5601990222930908, 0.8659898638725281, 0.4417426586151123, 0.8497354388237, 0.7168674468994141]\n",
      "weights [1.008711470752322, 1.300643465213308, 10, 0.9999990000010001, 2.0730646018555925, 2.273750575688442, 7.46206642893316, 1.7912853707107552, 6.654884806417776, 3.5319021325767785]\n",
      "Episode: 4, Step: 83, Epsilon: 0.2671\n",
      "Episode: 4, Step: 83, Action: [9.0415133e-09 1.0130038e-05 1.8896392e-08 9.9998975e-01 1.0068257e-08\n",
      " 7.7347373e-09 1.3054118e-08 1.1424966e-08 4.6529053e-08 2.5366887e-08], Действие: агент\n",
      "loss =  tensor(0.0567, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0583, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0583, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0575, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0591, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0553, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0566, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0569, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0559, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0517, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0488, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0447, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0499, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0466, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0456, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0460, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4601\n",
      "Reward: 11.6085\n",
      "Episode: 4, Step: 84, State: [0.0, 0.79067462682724, 0.9980217814445496, 0.0, 0.9566968679428101, 0.839801013469696, 0.8131979703903198, 0.3394123613834381, 0.4719576835632324, 0.21787148714065552]\n",
      "weights [0.9999990000010001, 4.777228902612696, 10, 0.9999990000010001, 10, 6.242197778280317, 5.353232236594196, 1.51380139097495, 1.8937840303481022, 1.2785606265440037]\n",
      "Episode: 4, Step: 84, Epsilon: 0.2660\n",
      "Episode: 4, Step: 84, Action: [0.01460559 0.0235107  0.13905519 0.01836555 0.12707245 0.02205545\n",
      " 0.48305778 0.06179236 0.03909436 0.07139058], Действие: случайное\n",
      "loss =  tensor(1.8035, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9967, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8034, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.9936, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4906, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5690, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5954, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5604, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1714, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0785, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1570, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0684, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2438, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9893, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8855, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8576, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2961\n",
      "Reward: 6.9429\n",
      "Episode: 4, Step: 85, State: [1.0, 1.0, 1.0, 0.011673151515424252, 0.9053373336791992, 0.9512437582015991, 0.4406091272830963, 0.8125633001327515, 0.9164021015167236, 0.009036144241690636]\n",
      "weights [10, 10, 10, 1.0118099996203904, 10, 10, 1.7876555752287067, 5.335106015002548, 10, 1.0091175223714435]\n",
      "Episode: 4, Step: 85, Epsilon: 0.2649\n",
      "Episode: 4, Step: 85, Action: [3.4388332e-11 8.4765055e-08 9.3314356e-11 9.9999988e-01 3.3902232e-11\n",
      " 2.7508119e-11 4.6275615e-11 3.9712612e-11 4.0689604e-10 1.4227927e-10], Действие: агент\n",
      "loss =  tensor(0.1267, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1309, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1187, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1190, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1060, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1074, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0971, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0961, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0740, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0756, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0700, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0692, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0673, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0671, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0629, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0603, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4032\n",
      "Reward: 17.9580\n",
      "Episode: 4, Step: 86, State: [0.0, 0.9851190447807312, 1.0, 0.0019455252913758159, 1.0, 1.0, 0.4629441499710083, 0.9848024249076843, 0.5206349492073059, 0.04417670518159866]\n",
      "weights [0.9999990000010001, 10, 10, 1.0019483138369072, 10, 10, 1.8620002704481238, 10, 2.086088487798354, 1.046217391021633]\n",
      "Episode: 4, Step: 86, Epsilon: 0.2638\n",
      "Episode: 4, Step: 86, Action: [0.06340057 0.11409569 0.04860826 0.22357322 0.00699105 0.07899764\n",
      " 0.02372009 0.03504946 0.12315993 0.28240408], Действие: случайное\n",
      "loss =  tensor(1.1773, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1001, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9976, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9828, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0041, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8059, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9632, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8857, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6227, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7245, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6497, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6394, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6598, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6381, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6463, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5775, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1732\n",
      "Reward: 2.9029\n",
      "Episode: 4, Step: 87, State: [0.9990403056144714, 1.0, 1.0, 0.8939688801765442, 0.9879153966903687, 0.9970149397850037, 0.989847719669342, 0.9989868402481079, 0.14074073731899261, 0.2128514051437378]\n",
      "weights [10, 10, 10, 9.431104477256577, 10, 10, 10, 10, 1.1637917444010104, 1.2704065485577813]\n",
      "Episode: 4, Step: 87, Epsilon: 0.2628\n",
      "Episode: 4, Step: 87, Action: [1.6039585e-12 1.3694628e-08 6.9065743e-12 1.0000000e+00 1.8949135e-12\n",
      " 1.7529028e-12 2.3005244e-12 2.1034311e-12 4.7422559e-11 1.1630401e-11], Действие: агент\n",
      "loss =  tensor(0.0772, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0841, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0845, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0751, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0735, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0772, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0697, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0735, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0612, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0621, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0609, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0592, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0579, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0565, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0575, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0569, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3716\n",
      "Reward: 22.5513\n",
      "Episode: 4, Step: 88, State: [0.0, 0.9960317611694336, 0.9901087880134583, 0.0, 0.9959717988967896, 0.9791044592857361, 0.9583756327629089, 0.9604862928390503, 0.35767194628715515, 0.07630521804094315]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 1.5568344514695625, 1.0826075202802272]\n",
      "Episode: 4, Step: 88, Epsilon: 0.2617\n",
      "Episode: 4, Step: 88, Action: [0.00654781 0.14720597 0.1310938  0.18208941 0.08918613 0.14041504\n",
      " 0.09801091 0.03873063 0.11108648 0.05563382], Действие: случайное\n",
      "loss =  tensor(1.0146, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0318, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0472, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1124, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1468, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1158, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9988, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1336, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7857, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7651, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7077, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6621, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5961, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6601, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6267, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5766, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4673\n",
      "Reward: 18.9059\n",
      "Episode: 4, Step: 89, State: [0.0, 0.9980158805847168, 0.9040554165840149, 0.002918287878856063, 0.8066465258598328, 0.5233830809593201, 0.5076141953468323, 0.7223910689353943, 0.3216931223869324, 0.5622490048408508]\n",
      "weights [0.9999990000010001, 10, 10, 1.0029258233478444, 5.1718482566639565, 2.098116667566267, 2.0309236367623416, 3.6021766086144766, 1.474256798430458, 2.2843984974561677]\n",
      "Episode: 4, Step: 89, Epsilon: 0.2607\n",
      "Episode: 4, Step: 89, Action: [1.1789688e-08 2.4605532e-05 3.3738633e-08 9.9997520e-01 1.1935352e-08\n",
      " 1.0431686e-08 1.9050823e-08 1.3803932e-08 1.0241970e-07 4.7708504e-08], Действие: агент\n",
      "loss =  tensor(0.0673, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0731, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0750, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0760, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0775, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0746, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0761, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0763, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0681, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0636, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0653, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0623, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0614, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0616, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0585, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0613, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4155\n",
      "Reward: 8.3124\n",
      "Episode: 4, Step: 90, State: [0.0, 0.8402777910232544, 0.9693372845649719, 0.21692606806755066, 0.9496475458145142, 0.8358209133148193, 0.6000000238418579, 0.7487335205078125, 0.15343914926052094, 0.5391566157341003]\n",
      "weights [0.9999990000010001, 6.260830886171288, 10, 1.2770169995510254, 10, 6.09087265203803, 2.4999938990265007, 3.979822625757236, 1.1812485988194381, 2.169929881196114]\n",
      "Episode: 4, Step: 90, Epsilon: 0.2596\n",
      "Episode: 4, Step: 90, Action: [0.11301217 0.13579425 0.03425323 0.00729261 0.02179637 0.37712896\n",
      " 0.127869   0.02285654 0.03759193 0.12240494], Действие: случайное\n",
      "loss =  tensor(1.1699, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2207, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3155, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1042, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1639, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1384, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0453, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0773, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8138, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9375, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8017, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7469, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7733, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7280, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7068, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6966, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2806\n",
      "Reward: 9.6996\n",
      "accuracy =  0.177\n",
      "--------------------------------------\n",
      "Episode: 4, Step: 90, Test Accuracy: 0.1770\n",
      "--------------------------------------\n",
      "Episode: 4, Step: 91, State: [1.0, 1.0, 1.0, 0.9990272521972656, 0.9979858994483948, 0.23980098962783813, 0.15736040472984314, 0.7507598996162415, 0.8306878209114075, 0.19377510249614716]\n",
      "weights [10, 10, 10, 10, 10, 1.3154432864456844, 1.1867455776675375, 4.012179365523149, 5.906214775382331, 1.2403471571628857]\n",
      "Episode: 4, Step: 91, Epsilon: 0.2586\n",
      "Episode: 4, Step: 91, Action: [8.4683656e-11 1.7858321e-06 3.0323374e-10 9.9999821e-01 9.0058669e-11\n",
      " 7.5410338e-11 1.2332403e-10 1.1645369e-10 1.3991465e-09 4.4165382e-10], Действие: агент\n",
      "loss =  tensor(0.0970, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0961, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0957, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0851, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0856, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0839, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0873, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0891, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0757, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0705, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0713, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0707, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0678, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0715, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0680, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0644, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.5156\n",
      "Reward: 33.9753\n",
      "Episode: 4, Step: 92, State: [0.002879078732803464, 0.3164682686328888, 0.9159248471260071, 0.04474708065390587, 0.8298086524009705, 0.6388059854507446, 0.6720812320709229, 0.8429584503173828, 0.5989418029785156, 0.024096384644508362]\n",
      "weights [1.002886385978904, 1.4629877313993918, 10, 1.0468420801503082, 5.875704836952975, 2.7685874935121295, 3.0495264323811098, 6.367700995819279, 2.4933975019813124, 1.0246903070908535]\n",
      "Episode: 4, Step: 92, Epsilon: 0.2575\n",
      "Episode: 4, Step: 92, Action: [1.5698072e-08 8.8174647e-06 3.2268773e-08 9.9999106e-01 1.6496875e-08\n",
      " 1.3908040e-08 2.0628431e-08 1.8183808e-08 7.9242035e-08 4.5229271e-08], Действие: агент\n",
      "loss =  tensor(0.0745, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0722, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0732, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0675, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0699, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0684, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0741, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0691, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0627, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0627, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0591, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0613, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0588, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0553, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0565, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0555, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3581\n",
      "Reward: 5.0809\n",
      "Episode: 4, Step: 93, State: [0.0, 0.983134925365448, 1.0, 0.11186770349740982, 0.9989929795265198, 0.9791044592857361, 0.9086294174194336, 0.8956433534622192, 0.5513227581977844, 0.02610441856086254]\n",
      "weights [0.9999990000010001, 10, 10, 1.1259571101972343, 10, 10, 10, 9.582431505275164, 2.2287686516361447, 1.0268030703242528]\n",
      "Episode: 4, Step: 93, Epsilon: 0.2565\n",
      "Episode: 4, Step: 93, Action: [1.4322626e-10 5.0729867e-08 3.9534426e-10 1.0000000e+00 1.3728299e-10\n",
      " 1.3279328e-10 2.0131141e-10 1.5399441e-10 1.4142492e-09 5.6041832e-10], Действие: агент\n",
      "loss =  tensor(0.0633, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0617, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0593, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0580, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0608, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0588, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0583, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0576, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0553, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0518, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0526, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0527, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0519, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0539, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0498, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0487, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4245\n",
      "Reward: 12.2616\n",
      "Episode: 4, Step: 94, State: [0.0, 0.7658730149269104, 0.97230464220047, 0.0, 0.9577039480209351, 0.8437811136245728, 0.7939086556434631, 0.8338398933410645, 0.6074073910713196, 0.02208835259079933]\n",
      "weights [0.9999990000010001, 4.271168180462587, 10, 0.9999990000010001, 10, 6.401233691828469, 4.852193821765713, 6.018255535891519, 2.54716321727403, 1.022586222449741]\n",
      "Episode: 4, Step: 94, Epsilon: 0.2555\n",
      "Episode: 4, Step: 94, Action: [0.1218914  0.08480167 0.12818025 0.07998644 0.27278449 0.01506005\n",
      " 0.07214089 0.05083851 0.17364133 0.00067495], Действие: случайное\n",
      "loss =  tensor(1.3107, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1841, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2521, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1775, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1623, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1496, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1566, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1804, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8488, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8383, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7127, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7418, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6611, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7146, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6123, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6753, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3126\n",
      "Reward: 17.9935\n",
      "Episode: 4, Step: 95, State: [0.9913627505302429, 0.8680555820465088, 0.9584569931030273, 0.9445525407791138, 0.02215508557856083, 0.772139310836792, 0.6162436604499817, 0.6656534671783447, 0.46984127163887024, 0.522088348865509]\n",
      "weights [10, 7.5788914500425095, 10, 10, 1.0226560087349434, 4.388627169720229, 2.605813353752578, 2.990899892577976, 1.8862239934581155, 2.0924325765935556]\n",
      "Episode: 4, Step: 95, Epsilon: 0.2544\n",
      "Episode: 4, Step: 95, Action: [1.2543240e-10 2.5057852e-06 3.7794354e-10 9.9999750e-01 1.3948337e-10\n",
      " 1.0902830e-10 1.4680823e-10 1.4821047e-10 1.2616574e-09 5.8006439e-10], Действие: агент\n",
      "loss =  tensor(0.0784, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0802, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0761, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0813, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0811, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0731, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0786, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0810, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0710, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0661, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0649, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0658, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0647, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0625, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0634, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0597, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3414\n",
      "Reward: 22.9117\n",
      "Episode: 4, Step: 96, State: [0.0, 0.9682539701461792, 1.0, 0.0, 1.0, 1.0, 0.9969543218612671, 0.9918946027755737, 0.048677247017621994, 0.5963855385780334]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 1.051166857618159, 2.477605779711529]\n",
      "Episode: 4, Step: 96, Epsilon: 0.2534\n",
      "Episode: 4, Step: 96, Action: [1.04901747e-10 1.02011825e-07 3.56328134e-10 9.99999881e-01\n",
      " 1.13384954e-10 1.06256989e-10 1.75027839e-10 1.22553703e-10\n",
      " 1.53586155e-09 5.44324086e-10], Действие: агент\n",
      "loss =  tensor(0.0689, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0681, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0646, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0637, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0647, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0704, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0648, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0648, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0603, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0570, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0533, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0536, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0540, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0527, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0547, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0546, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3363\n",
      "Reward: 4.2658\n",
      "Episode: 4, Step: 97, State: [0.0, 0.995039701461792, 1.0, 0.0, 1.0, 1.0, 0.9857867956161499, 0.978723406791687, 0.033862434327602386, 0.6586345434188843]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 1.035048217233763, 2.9294032284697527]\n",
      "Episode: 4, Step: 97, Epsilon: 0.2524\n",
      "Episode: 4, Step: 97, Action: [9.3931855e-11 1.0161450e-07 3.2657124e-10 9.9999988e-01 1.0189577e-10\n",
      " 9.5261229e-11 1.5950882e-10 1.1053426e-10 1.4292395e-09 4.9922172e-10], Действие: агент\n",
      "loss =  tensor(0.0583, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0544, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0574, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0543, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0532, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0549, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0533, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0541, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0512, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0488, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0496, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0492, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0483, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0474, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0470, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0462, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3834\n",
      "Reward: 9.7476\n",
      "Episode: 4, Step: 98, State: [0.0, 0.9642857313156128, 0.9782393574714661, 0.0, 0.9728096723556519, 0.9084576964378357, 0.7472081184387207, 0.8277608752250671, 0.02539682574570179, 0.7520080208778381]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 3.955807591669036, 5.805848093216988, 1.026057579493883, 4.032372220938552]\n",
      "Episode: 4, Step: 98, Epsilon: 0.2514\n",
      "Episode: 4, Step: 98, Action: [5.7092409e-10 9.8913586e-07 1.9365092e-09 9.9999905e-01 6.2158606e-10\n",
      " 5.6661298e-10 9.9510455e-10 6.9305917e-10 7.4626660e-09 2.8928571e-09], Действие: агент\n",
      "loss =  tensor(0.0510, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0482, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0467, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0480, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0483, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0484, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0513, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0441, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0463, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0444, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0451, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0428, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0423, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0443, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0436, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0404, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4511\n",
      "Reward: 13.3053\n",
      "Episode: 4, Step: 99, State: [0.0, 0.8323412537574768, 0.912957489490509, 0.0, 0.8912386894226074, 0.7552238702774048, 0.5857868194580078, 0.7173252105712891, 0.04126984253525734, 0.7620481848716736]\n",
      "weights [0.9999990000010001, 5.964460894229673, 10, 0.9999990000010001, 9.19436149058662, 4.085348991277475, 2.4142099594261044, 3.5376216761294086, 1.0430452710480258, 4.202513844859143]\n",
      "Episode: 4, Step: 99, Epsilon: 0.2504\n",
      "Episode: 4, Step: 99, Action: [6.0179630e-09 1.5751766e-05 1.8511052e-08 9.9998415e-01 6.6156072e-09\n",
      " 5.7823430e-09 1.0271793e-08 7.4310509e-09 5.9839486e-08 2.6928285e-08], Действие: агент\n",
      "loss =  tensor(0.0434, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0434, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0422, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0419, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0451, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0426, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0425, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0445, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0413, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0393, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0417, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0393, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0402, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0387, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0383, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0378, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4996\n",
      "Reward: 12.9575\n",
      "Episode: 4, Step: 100, State: [0.0, 0.7132936716079712, 0.8209693431854248, 0.0, 0.8046324253082275, 0.6597014665603638, 0.5289340019226074, 0.6565349698066711, 0.05079365149140358, 0.7791164517402649]\n",
      "weights [0.9999990000010001, 3.487877361239444, 5.585604343904998, 0.9999990000010001, 5.118530457509208, 2.9385876315854085, 2.1228402840389764, 2.9114960784829984, 1.053510596574299, 4.52725194169813]\n",
      "Episode: 4, Step: 100, Epsilon: 0.2494\n",
      "Episode: 4, Step: 100, Action: [3.1606088e-08 1.1348024e-04 8.9539867e-08 9.9988604e-01 3.5197189e-08\n",
      " 2.9616174e-08 5.2520534e-08 3.9378175e-08 2.5746112e-07 1.2779023e-07], Действие: агент\n",
      "loss =  tensor(0.0387, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0417, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0405, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0388, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0373, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0407, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0380, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0367, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0372, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0366, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0364, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0353, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0351, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0365, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0364, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0363, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.5072\n",
      "Reward: 10.1918\n",
      "accuracy =  0.3333\n",
      "--------------------------------------\n",
      "Episode: 4, Step: 100, Test Accuracy: 0.3333\n",
      "--------------------------------------\n",
      "Восстанавливаем лучшее состояние модели...\n",
      "Episode: 5, Step: 1, State: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "weights [np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815), np.float64(1.1111098765445815)]\n",
      "Episode: 5, Step: 1, Epsilon: 0.3771\n",
      "Episode: 5, Step: 1, Action: [0.04034444 0.00785628 0.02879176 0.34300478 0.19763031 0.01180063\n",
      " 0.05991139 0.25764067 0.01918591 0.03383383], Действие: случайное\n",
      "loss =  tensor(1.1929, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2636, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0290, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1821, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0791, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2072, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9054, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0831, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6918, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8377, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6550, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6688, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6188, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6711, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5707, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5302, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3088\n",
      "Reward: 3.3896\n",
      "Episode: 5, Step: 2, State: [0.0, 0.9484127163887024, 0.9910979270935059, 0.5437743067741394, 0.8358509540557861, 0.9482586979866028, 0.8913705348968506, 0.0678824707865715, 0.9576719403266907, 0.7650602459907532]\n",
      "weights [0.9999990000010001, 10, 10, 2.191892791123771, 6.091987329323371, 10, 9.205520744576173, 1.0728249344467526, 10, 4.256392230530774]\n",
      "Episode: 5, Step: 2, Epsilon: 0.3755\n",
      "Episode: 5, Step: 2, Action: [3.7784964e-10 1.1062888e-06 1.5376657e-09 9.9999893e-01 4.1155385e-10\n",
      " 4.2129508e-10 6.8558986e-10 5.1319132e-10 1.1761152e-08 2.1989817e-09], Действие: агент\n",
      "loss =  tensor(0.1458, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1421, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1374, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1377, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1363, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1493, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1374, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1339, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1133, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1124, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1139, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1123, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1112, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1096, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1058, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1050, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3449\n",
      "Reward: 6.9813\n",
      "Episode: 5, Step: 3, State: [0.0, 1.0, 1.0, 0.011673151515424252, 0.9959717988967896, 1.0, 0.9705584049224854, 0.10131712257862091, 0.908994734287262, 0.6134538054466248]\n",
      "weights [0.9999990000010001, 10, 10, 1.0118099996203904, 10, 10, 10, 1.1127383333829581, 10, 2.5870062287101088]\n",
      "Episode: 5, Step: 3, Epsilon: 0.3738\n",
      "Episode: 5, Step: 3, Action: [0.01950598 0.23398491 0.03871801 0.12627109 0.15182687 0.08468184\n",
      " 0.05492843 0.01388807 0.22959057 0.04660423], Действие: случайное\n",
      "loss =  tensor(1.6543, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.8008, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6520, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4775, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3780, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3737, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3441, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3167, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0354, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9275, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9907, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9744, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9635, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8762, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2064\n",
      "Reward: 11.3410\n",
      "Episode: 5, Step: 4, State: [1.0, 1.0, 1.0, 0.06517509371042252, 1.0, 1.0, 0.9868020415306091, 0.9878419637680054, 0.012698412872850895, 0.8544176816940308]\n",
      "weights [10, 10, 10, 1.0697178942859054, 10, 10, 10, 10, 1.0128607106255012, 6.868918854413815]\n",
      "Episode: 5, Step: 4, Epsilon: 0.3722\n",
      "Episode: 5, Step: 4, Action: [0.0064991  0.18694114 0.18646841 0.11064996 0.12464981 0.03829877\n",
      " 0.28021819 0.00672117 0.00119056 0.05836288], Действие: случайное\n",
      "loss =  tensor(1.5934, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5725, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5355, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4111, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3787, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2648, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2708, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3323, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1307, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9926, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9589, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9620, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8970, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9035, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9055, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9340, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2804\n",
      "Reward: 18.4554\n",
      "Episode: 5, Step: 5, State: [0.0, 0.9910714030265808, 0.9950544238090515, 0.0, 0.9093655347824097, 0.9840795993804932, 0.39289340376853943, 1.0, 1.0, 0.9839357137680054]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 1.647154484983167, 10, 10, 10]\n",
      "Episode: 5, Step: 5, Epsilon: 0.3706\n",
      "Episode: 5, Step: 5, Action: [5.8869472e-11 1.4410223e-07 2.7616220e-10 9.9999988e-01 6.4090913e-11\n",
      " 5.9445365e-11 1.2600004e-10 8.1416318e-11 2.9656952e-09 4.4070197e-10], Действие: агент\n",
      "loss =  tensor(0.2017, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1972, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2041, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2245, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2066, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2080, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1825, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1816, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1576, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1550, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1421, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1478, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1452, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1415, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1372, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1372, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2674\n",
      "Reward: 15.4939\n",
      "Episode: 5, Step: 6, State: [0.9366602897644043, 0.02876984141767025, 0.9040554165840149, 0.42315176129341125, 0.8479355573654175, 0.9582089781761169, 0.3634517788887024, 0.9989868402481079, 1.0, 0.8815261125564575]\n",
      "weights [10, 1.029621003366143, 10, 1.7335552045491118, 6.576116063417694, 10, 1.570970424336054, 10, 10, 8.440607301497002]\n",
      "Episode: 5, Step: 6, Epsilon: 0.3690\n",
      "Episode: 5, Step: 6, Action: [1.9057478e-11 2.2765354e-07 7.5723941e-11 9.9999976e-01 2.6496918e-11\n",
      " 1.9805834e-11 3.4601370e-11 3.2832355e-11 7.8683587e-10 1.3021759e-10], Действие: агент\n",
      "loss =  tensor(0.1463, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1542, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1453, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1365, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1397, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1407, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1328, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1360, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1197, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1167, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1150, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1136, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1094, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1104, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1092, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1089, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3431\n",
      "Reward: 12.9434\n",
      "Episode: 5, Step: 7, State: [0.9990403056144714, 0.0019841270986944437, 0.9910979270935059, 0.26459142565727234, 0.9617321491241455, 0.9661691784858704, 0.43045684695243835, 0.8490374684333801, 0.9417989253997803, 0.17469879984855652]\n",
      "weights [10, 1.0019870677065101, 10, 1.3597864848220802, 10, 10, 1.7557901255752013, 6.624116365207727, 10, 1.2116773708061113]\n",
      "Episode: 5, Step: 7, Epsilon: 0.3674\n",
      "Episode: 5, Step: 7, Action: [0.00759848 0.09299247 0.03732112 0.20987073 0.00203355 0.00865216\n",
      " 0.0076739  0.02729993 0.00837923 0.59817844], Действие: случайное\n",
      "loss =  tensor(1.5297, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3261, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3449, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4555, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2356, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0317, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2650, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9826, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8453, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6508, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7588, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7403, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7313, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8714, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7532, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9019, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2263\n",
      "Reward: 4.1639\n",
      "Episode: 5, Step: 8, State: [1.0, 1.0, 1.0, 0.01653696410357952, 0.9345418214797974, 0.9641790986061096, 0.9086294174194336, 0.93313068151474, 1.0, 0.001004016026854515]\n",
      "weights [10, 10, 10, 1.0168139998007217, 10, 10, 10, 10, 10, 1.0010040230780932]\n",
      "Episode: 5, Step: 8, Epsilon: 0.3658\n",
      "Episode: 5, Step: 8, Action: [1.24016734e-11 3.18786988e-08 4.70152979e-11 1.00000000e+00\n",
      " 1.32315868e-11 1.21238661e-11 1.95966490e-11 1.57365024e-11\n",
      " 5.50078039e-10 7.86612026e-11], Действие: агент\n",
      "loss =  tensor(0.1558, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1714, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1647, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1639, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1503, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1523, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1401, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1401, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1299, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1220, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1138, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1133, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1121, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1099, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1059, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1056, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2888\n",
      "Reward: 11.8754\n",
      "Episode: 5, Step: 9, State: [1.0, 0.0, 1.0, 0.14007781445980072, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]\n",
      "weights [10, 0.9999990000010001, 10, 1.1628945664161912, 10, 10, 10, 10, 10, 0.9999990000010001]\n",
      "Episode: 5, Step: 9, Epsilon: 0.3643\n",
      "Episode: 5, Step: 9, Action: [2.1841636e-11 4.4840736e-08 6.8933907e-11 1.0000000e+00 2.8594486e-11\n",
      " 2.3489037e-11 3.3749652e-11 3.3417463e-11 6.6888806e-10 1.1656301e-10], Действие: агент\n",
      "loss =  tensor(0.1207, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1190, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1121, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1146, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1087, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1060, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1035, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1067, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1008, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0996, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0928, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0938, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0912, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0905, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0894, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0891, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2955\n",
      "Reward: 3.1444\n",
      "Episode: 5, Step: 10, State: [0.9952015280723572, 0.0, 0.997032642364502, 0.08268482238054276, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]\n",
      "weights [10, 0.9999990000010001, 10, 1.0901366665037098, 10, 10, 10, 10, 10, 0.9999990000010001]\n",
      "Episode: 5, Step: 10, Epsilon: 0.3627\n",
      "Episode: 5, Step: 10, Action: [2.5204673e-11 4.7111421e-08 7.7790011e-11 1.0000000e+00 3.2767296e-11\n",
      " 2.6776453e-11 3.8866733e-11 3.8219230e-11 7.3377981e-10 1.3075870e-10], Действие: агент\n",
      "loss =  tensor(0.0920, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0948, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0916, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0912, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0917, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0872, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0872, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0854, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0831, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0827, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0807, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0793, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0785, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0810, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0773, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0762, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3054\n",
      "Reward: 3.4496\n",
      "accuracy =  0.294\n",
      "--------------------------------------\n",
      "Episode: 5, Step: 10, Test Accuracy: 0.2940\n",
      "--------------------------------------\n",
      "Episode: 5, Step: 11, State: [0.9683301448822021, 0.01686508022248745, 0.9950544238090515, 0.0, 1.0, 1.0, 1.0, 0.9989868402481079, 1.0, 0.0]\n",
      "weights [10, 1.0171533557906254, 10, 0.9999990000010001, 10, 10, 10, 10, 10, 0.9999990000010001]\n",
      "Episode: 5, Step: 11, Epsilon: 0.3611\n",
      "Episode: 5, Step: 11, Action: [0.07310843 0.09705902 0.17271372 0.14028065 0.02148184 0.03060274\n",
      " 0.05143877 0.01670977 0.00390536 0.39269969], Действие: случайное\n",
      "loss =  tensor(1.0492, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1398, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0628, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9672, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9361, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8943, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0328, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0343, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8856, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9054, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7703, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8214, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7215, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7818, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7454, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7605, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2738\n",
      "Reward: 9.3497\n",
      "Episode: 5, Step: 12, State: [1.0, 1.0, 1.0, 0.0, 0.9637462496757507, 0.9412935376167297, 0.5807106494903564, 0.8459979891777039, 0.932275116443634, 0.01004016026854515]\n",
      "weights [10, 10, 10, 0.9999990000010001, 10, 10, 2.3849821461059366, 6.49337954277984, 10, 1.0101409670621602]\n",
      "Episode: 5, Step: 12, Epsilon: 0.3596\n",
      "Episode: 5, Step: 12, Action: [5.5234650e-11 1.5487331e-07 1.9645233e-10 9.9999988e-01 5.7797819e-11\n",
      " 5.1724715e-11 8.6388473e-11 6.9374187e-11 1.8227957e-09 3.2611810e-10], Действие: агент\n",
      "loss =  tensor(0.0896, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0921, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0945, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0892, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0946, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0987, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0964, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0919, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0944, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0835, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0873, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0825, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0838, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0803, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0824, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0819, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3618\n",
      "Reward: 16.1343\n",
      "Episode: 5, Step: 13, State: [0.740882933139801, 0.3115079402923584, 0.8714144229888916, 0.0, 0.8751258850097656, 0.902487576007843, 0.8182741403579712, 0.9108409285545349, 0.9873015880584717, 0.001004016026854515]\n",
      "weights [3.859244598870547, 1.4524474661002904, 7.77686149864314, 0.9999990000010001, 8.008000633898941, 10, 5.502763884050112, 10, 10, 1.0010040230780932]\n",
      "Episode: 5, Step: 13, Epsilon: 0.3580\n",
      "Episode: 5, Step: 13, Action: [0.01193372 0.06203118 0.01998265 0.1904862  0.01096518 0.07144126\n",
      " 0.01789189 0.08308932 0.2492479  0.2829307 ], Действие: случайное\n",
      "loss =  tensor(1.3808, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3495, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4394, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3993, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3397, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2897, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3000, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4017, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8825, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1680, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0264, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0356, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9568, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7589, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6929, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8372, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3143\n",
      "Reward: 13.0851\n",
      "Episode: 5, Step: 14, State: [0.6257197856903076, 1.0, 1.0, 0.0, 1.0, 1.0, 0.9979695677757263, 0.8510638475418091, 0.16507937014102936, 0.2098393589258194]\n",
      "weights [2.6717878476598287, 10, 10, 0.9999990000010001, 10, 10, 10, 6.7142414333503275, 1.1977172039115973, 1.2655638391159507]\n",
      "Episode: 5, Step: 14, Epsilon: 0.3565\n",
      "Episode: 5, Step: 14, Action: [2.2027727e-10 4.4278784e-07 8.7128665e-10 9.9999952e-01 2.5146094e-10\n",
      " 2.4619495e-10 3.7113224e-10 2.7755301e-10 7.7288398e-09 1.5512408e-09], Действие: агент\n",
      "loss =  tensor(0.1196, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1157, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1228, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1174, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1128, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1158, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1079, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1062, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0984, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0901, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0880, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0921, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0869, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0879, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0865, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0835, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.268\n",
      "Reward: 4.7720\n",
      "Episode: 5, Step: 15, State: [0.0, 0.9940476417541504, 1.0, 0.755836546421051, 1.0, 1.0, 1.0, 0.9918946027755737, 0.19682539999485016, 0.38353413343429565]\n",
      "weights [0.9999990000010001, 10, 10, 4.095600261799191, 10, 10, 10, 10, 1.245057743280035, 1.6221471975792194]\n",
      "Episode: 5, Step: 15, Epsilon: 0.3550\n",
      "Episode: 5, Step: 15, Action: [2.63681549e-01 1.74234651e-01 6.08480340e-02 2.46579424e-02\n",
      " 1.04691005e-01 3.76533642e-02 1.02144600e-01 1.34927051e-04\n",
      " 1.31710060e-01 1.00243868e-01], Действие: случайное\n",
      "loss =  tensor(1.4152, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6431, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3395, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2267, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2554, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1987, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2357, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2707, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9635, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0449, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0568, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9063, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9762, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8420, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8674, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1149\n",
      "Reward: 5.3332\n",
      "Episode: 5, Step: 16, State: [1.0, 1.0, 1.0, 0.002918287878856063, 0.9123867154121399, 0.9890547394752502, 0.9736040830612183, 1.0, 1.0, 1.0]\n",
      "weights [10, 10, 10, 1.0029258233478444, 10, 10, 10, 10, 10, 10]\n",
      "Episode: 5, Step: 16, Epsilon: 0.3535\n",
      "Episode: 5, Step: 16, Action: [0.14624619 0.07805385 0.10687092 0.13822328 0.0438485  0.0551243\n",
      " 0.08976894 0.13050831 0.14075211 0.07060359], Действие: случайное\n",
      "loss =  tensor(1.1148, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1151, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1384, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0707, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1075, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0988, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0944, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1188, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8761, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8329, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9259, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9002, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7427, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7557, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7479, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7829, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4411\n",
      "Reward: 35.5268\n",
      "Episode: 5, Step: 17, State: [1.0, 0.2321428507566452, 0.8714144229888916, 0.023346303030848503, 0.5971802473068237, 0.8179104328155518, 0.41319796442985535, 0.5967578291893005, 0.305820107460022, 0.7108433842658997]\n",
      "weights [10, 1.3023238745143189, 7.77686149864314, 1.0239033335971208, 2.482493747688536, 5.491772668196767, 1.7041493301553703, 2.479893206844773, 1.4405467087131179, 3.458321502137321]\n",
      "Episode: 5, Step: 17, Epsilon: 0.3519\n",
      "Episode: 5, Step: 17, Action: [0.29105376 0.06495946 0.02063248 0.09496066 0.02062728 0.13212896\n",
      " 0.11391969 0.10880088 0.08045182 0.07246501], Действие: случайное\n",
      "loss =  tensor(1.0696, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0282, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0874, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0417, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9871, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0303, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0391, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9067, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8535, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7548, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7362, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6791, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6771, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7457, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6992, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6434, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4978\n",
      "Reward: 19.6282\n",
      "Episode: 5, Step: 18, State: [0.10556621849536896, 0.4196428656578064, 0.8674579858779907, 0.0009727626456879079, 0.7613292932510376, 0.3194029927253723, 0.7522842884063721, 0.5055724382400513, 0.8095238208770752, 0.531124472618103]\n",
      "weights [1.1180245006995206, 1.723073979368703, 7.544720531852958, 1.0009727078868775, 4.189855654117442, 1.469296103296539, 4.036869347920583, 2.0225368786148574, 5.249972750565821, 2.132757648551484]\n",
      "Episode: 5, Step: 18, Epsilon: 0.3504\n",
      "Episode: 5, Step: 18, Action: [0.2899085  0.1077426  0.04189223 0.14631688 0.00649175 0.11768464\n",
      " 0.11440462 0.12477001 0.02432654 0.02646223], Действие: случайное\n",
      "loss =  tensor(0.9729, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0863, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0837, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0974, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9894, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9420, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8814, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9594, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7729, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6615, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6968, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6247, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6379, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6108, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5999, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.5336, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.5143\n",
      "Reward: 10.3631\n",
      "Episode: 5, Step: 19, State: [0.002879078732803464, 0.4077380895614624, 0.8783382773399353, 0.0, 0.9436052441596985, 0.5751243829727173, 0.49035534262657166, 0.41236069798469543, 0.8423280715942383, 0.35542169213294983]\n",
      "weights [1.002886385978904, 1.688439344039889, 8.219444527754646, 0.9999990000010001, 10, 2.3536244639600556, 1.9621475931997954, 1.7017212682154599, 6.342242832114849, 1.551399475278003]\n",
      "Episode: 5, Step: 19, Epsilon: 0.3489\n",
      "Episode: 5, Step: 19, Action: [0.0249096  0.10179661 0.01618889 0.08867071 0.24580902 0.22720202\n",
      " 0.05965792 0.01156681 0.0411302  0.18306821], Действие: случайное\n",
      "loss =  tensor(1.6760, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5180, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4286, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.5059, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3522, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2244, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1997, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3880, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0770, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1626, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9039, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8783, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9276, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7161, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8365, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2388\n",
      "Reward: 3.5904\n",
      "Episode: 5, Step: 20, State: [0.39443376660346985, 1.0, 1.0, 0.7937743067741394, 0.9989929795265198, 0.8805969953536987, 0.5969542860984802, 0.9848024249076843, 0.9809523820877075, 0.00200803205370903]\n",
      "weights [1.6513443014265472, 10, 10, 4.849032801514179, 10, 8.374928487216167, 2.481101980264103, 10, 10, 1.0020110683323142]\n",
      "Episode: 5, Step: 20, Epsilon: 0.3474\n",
      "Episode: 5, Step: 20, Action: [0.01540701 0.28823025 0.02526588 0.07853126 0.18940383 0.13112497\n",
      " 0.07055848 0.10447711 0.09301281 0.00398841], Действие: случайное\n",
      "loss =  tensor(1.4917, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3529, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3820, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3349, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2511, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1179, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2029, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0764, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0749, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8153, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8790, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8441, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7783, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7381, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7284, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7113, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3206\n",
      "Reward: 18.2636\n",
      "accuracy =  0.1945\n",
      "--------------------------------------\n",
      "Episode: 5, Step: 20, Test Accuracy: 0.1945\n",
      "--------------------------------------\n",
      "Episode: 5, Step: 21, State: [0.0, 1.0, 0.8526211380958557, 0.419260710477829, 0.5367572903633118, 0.31343284249305725, 0.8954314589500427, 0.9604862928390503, 0.8719576597213745, 0.9949799180030823]\n",
      "weights [0.9999990000010001, 10, 6.7851875220944295, 1.7219401134073078, 2.1586909421485245, 1.4565196318326017, 9.563014143117046, 10, 7.809855614700266, 10]\n",
      "Episode: 5, Step: 21, Epsilon: 0.3460\n",
      "Episode: 5, Step: 21, Action: [1.4946354e-10 4.1644452e-07 6.0434624e-10 9.9999952e-01 1.6014894e-10\n",
      " 1.4212516e-10 2.7334168e-10 1.9710607e-10 4.2766803e-09 8.7404628e-10], Действие: агент\n",
      "loss =  tensor(0.2801, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.3197, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2918, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2823, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2783, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2809, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2622, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2588, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2117, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.2047, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1920, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1842, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1770, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1797, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1737, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1711, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3271\n",
      "Reward: 14.7579\n",
      "Episode: 5, Step: 22, State: [0.0, 1.0, 1.0, 0.17607003450393677, 1.0, 0.9950248599052429, 0.9847715497016907, 0.7284700870513916, 0.09841269999742508, 0.7570281028747559]\n",
      "weights [0.9999990000010001, 10, 10, 1.2136939159677425, 10, 10, 10, 3.682821926758911, 1.109153701303737, 4.115685378211277]\n",
      "Episode: 5, Step: 22, Epsilon: 0.3445\n",
      "Episode: 5, Step: 22, Action: [2.6524632e-10 5.2065997e-07 1.1774665e-09 9.9999952e-01 3.0516395e-10\n",
      " 3.1595901e-10 5.1472776e-10 3.4702369e-10 9.0598657e-09 1.9008592e-09], Действие: агент\n",
      "loss =  tensor(0.2058, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1920, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1939, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1814, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1803, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1820, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1730, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1696, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1545, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1523, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1451, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1452, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1398, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1359, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1335, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1312, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3729\n",
      "Reward: 7.0309\n",
      "Episode: 5, Step: 23, State: [0.0, 0.97817462682724, 1.0, 0.020428014919161797, 1.0, 0.993034839630127, 0.9675126671791077, 0.5977710485458374, 0.1767195761203766, 0.5542168617248535]\n",
      "weights [0.9999990000010001, 10, 10, 1.0208529790329774, 10, 10, 10, 2.486140070834477, 1.2146514800341415, 2.243238182204637]\n",
      "Episode: 5, Step: 23, Epsilon: 0.3430\n",
      "Episode: 5, Step: 23, Action: [9.9749475e-10 1.2305530e-06 3.7917167e-09 9.9999869e-01 1.0989701e-09\n",
      " 1.1348809e-09 1.8128220e-09 1.2383257e-09 2.4631053e-08 6.0188312e-09], Действие: агент\n",
      "loss =  tensor(0.1445, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1424, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1432, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1386, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1384, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1410, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1348, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1387, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1269, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1162, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1175, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1162, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1142, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1132, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1146, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1106, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4678\n",
      "Reward: 14.2679\n",
      "Episode: 5, Step: 24, State: [0.012476007454097271, 0.5228174328804016, 0.9980217814445496, 0.0, 0.9768378734588623, 0.874626874923706, 0.7573603987693787, 0.2998986840248108, 0.37671956419944763, 0.5281124711036682]\n",
      "weights [1.012632599223576, 2.095629583466704, 10, 0.9999990000010001, 10, 7.976127445686817, 4.121321802403281, 1.4283626509749165, 1.6044116550905843, 2.119144541061069]\n",
      "Episode: 5, Step: 24, Epsilon: 0.3416\n",
      "Episode: 5, Step: 24, Action: [1.3774372e-08 1.6710592e-05 4.0815500e-08 9.9998295e-01 1.5729295e-08\n",
      " 1.4924671e-08 2.3678497e-08 1.8171285e-08 1.8263896e-07 6.1180351e-08], Действие: агент\n",
      "loss =  tensor(0.1156, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1158, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1167, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1144, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1154, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1149, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1144, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1120, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1061, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1015, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0993, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0986, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0968, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0975, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0954, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0953, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.484\n",
      "Reward: 8.8860\n",
      "Episode: 5, Step: 25, State: [0.025911707431077957, 0.4166666567325592, 0.9960435032844543, 0.0, 0.9738166928291321, 0.8497512340545654, 0.7015228271484375, 0.22593718767166138, 0.45291006565093994, 0.5451807379722595]\n",
      "weights [1.0265999304465658, 1.7142827463212307, 10, 0.9999990000010001, 10, 6.655584411114257, 3.350328737429368, 1.2918831549456609, 1.8278496995930307, 2.198670735427807]\n",
      "Episode: 5, Step: 25, Epsilon: 0.3401\n",
      "Episode: 5, Step: 25, Action: [2.0547226e-08 2.5584843e-05 5.7832139e-08 9.9997401e-01 2.3699521e-08\n",
      " 2.1947045e-08 3.5044067e-08 2.7698563e-08 2.4133476e-07 8.5694325e-08], Действие: агент\n",
      "loss =  tensor(0.0982, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0976, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0980, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0944, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0913, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0926, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0924, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0912, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0889, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0873, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0841, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0835, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0815, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0839, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0813, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0791, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.5062\n",
      "Reward: 9.4282\n",
      "Episode: 5, Step: 26, State: [0.17082533240318298, 0.2123015820980072, 0.997032642364502, 0.0, 0.9587109684944153, 0.765174150466919, 0.631472110748291, 0.20668692886829376, 0.4751322865486145, 0.5441766977310181]\n",
      "weights [1.2060170589644528, 1.2695197905102706, 10, 0.9999990000010001, 10, 4.258456824627824, 2.713491476965297, 1.2605348075743128, 1.905238346984502, 2.1938277424486685]\n",
      "Episode: 5, Step: 26, Epsilon: 0.3387\n",
      "Episode: 5, Step: 26, Action: [3.5137944e-08 5.6561021e-05 9.2466912e-08 9.9994278e-01 4.2282064e-08\n",
      " 3.6977610e-08 5.8834207e-08 4.9631236e-08 3.5972161e-07 1.3874906e-07], Действие: агент\n",
      "loss =  tensor(0.0850, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0849, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0819, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0814, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0819, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0814, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0812, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0834, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0759, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0747, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0741, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0752, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0752, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0741, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0721, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0724, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.494\n",
      "Reward: 7.9725\n",
      "Episode: 5, Step: 27, State: [0.1756238043308258, 0.2628968358039856, 0.9990108609199524, 0.0, 0.9758307933807373, 0.8059701323509216, 0.68324875831604, 0.2178318202495575, 0.45185184478759766, 0.5100401639938354]\n",
      "weights [1.2130369511110348, 1.3566603589748205, 10, 0.9999990000010001, 10, 5.153819142882908, 3.1570415877206375, 1.2784957856803538, 1.8243209726602787, 2.040979454911817]\n",
      "Episode: 5, Step: 27, Epsilon: 0.3372\n",
      "Episode: 5, Step: 27, Action: [0.04090317 0.02895444 0.10338204 0.02145306 0.08260833 0.0310042\n",
      " 0.11212742 0.08669823 0.39135714 0.10151196], Действие: случайное\n",
      "loss =  tensor(1.8517, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.1977, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(2.2525, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7414, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7496, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7156, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.7453, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4350, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1501, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1340, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3173, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3455, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2610, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0949, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1525, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1640, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2324\n",
      "Reward: 4.1720\n",
      "Episode: 5, Step: 28, State: [1.0, 1.0, 1.0, 0.8677042722702026, 1.0, 0.993034839630127, 0.8426395654678345, 0.21276596188545227, 0.4751322865486145, 0.2439759075641632]\n",
      "weights [10, 10, 10, 7.558765943496339, 10, 10, 6.354797177421477, 1.2702686638478782, 1.905238346984502, 1.3227074206996232]\n",
      "Episode: 5, Step: 28, Epsilon: 0.3358\n",
      "Episode: 5, Step: 28, Action: [3.0899786e-11 2.7150588e-07 1.2934674e-10 9.9999976e-01 3.5911035e-11\n",
      " 3.5518460e-11 4.6782352e-11 4.2870169e-11 1.0530111e-09 2.1634580e-10], Действие: агент\n",
      "loss =  tensor(0.1428, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1602, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1584, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1573, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1380, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1559, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1226, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1352, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1081, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1034, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.1069, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0959, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0932, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0956, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0938, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0958, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1469\n",
      "Reward: 10.9807\n",
      "Episode: 5, Step: 29, State: [0.0, 0.9871031641960144, 1.0, 0.9873540997505188, 1.0, 1.0, 1.0, 1.0, 0.6560846567153931, 0.9236947894096375]\n",
      "weights [0.9999990000010001, 10, 10, 10, 10, 10, 10, 10, 2.90768385837498, 10]\n",
      "Episode: 5, Step: 29, Epsilon: 0.3344\n",
      "Episode: 5, Step: 29, Action: [5.7701934e-13 1.7931777e-09 3.3956191e-12 1.0000000e+00 6.7783100e-13\n",
      " 7.2134643e-13 1.1307234e-12 8.5342692e-13 3.9653045e-11 5.3426499e-12], Действие: агент\n",
      "loss =  tensor(0.1018, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0980, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0983, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0948, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0988, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0932, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0899, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0895, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0842, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0866, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0862, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0801, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0789, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0763, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0749, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0770, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3234\n",
      "Reward: 16.5229\n",
      "Episode: 5, Step: 30, State: [0.0, 0.9980158805847168, 1.0, 0.08171205967664719, 1.0, 1.0, 1.0, 0.9949341416358948, 0.05925925821065903, 0.6465863585472107]\n",
      "weights [0.9999990000010001, 10, 10, 1.0889818619048974, 10, 10, 10, 10, 1.0629909948483274, 2.8295375536488194]\n",
      "Episode: 5, Step: 30, Epsilon: 0.3329\n",
      "Episode: 5, Step: 30, Action: [1.3285785e-10 1.9881421e-07 5.7709060e-10 9.9999976e-01 1.5098475e-10\n",
      " 1.5588154e-10 2.5165625e-10 1.6962272e-10 4.5447308e-09 9.6988695e-10], Действие: агент\n",
      "loss =  tensor(0.0795, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0830, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0807, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0788, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0779, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0770, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0783, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0757, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0722, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0715, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0689, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0711, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0713, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0684, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0683, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0679, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3548\n",
      "Reward: 5.5420\n",
      "accuracy =  0.2986\n",
      "--------------------------------------\n",
      "Episode: 5, Step: 30, Test Accuracy: 0.2986\n",
      "--------------------------------------\n",
      "Episode: 5, Step: 31, State: [0.0, 0.9732142686843872, 0.9950544238090515, 0.0, 1.0, 0.998009979724884, 0.9807106852531433, 0.9503546357154846, 0.08571428805589676, 0.4859437644481659]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 10, 10, 1.0937488065134835, 1.9453086754561721]\n",
      "Episode: 5, Step: 31, Epsilon: 0.3315\n",
      "Episode: 5, Step: 31, Action: [3.2759928e-10 3.6982200e-07 1.2882925e-09 9.9999964e-01 3.6255018e-10\n",
      " 3.7454567e-10 5.9075778e-10 4.0379339e-10 9.0608516e-09 2.1473190e-09], Действие: агент\n",
      "loss =  tensor(0.0684, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0711, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0691, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0693, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0685, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0663, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0696, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0651, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0648, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0628, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0626, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0643, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0620, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0593, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0609, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0598, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3876\n",
      "Reward: 8.0260\n",
      "Episode: 5, Step: 32, State: [0.0, 0.9394841194152832, 0.9307616353034973, 0.0, 0.9879153966903687, 0.9711442589759827, 0.913705587387085, 0.8642350435256958, 0.11534391343593597, 0.4186747074127197]\n",
      "weights [0.9999990000010001, 10, 10, 0.9999990000010001, 10, 10, 10, 7.365616727263034, 1.1303814949178992, 1.7202043202782886]\n",
      "Episode: 5, Step: 32, Epsilon: 0.3301\n",
      "Episode: 5, Step: 32, Action: [1.18124879e-01 1.71953024e-01 1.88905925e-02 1.34464380e-01\n",
      " 2.73961062e-02 9.42161937e-02 3.04464162e-01 2.06386508e-04\n",
      " 5.60780074e-02 7.42062691e-02], Действие: случайное\n",
      "loss =  tensor(1.1789, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3718, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1799, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3354, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1735, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1512, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1948, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2288, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9782, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9414, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8845, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8650, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8454, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8541, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8303, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7882, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2936\n",
      "Reward: 13.6332\n",
      "Episode: 5, Step: 33, State: [0.9539347290992737, 1.0, 1.0, 0.0, 0.9295065402984619, 0.8437811136245728, 0.09847715497016907, 0.9848024249076843, 0.8645502924919128, 0.39558231830596924]\n",
      "weights [10, 10, 10, 0.9999990000010001, 10, 6.401233691828469, 1.10923300089407, 10, 7.382759517445078, 1.6544822823762761]\n",
      "Episode: 5, Step: 33, Epsilon: 0.3287\n",
      "Episode: 5, Step: 33, Action: [5.5007544e-11 3.7530748e-07 1.9908823e-10 9.9999964e-01 5.8091237e-11\n",
      " 4.8423029e-11 9.1836268e-11 7.1659116e-11 1.5344674e-09 3.4018316e-10], Действие: агент\n",
      "loss =  tensor(0.0878, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0842, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0844, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0830, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0830, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0851, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0830, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0886, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0782, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0774, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0789, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0726, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0741, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0745, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0737, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0719, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.347\n",
      "Reward: 13.6162\n",
      "Episode: 5, Step: 34, State: [0.6554702520370483, 0.9642857313156128, 0.7161226272583008, 0.0019455252913758159, 0.7985901236534119, 0.6427860856056213, 0.03248731046915054, 0.9878419637680054, 0.9851852059364319, 0.7751004099845886]\n",
      "weights [2.902498560469653, 10, 3.5226353819841694, 1.0019483138369072, 4.964975169857255, 2.7994351851052963, 1.0335771067848178, 10, 10, 4.446408966430345]\n",
      "Episode: 5, Step: 34, Epsilon: 0.3273\n",
      "Episode: 5, Step: 34, Action: [3.1946443e-10 2.9904115e-06 1.1225283e-09 9.9999702e-01 3.3756714e-10\n",
      " 2.6207150e-10 5.6498983e-10 4.3217352e-10 7.6737514e-09 1.7980974e-09], Действие: агент\n",
      "loss =  tensor(0.0759, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0786, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0771, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0802, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0731, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0746, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0733, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0693, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0664, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0667, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0668, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0667, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0630, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0647, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0608, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0632, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.5041\n",
      "Reward: 18.2676\n",
      "Episode: 5, Step: 35, State: [0.0019193857442587614, 0.579365074634552, 0.7893174886703491, 0.0, 0.9083585143089294, 0.7293532490730286, 0.11269035190343857, 0.8723404407501221, 0.7111111283302307, 0.29718875885009766]\n",
      "weights [1.001922073021743, 2.3773528120100567, 4.746455921912782, 0.9999990000010001, 10, 3.694839497372468, 1.1270010138446744, 7.8332729064944635, 3.461526685653772, 1.4228551260915085]\n",
      "Episode: 5, Step: 35, Epsilon: 0.3260\n",
      "Episode: 5, Step: 35, Action: [2.4658100e-08 3.2583401e-05 6.6457226e-08 9.9996698e-01 2.5704708e-08\n",
      " 2.2335447e-08 3.8921517e-08 3.1183067e-08 2.6992009e-07 1.0183954e-07], Действие: агент\n",
      "loss =  tensor(0.0654, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0639, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0654, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0620, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0605, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0611, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0618, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0627, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0574, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0566, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0569, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0573, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0555, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0560, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0566, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0566, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4882\n",
      "Reward: 8.6622\n",
      "Episode: 5, Step: 36, State: [0.005758157465606928, 0.4424603283405304, 0.9821958541870117, 0.0, 0.9788519740104675, 0.8786069750785828, 0.3147208094596863, 0.8541033267974854, 0.5936508178710938, 0.10441767424345016]\n",
      "weights [1.0057904942528242, 1.7935911240763656, 10, 0.9999990000010001, 10, 8.237637730912509, 1.4592571240262224, 6.8541189043634745, 2.4609315904841176, 1.1165906859143937]\n",
      "Episode: 5, Step: 36, Epsilon: 0.3246\n",
      "Episode: 5, Step: 36, Action: [9.96466465e-09 6.97609266e-06 2.64209756e-08 9.99992847e-01\n",
      " 1.06531317e-08 9.80463977e-09 1.52374557e-08 1.24922925e-08\n",
      " 1.08574937e-07 4.15398702e-08], Действие: агент\n",
      "loss =  tensor(0.0583, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0570, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0560, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0558, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0562, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0555, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0547, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0541, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0520, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0514, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0513, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0505, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0517, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0513, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0504, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0507, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4889\n",
      "Reward: 8.5125\n",
      "Episode: 5, Step: 37, State: [0.005758157465606928, 0.4226190447807312, 0.9851632118225098, 0.0, 0.9768378734588623, 0.8776119351387024, 0.36852791905403137, 0.8338398933410645, 0.5894179940223694, 0.08835341036319733]\n",
      "weights [1.0057904942528242, 1.731955754696622, 10, 0.9999990000010001, 10, 8.170664602538558, 1.5835987790674548, 6.018255535891519, 2.435561105650052, 1.0969150923751103]\n",
      "Episode: 5, Step: 37, Epsilon: 0.3232\n",
      "Episode: 5, Step: 37, Action: [9.72771375e-09 6.40480812e-06 2.54410182e-08 9.99993443e-01\n",
      " 1.04212363e-08 9.61548263e-09 1.47626569e-08 1.21852635e-08\n",
      " 1.03317838e-07 3.98328766e-08], Действие: агент\n",
      "loss =  tensor(0.0523, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0511, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0505, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0517, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0503, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0507, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0506, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0487, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0490, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0486, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0482, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0480, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0469, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0463, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0451, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0449, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4909\n",
      "Reward: 8.3104\n",
      "Episode: 5, Step: 38, State: [0.008637236431241035, 0.363095223903656, 0.9881305694580078, 0.0, 0.9778448939323425, 0.8905472755432129, 0.40507614612579346, 0.8318135738372803, 0.585185170173645, 0.07831325381994247]\n",
      "weights [1.008711470752322, 1.5700909577694442, 10, 0.9999990000010001, 10, 9.136281154094533, 1.6808845579200566, 5.945747686468009, 2.4107083869451356, 1.084966144059643]\n",
      "Episode: 5, Step: 38, Epsilon: 0.3218\n",
      "Episode: 5, Step: 38, Action: [9.36289268e-09 5.90864875e-06 2.40593501e-08 9.99993920e-01\n",
      " 1.01324904e-08 9.31591781e-09 1.41005030e-08 1.17924275e-08\n",
      " 9.64473443e-08 3.76062204e-08], Действие: агент\n",
      "loss =  tensor(0.0460, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0467, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0470, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0461, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0451, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0463, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0439, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0452, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0430, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0433, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0444, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0427, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0426, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0429, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0423, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0415, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4937\n",
      "Reward: 8.5244\n",
      "Episode: 5, Step: 39, State: [0.00671785045415163, 0.3730158805847168, 0.9861523509025574, 0.0, 0.9758307933807373, 0.8855721354484558, 0.38477158546447754, 0.8145896792411804, 0.5947089791297913, 0.07931727170944214]\n",
      "weights [1.0067622716213627, 1.5949341842954499, 10, 0.9999990000010001, 10, 8.739053768636781, 1.6254099306272056, 5.393413929135351, 2.467356741573359, 1.0861493141154013]\n",
      "Episode: 5, Step: 39, Epsilon: 0.3205\n",
      "Episode: 5, Step: 39, Action: [1.03593232e-08 6.66112601e-06 2.64330815e-08 9.99993205e-01\n",
      " 1.11567706e-08 1.02386135e-08 1.55584541e-08 1.30090747e-08\n",
      " 1.04081678e-07 4.12045935e-08], Действие: агент\n",
      "loss =  tensor(0.0431, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0433, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0430, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0443, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0421, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0431, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0411, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0421, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0406, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0401, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0405, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0404, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0406, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0397, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0392, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0404, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4957\n",
      "Reward: 8.3432\n",
      "Episode: 5, Step: 40, State: [0.008637236431241035, 0.3492063581943512, 0.9851632118225098, 0.0, 0.9778448939323425, 0.8895522356033325, 0.36548224091529846, 0.826747715473175, 0.5873016119003296, 0.09036144614219666]\n",
      "weights [1.008711470752322, 1.5365830259841577, 10, 0.9999990000010001, 10, 9.053971816367124, 1.575997534639493, 5.7718963466182895, 2.4230711962153224, 1.0993365402361581]\n",
      "Episode: 5, Step: 40, Epsilon: 0.3191\n",
      "Episode: 5, Step: 40, Action: [1.0589721e-08 7.0608889e-06 2.6945163e-08 9.9999273e-01 1.1470001e-08\n",
      " 1.0459622e-08 1.5911645e-08 1.3360109e-08 1.0529626e-07 4.2125755e-08], Действие: агент\n",
      "loss =  tensor(0.0410, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0384, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0399, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0395, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0401, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0387, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0396, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0383, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0393, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0373, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0374, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0369, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0371, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0369, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0373, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0367, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4978\n",
      "Reward: 8.3813\n",
      "accuracy =  0.3682\n",
      "--------------------------------------\n",
      "Episode: 5, Step: 40, Test Accuracy: 0.3682\n",
      "--------------------------------------\n",
      "Episode: 5, Step: 41, State: [0.011516314931213856, 0.3323412835597992, 0.9891197085380554, 0.0, 0.9778448939323425, 0.8965173959732056, 0.37969544529914856, 0.8125633001327515, 0.5788359642028809, 0.0803212821483612]\n",
      "weights [1.0116494621567278, 1.4977689613082494, 10, 0.9999990000010001, 10, 9.663366572941117, 1.6121087299988148, 5.335106015002548, 2.374366139172373, 1.0873350587049897]\n",
      "Episode: 5, Step: 41, Epsilon: 0.3178\n",
      "Episode: 5, Step: 41, Action: [1.0994086e-08 7.2261405e-06 2.7661805e-08 9.9999261e-01 1.1927914e-08\n",
      " 1.0876346e-08 1.6412006e-08 1.3845492e-08 1.0635391e-07 4.3183256e-08], Действие: агент\n",
      "loss =  tensor(0.0381, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0376, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0368, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0377, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0358, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0364, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0373, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0358, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0358, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0365, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0350, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0350, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0354, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0339, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0339, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0350, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4906\n",
      "Reward: 7.9104\n",
      "Episode: 5, Step: 42, State: [0.018234165385365486, 0.3392857015132904, 0.9950544238090515, 0.0, 0.9859012961387634, 0.9164178967475891, 0.4111675024032593, 0.8206686973571777, 0.573544979095459, 0.07028112560510635]\n",
      "weights [1.01857178786501, 1.513511193535827, 10, 0.9999990000010001, 10, 10, 1.6982729482636265, 5.576240227014253, 2.3449076832798252, 1.0755927968635155]\n",
      "Episode: 5, Step: 42, Epsilon: 0.3165\n",
      "Episode: 5, Step: 42, Action: [8.4094962e-09 5.3216099e-06 2.1309114e-08 9.9999452e-01 9.1186427e-09\n",
      " 8.3570173e-09 1.2548577e-08 1.0579586e-08 8.3205045e-08 3.3250625e-08], Действие: агент\n",
      "loss =  tensor(0.0355, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0338, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0342, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0337, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0335, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0342, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0344, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0335, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0330, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0331, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0326, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0326, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0319, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0325, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0321, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0321, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4912\n",
      "Reward: 8.1327\n",
      "Episode: 5, Step: 43, State: [0.015355085954070091, 0.3601190447807312, 0.9950544238090515, 0.0, 0.9859012961387634, 0.9084576964378357, 0.4091370701789856, 0.8156028389930725, 0.5629629492759705, 0.07128514349460602]\n",
      "weights [1.0155935100476676, 1.5627882484314302, 10, 0.9999990000010001, 10, 10, 1.6924370392738677, 5.423047575634075, 2.2881302860090242, 1.0767556007526744]\n",
      "Episode: 5, Step: 43, Epsilon: 0.3151\n",
      "Episode: 5, Step: 43, Action: [0.12763672 0.18283647 0.21108518 0.06434766 0.11276118 0.00819178\n",
      " 0.02303718 0.20137841 0.01148687 0.05723855], Действие: случайное\n",
      "loss =  tensor(1.6825, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4779, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3903, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.6582, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4356, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3524, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4844, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.4966, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0236, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.1228, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0835, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0730, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9282, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9359, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9699, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8824, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1853\n",
      "Reward: 5.4205\n",
      "Episode: 5, Step: 44, State: [0.9788867831230164, 0.9940476417541504, 1.0, 0.0, 0.9969788789749146, 1.0, 1.0, 0.1965552121400833, 0.9989417791366577, 1.0]\n",
      "weights [10, 10, 10, 0.9999990000010001, 10, 10, 10, 1.2446390473508253, 10, 10]\n",
      "Episode: 5, Step: 44, Epsilon: 0.3138\n",
      "Episode: 5, Step: 44, Action: [1.97496598e-12 1.74735515e-08 7.80962274e-12 1.00000000e+00\n",
      " 2.28990828e-12 1.93052627e-12 3.69101711e-12 2.87697513e-12\n",
      " 7.83074716e-11 1.28178666e-11], Действие: агент\n",
      "loss =  tensor(0.0619, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0589, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0686, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0707, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0652, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0648, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0635, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0631, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0628, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0589, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0573, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0571, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0541, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0557, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0545, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0576, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.2875\n",
      "Reward: 11.0424\n",
      "Episode: 5, Step: 45, State: [0.8109405040740967, 0.4950396716594696, 0.9446092844009399, 0.0, 0.9234642386436462, 0.9800994992256165, 0.9766497611999512, 0.036474164575338364, 0.9989417791366577, 0.9859437942504883]\n",
      "weights [5.289312265381556, 1.9803496701149967, 10, 0.9999990000010001, 10, 10, 10, 1.0378538129239163, 10, 10]\n",
      "Episode: 5, Step: 45, Epsilon: 0.3125\n",
      "Episode: 5, Step: 45, Action: [3.1005049e-11 1.8572905e-07 9.8252156e-11 9.9999976e-01 3.8120788e-11\n",
      " 3.0436691e-11 5.4556581e-11 4.7194349e-11 6.9541400e-10 1.5505423e-10], Действие: агент\n",
      "loss =  tensor(0.0591, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0594, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0569, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0580, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0578, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0581, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0554, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0544, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0515, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0496, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0498, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0476, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0461, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0469, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0452, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0477, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4455\n",
      "Reward: 17.6552\n",
      "Episode: 5, Step: 46, State: [0.0019193857442587614, 0.5019841194152832, 0.7912957668304443, 0.0, 0.904330313205719, 0.8517413139343262, 0.7299492359161377, 0.036474164575338364, 0.9523809552192688, 0.8313252925872803]\n",
      "weights [1.001922073021743, 2.0079640650451642, 4.791446696439965, 0.9999990000010001, 10, 6.74492187685488, 3.702993770073868, 1.0378538129239163, 10, 5.928535977935319]\n",
      "Episode: 5, Step: 46, Epsilon: 0.3112\n",
      "Episode: 5, Step: 46, Action: [4.0813113e-09 6.3710650e-06 1.0879366e-08 9.9999356e-01 4.4850261e-09\n",
      " 3.8640486e-09 6.9871531e-09 5.6666849e-09 4.5627093e-08 1.5178378e-08], Действие: агент\n",
      "loss =  tensor(0.0459, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0487, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0478, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0456, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0449, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0451, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0441, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0460, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0432, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0410, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0428, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0409, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0407, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0405, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0409, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0392, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.4277\n",
      "Reward: 8.8247\n",
      "Episode: 5, Step: 47, State: [0.0009596928721293807, 0.5902777910232544, 0.8773491382598877, 0.0, 0.9375629425048828, 0.8636816143989563, 0.7543147206306458, 0.046605877578258514, 0.9428571462631226, 0.7640562057495117]\n",
      "weights [1.000959612846125, 2.440672088109015, 8.153157936720973, 0.9999990000010001, 10, 7.335713813489662, 4.070231364026001, 1.048883066928092, 10, 4.238279565254407]\n",
      "Episode: 5, Step: 47, Epsilon: 0.3099\n",
      "Episode: 5, Step: 47, Action: [2.2782469e-09 2.9856412e-06 6.2325434e-09 9.9999702e-01 2.4564237e-09\n",
      " 2.1815447e-09 3.8903889e-09 3.0885239e-09 2.7043878e-08 8.7840331e-09], Действие: агент\n",
      "loss =  tensor(0.0406, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0399, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0414, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0399, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0395, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0408, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0388, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0404, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0379, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0371, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0384, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0373, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0368, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0359, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0365, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0361, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.411\n",
      "Reward: 8.7435\n",
      "Episode: 5, Step: 48, State: [0.0, 0.7609127163887024, 0.8921859264373779, 0.0, 0.9425981640815735, 0.8895522356033325, 0.7593908905982971, 0.05572441592812538, 0.929100513458252, 0.7128514051437378]\n",
      "weights [0.9999990000010001, 4.182555434735436, 9.275140914495331, 0.9999990000010001, 10, 9.053971816367124, 4.1561013478884306, 1.0590117523489113, 10, 3.482505348825471]\n",
      "Episode: 5, Step: 48, Epsilon: 0.3086\n",
      "Episode: 5, Step: 48, Action: [0.48591034 0.01499168 0.01766053 0.04322232 0.03842411 0.00731056\n",
      " 0.02849963 0.00655276 0.07416424 0.28326383], Действие: случайное\n",
      "loss =  tensor(1.4039, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3561, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.3004, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.2132, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(1.0176, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9914, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.9091, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.8794, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7518, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.7952, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6936, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6233, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6702, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6220, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6667, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.6739, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.1684\n",
      "Reward: 4.0694\n",
      "Episode: 5, Step: 49, State: [1.0, 1.0, 1.0, 0.005836575757712126, 0.9506545662879944, 0.9353233575820923, 0.8974619507789612, 1.0, 0.9989417791366577, 0.5522088408470154]\n",
      "weights [10, 10, 10, 1.0058698295929869, 10, 10, 9.75238221532896, 10, 10, 2.2331788968604025]\n",
      "Episode: 5, Step: 49, Epsilon: 0.3073\n",
      "Episode: 5, Step: 49, Action: [4.6885044e-13 2.4107165e-09 1.8297529e-12 1.0000000e+00 5.1161370e-13\n",
      " 4.3186925e-13 7.9644998e-13 6.2965215e-13 1.8881965e-11 3.0325885e-12], Действие: агент\n",
      "loss =  tensor(0.0779, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0881, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0694, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0760, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0698, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0729, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0644, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0624, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0563, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0535, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0525, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0500, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0496, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0496, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0465, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0493, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3611\n",
      "Reward: 18.9367\n",
      "Episode: 5, Step: 50, State: [0.0, 0.9722222089767456, 0.8506429195404053, 0.0, 0.9113796353340149, 0.9810945391654968, 0.9695431590080261, 0.9939209818840027, 0.7470899224281311, 0.01606425642967224]\n",
      "weights [0.9999990000010001, 10, 6.695319040810291, 0.9999990000010001, 10, 10, 10, 10, 3.953958875984123, 1.0163254970755384]\n",
      "Episode: 5, Step: 50, Epsilon: 0.3060\n",
      "Episode: 5, Step: 50, Action: [1.4549367e-10 6.0758907e-08 4.3509435e-10 9.9999988e-01 1.3840720e-10\n",
      " 1.3772200e-10 2.1671713e-10 1.6514383e-10 2.3583961e-09 6.3412808e-10], Действие: агент\n",
      "loss =  tensor(0.0526, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0528, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0492, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0495, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0514, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0479, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0467, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0494, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0434, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0444, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0426, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0419, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0403, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0409, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0416, grad_fn=<NllLossBackward0>)\n",
      "loss =  tensor(0.0413, grad_fn=<NllLossBackward0>)\n",
      "accuracy =  0.3225\n",
      "Reward: 3.9146\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      3\u001b[39m critic = Critic(NUM_CLASSES)\n\u001b[32m      6\u001b[39m visualize_data(env.train_data.images, env.train_data.labels)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mactor_critic\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcritic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisodes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining complete!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 101\u001b[39m, in \u001b[36mactor_critic\u001b[39m\u001b[34m(env, actor, critic, episodes, max_steps, gamma, lr_actor, lr_critic)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m step % \u001b[32m10\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m    100\u001b[39m     env.model.eval()\u001b[38;5;66;03m#Необходимо переводить в eval\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     accuracy, _ = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--------------------------------------\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    103\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpisode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepisode+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Step: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 84\u001b[39m, in \u001b[36mDataSelectionEnv.evaluate\u001b[39m\u001b[34m(self, dataloader)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[32m     83\u001b[39m     images, labels = images.to(DEVICE), labels.to(DEVICE)\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Получили тензор(batch_size,NUM_CLASSES)\u001b[39;00m\n\u001b[32m     85\u001b[39m     predicted = torch.argmax(output, dim=\u001b[32m1\u001b[39m)+\u001b[32m1\u001b[39m  \u001b[38;5;66;03m# Получили тезор(batch_size)\u001b[39;00m\n\u001b[32m     86\u001b[39m     correct += (predicted == labels).sum().item()  \u001b[38;5;66;03m# Нашли количество правильных ответов\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\VSCode\\project\\CV_project\\a2c-ppo\\my_venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\VSCode\\project\\CV_project\\a2c-ppo\\my_venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mSimpleCNN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     23\u001b[39m x = \u001b[38;5;28mself\u001b[39m.pool(x)\n\u001b[32m     24\u001b[39m x = F.relu(\u001b[38;5;28mself\u001b[39m.bn2(\u001b[38;5;28mself\u001b[39m.cv2(x)))\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m x = F.relu(\u001b[38;5;28mself\u001b[39m.bn3(\u001b[38;5;28mself\u001b[39m.cv3(x)))\n\u001b[32m     27\u001b[39m x = \u001b[38;5;28mself\u001b[39m.pool(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\VSCode\\project\\CV_project\\a2c-ppo\\my_venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\VSCode\\project\\CV_project\\a2c-ppo\\my_venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\VSCode\\project\\CV_project\\a2c-ppo\\my_venv\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py:213\u001b[39m, in \u001b[36mMaxPool2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m        \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\VSCode\\project\\CV_project\\a2c-ppo\\my_venv\\Lib\\site-packages\\torch\\_jit_internal.py:624\u001b[39m, in \u001b[36mboolean_dispatch.<locals>.fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(*args, **kwargs)\n\u001b[32m    623\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\VSCode\\project\\CV_project\\a2c-ppo\\my_venv\\Lib\\site-packages\\torch\\nn\\functional.py:830\u001b[39m, in \u001b[36m_max_pool2d\u001b[39m\u001b[34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[39m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    829\u001b[39m     stride = torch.jit.annotate(List[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[32m--> \u001b[39m\u001b[32m830\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "env = DataSelectionEnv()\n",
    "actor = Actor(NUM_CLASSES, NUM_CLASSES)\n",
    "critic = Critic(NUM_CLASSES)\n",
    "\n",
    "\n",
    "visualize_data(env.train_data.images, env.train_data.labels)\n",
    "\n",
    "actor_critic(env, actor, critic, episodes=10)\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.3429\n",
      "Test Accuracy: 0.3429\n",
      "Error per class: [0.009164969450101833, 0.7944936086529006, 0.748, 0.8336633663366336, 0.3026315789473684, 0.865, 0.9990157480314961, 0.8991097922848664, 0.9849699398797596, 0.0950920245398773]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the trained CNN\n",
    "test_dataset = DataPreloading().get_train_data() #Or, load a completely separate test dataset if you have one.\n",
    "\n",
    "#Create test indices - fixed\n",
    "test_indices = random.sample(range(len(test_dataset)), int(0.2*len(test_dataset))) #20% for test data\n",
    "test_subset = Subset(test_dataset,test_indices)\n",
    "\n",
    "test_dataloader = get_dataloader(test_subset, shuffle=False)\n",
    "accuracy, error_per_class = env.evaluate(test_dataloader) # Reuse your existing evaluate function\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(\"Error per class:\", error_per_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
